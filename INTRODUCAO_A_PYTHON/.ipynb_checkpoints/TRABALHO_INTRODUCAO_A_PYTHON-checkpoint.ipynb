{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img style=\"display:block;margin-left: auto;margin-right: auto;width: 50%;\" src=\"data:image/jpeg;base64,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\" width=300 height=200 /></p>\n",
    "<h1 style='text-align: center;'>UNIFOR - Universidade de Fortaleza</h1>\n",
    "<h2 style='text-align: center;'>MBA EM CIÊCIA DE DADOS </h2>\n",
    "<br><br>\n",
    "<h4 style='text-align: center;'>JOSÉ VALCLEMIR RODRIGUES DA SILVA</h4>\n",
    "<br><br>\n",
    "<h4 style='text-align: center;'>Fortaleza-Ceará</h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  INTRODUÇÃO\n",
    "\n",
    "   Após mais de uma década de governo PT e de seu fim no impeachment de Dilma Rousseff,\n",
    "grupos alternativos de politicos, batalham pela apreensão do apoio da população. O contexto de incerteza\n",
    "na area pública brasileira abriu espaço para diferentes forças políticas, consolidando retóricas\n",
    "fortes e muitas vezes radicalizadas. Esse novo movimento identifica-se como a \"nova direita conservadora\" que se caracteriza como a antítese da politica tradicional, construindo um discurso de caráter opositor, defendendo pautas como, o estado menor, liberação de porte de armas, familia e direitos de propriedade privada.\n",
    "\n",
    "\n",
    "\n",
    "Um grande exemplo desse movimento é Jair Bolsonaro, militar reformado e que durante seus 27 anos como depultado federal, só conseguiu impulsionar e aprovar dois projetos. \n",
    "Mas sua limitada transcendência política nunca foi sinônimo de poucas aspirações, nem de falta de astúcia. \n",
    "Foi o deputado mais votado nas eleições de 2014. E depois de passar por vários partidos, ingressou no começo de 2018 no PSL.\n",
    "\n",
    "\n",
    "O Twitter é uma rede social fundada em 2006, com o intuito de permitir que seus usuários publiquem\n",
    "mensagens de texto de até no máximo 140 caracteres. O Twitter hoje, é uma das redes sociais mais populares\n",
    "do mundo, tendo cerca de 319 milhões de usuários ativos mensalmente.\n",
    "\n",
    "No ano de 2018, ocorreram as eleições presidenciais do Brasil, na qual milhões de brasileiros foram\n",
    "às urnas para eleger o novo líder do país. Este evento de âmbito mundial gerou várias pesquisas\n",
    "envolvendo milhares de pessoas. \n",
    "opinião da população de diferentes regiões do país. Este acontecimento também gerou milhares de\n",
    "publicações em redes sociais, contendo opiniões dos usuários, sendo essas uma boa fonte de pesquisa.\n",
    "\n",
    "\n",
    "Diversos autores utilizam o Twitter como fonte de dados para estudos sobre análise de sentimentos,\n",
    "acerca dos mais variados temas, por ser uma ótima fonte de opinião dos internautas. As eleições brasileiras do ano de 2014 geraram quase 40 milhões de tweets,\n",
    "o que faz deste um tema relevante para aplicar técnicas de analise da dados e até mesmo, análise de sentimentos, para descobrir se existe\n",
    "alguma relação entre a opinião dos usuários da rede social e o resultado final das eleições.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  METODOLOGIA\n",
    "Algumas etapas foram percorridas a fim de alcançar o objetivo proposto neste trabalho. Essas etapas\n",
    "encontram-se detalhadas na seguinte subseção.\n",
    "\n",
    "2.1 Pré-processamento dos tweets\n",
    "Após a coleta dos dados, deu-se início a etapa de pré-processamento dos tweets. Esta etapa\n",
    "tem como finalidade padronizar e preparar os dados para serem utilizados nas próximas etapas. As\n",
    "técnicas utilizadas neste processo foram desenvolvidas utilizando as bibliotecas que estão descritas na Tabela I.\n",
    "\n",
    "<h3>Tabela I. Tabela de módulos </h3>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Biblioteca</th>\n",
    "      <th>Disponível em</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>sklearn</td>\n",
    "      <td>https://scikit-learn.org/</td>\n",
    "    </tr>  \n",
    "    <tr>\n",
    "      <td>Pandas</td>\n",
    "      <td>https://pandas.pydata.org/</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Numpy</td>\n",
    "      <td>https://numpy.org/ </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Nltk</td>\n",
    "      <td>https://www.nltk.org/ </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Mathplotlib</td>\n",
    "      <td>https://matplotlib.org/stable/index.html</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Seaborn</td>\n",
    "      <td>https://seaborn.pydata.org/</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "    \n",
    "2.1.1 *Preparação e padronização*. Primeiramente, todo o corpus foi padronizado em letra minúscula. Após a padronização, algumas informaçães utilizadas pelo Twitter, que não definem a opinião\n",
    "dos usuários, foram removidas, como: links para websites, citações de outros usuários e emoctions.\n",
    "\n",
    "2.1.2 *Tokenização*. A primeira etapa no pré-processamento de textos é a tokenização, que consiste\n",
    "em quebrar o fluxo de caracteres em palavras. Nesta etapa, cada tweet foi quebrado\n",
    "em um vetor de palavras, utilizando como delimitadores os espaços em brancos entre as palavras.\n",
    "\n",
    "2.1.3 *Remoção de stopwords*. Uma das tarefas mais utilizadas em pré-processamento de textos é a\n",
    "remoção de stopwords. Esse método consiste em remover palavras muito frequentes que não agregam\n",
    "conteúdo semântico ao texto, sendo informações irrerelevantes para a análise.\n",
    "Para isso, foi utilizado a lista de stopwords em português, disponível pela biblioteca NLTK em python.\n",
    "\n",
    "2.1.4 *Lematização*. A lematização é uma técnica muito utilizada em buscadores de palavras em\n",
    "websites, por possibilitar que a busca incorpore o maior número de palavras relacionadas à busca.\n",
    "Esta técnica consiste em reduzir uma palavra ao seu lema, que é a sua forma no masculino e singular,\n",
    "diminuindo o número de palavras no vocabulário. Para isso, foi utilizado\n",
    "o pacote Wordnet Lemmatizer da biblioteca NLTK do python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importação das bibliotecas</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valclemir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\valclemir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\valclemir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "import pandas as pd, numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "import csv, re\n",
    "from unicodedata import normalize\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pickle import load\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import seaborn as sns\n",
    "simplefilter('ignore')\n",
    "import plotly.offline as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega o dataset e transforma em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bolsonaro \n",
    "with open('jairbolsonaro.json', 'r', encoding='utf8') as json_file:\n",
    "    words = json.load(json_file)\n",
    "    \n",
    "columns_name = []\n",
    "for i in words[0]:\n",
    "    columns_name.append(i)\n",
    "\n",
    "DF = pd.DataFrame(columns=columns_name)\n",
    "DF = DF[['full_text', 'created_at', 'source', \n",
    "         #'geo', 'coordinates', \n",
    "         'place', 'retweet_count', 'favorite_count']]\n",
    "    \n",
    "\n",
    "DF['full_text'] = [i['full_text']  for i in words]\n",
    "DF['created_at'] = [i['created_at'] for i in words]\n",
    "DF['entities'] = [i['entities'] for i in words]\n",
    "DF['source'] = [i['source'] for i in words]\n",
    "#DF['geo'] = [i['geo'] for i in words]\n",
    "#DF['coordinates'] = [i['coordinates'] for i in words]\n",
    "DF['place'] = [i['place'] for i in words]\n",
    "DF['retweet_count'] = [i['retweet_count'] for i in words]\n",
    "DF['favorite_count'] = [i['favorite_count'] for i in words]\n",
    "DF['day'] = [str(i)[8:10].strip() for i in pd.to_datetime(DF['created_at'])]\n",
    "DF['month'] = [str(i)[5:7].strip() for i in pd.to_datetime(DF['created_at'])]\n",
    "DF['year'] = [str(i)[0:4].strip() for i in pd.to_datetime(DF['created_at'])]\n",
    "DF['hour'] = [str(i)[10:19].strip() for i in pd.to_datetime(DF['created_at'])]\n",
    "        \n",
    "    \n",
    "#Lula   \n",
    "with open('LulaOficial.json', 'r', encoding='utf8') as json_file:\n",
    "    words = json.load(json_file)\n",
    "    \n",
    "columns_name = []\n",
    "for i in words[0]:\n",
    "    columns_name.append(i)\n",
    "\n",
    "DF_LULA = pd.DataFrame(columns=columns_name)\n",
    "DF_LULA = DF_LULA[['full_text', 'created_at', 'source', \n",
    "         #'geo', 'coordinates', \n",
    "         'place', 'retweet_count', 'favorite_count']]\n",
    "    \n",
    "\n",
    "DF_LULA['full_text'] = [i['full_text']  for i in words]\n",
    "DF_LULA['created_at'] = [i['created_at'] for i in words]\n",
    "DF_LULA['entities'] = [i['entities'] for i in words]\n",
    "DF_LULA['source'] = [i['source'] for i in words]\n",
    "#DF['geo'] = [i['geo'] for i in words]\n",
    "#DF['coordinates'] = [i['coordinates'] for i in words]\n",
    "DF_LULA['place'] = [i['place'] for i in words]\n",
    "DF_LULA['retweet_count'] = [i['retweet_count'] for i in words]\n",
    "DF_LULA['favorite_count'] = [i['favorite_count'] for i in words]\n",
    "DF_LULA['day'] = [str(i)[8:10].strip() for i in pd.to_datetime(DF_LULA['created_at'])]\n",
    "DF_LULA['month'] = [str(i)[5:7].strip() for i in pd.to_datetime(DF_LULA['created_at'])]\n",
    "DF_LULA['year'] = [str(i)[0:4].strip() for i in pd.to_datetime(DF_LULA['created_at'])]\n",
    "DF_LULA['hour'] = [str(i)[10:19].strip() for i in pd.to_datetime(DF_LULA['created_at'])]  \n",
    "DF_LULA['hour'] = [str(i)[10:19].strip() for i in pd.to_datetime(DF_LULA['created_at'])]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções necessárias para fazer a limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retorna texto limpo\n",
    "def cleaner(text):\n",
    "    \n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    \n",
    "    text = regrex_pattern.sub(r'',text)\n",
    "    \n",
    "    text = re.sub(\"@[A-Za-z0-9]+\",\"\",text) #Remove @mentions\n",
    "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text) #Remove http links\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation]) #Remove ponctuation\n",
    "    text = re.sub('[0-9]+', '', text) ##Remove numbers\n",
    "    text = text.replace('“', '').replace('”', '')\n",
    "    return text\n",
    "\n",
    "#Remove stopwords\n",
    "def remove_stop_words(text, stop_words=True):\n",
    "    words_list = []\n",
    "    stopWords = stopwords.words('portuguese')\n",
    "    list_new_stopWords = ['jair', 'jair bolsonaro', 'bolsonaro', 'dilma', 'lula', 'rousseff',\n",
    "                         'sobre', 'via', 'governo', 'todo', 'presidente', 'sp', 'rj', 'sempre'\n",
    "                         ,'apos', 'd', 'r', 'p', 'c', 'q', 'todos', 'deputado', 'rio', 'ñ', 'rt',\n",
    "                         'sao', 'paulo', 'quer', 'n', 'nao', 'parabens', 'obrigado', 'hoje', 'fala']\n",
    "    \n",
    "    for i in list_new_stopWords:\n",
    "        stopWords.append(i)\n",
    "        \n",
    "    word_tokens = word_tokenize(cleaner(text))\n",
    "    \n",
    "    for word in word_tokens:\n",
    "        word = word.lower().strip()\n",
    "        if word not in stopWords:  #Remove palavras stopWords\n",
    "            words_list.append(word)\n",
    "   \n",
    "            \n",
    "                \n",
    "    full_text = \" \".join(s for s in words_list)\n",
    "    return full_text\n",
    "\n",
    "\n",
    "def untokenize(ngram):\n",
    "    tokens = list(ngram)\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and \\\n",
    "                             i not in string.punctuation and \\\n",
    "                             i != \"n't\"\n",
    "                          else i for i in tokens]).strip()\n",
    "\n",
    "\n",
    "\n",
    "# Transforma as horas em intervalos.\n",
    "def get_range_hour(hour):\n",
    "    \n",
    "    hour = datetime.strptime(hour, '%H:%M:%S').time()\n",
    "    return_range = None\n",
    "    \n",
    "    #Manhã\n",
    "    time_str_morning_begin = '06:00:00'\n",
    "    time_str_morning_end = '11:59:59'\n",
    "\n",
    "    time_morning_begin = datetime.strptime(time_str_morning_begin, '%H:%M:%S').time()\n",
    "    time_morning_end = datetime.strptime(time_str_morning_end, '%H:%M:%S').time()\n",
    "\n",
    "    #Tarde \n",
    "    time_str_evening_begin = '12:00:00'\n",
    "    time_str_evening_end = '17:59:59'\n",
    "\n",
    "    time_evening_begin = datetime.strptime(time_str_evening_begin, '%H:%M:%S').time()\n",
    "    time_evening_end = datetime.strptime(time_str_evening_end, '%H:%M:%S').time()\n",
    "\n",
    "    #Noite \n",
    "    time_str_night_begin = '18:00:00'\n",
    "    time_str_night_end = '23:59:59'\n",
    "\n",
    "    time_night_begin = datetime.strptime(time_str_night_begin, '%H:%M:%S').time()\n",
    "    time_night_end = datetime.strptime(time_str_night_end, '%H:%M:%S').time()\n",
    "\n",
    "    #Madrugada\n",
    "    time_str_dawn_begin = '00:00:00'\n",
    "    time_str_dawn_end = '05:59:59'\n",
    "\n",
    "    time_dawn_begin = datetime.strptime(time_str_dawn_begin, '%H:%M:%S').time()\n",
    "    time_dawn_end = datetime.strptime(time_str_dawn_end, '%H:%M:%S').time()\n",
    "    \n",
    "    #Manha\n",
    "    if hour >= time_morning_begin and hour <= time_morning_end:\n",
    "        return_range = 1 \n",
    "\n",
    "    #Tarde    \n",
    "    elif hour >= time_evening_begin and hour <= time_evening_end:\n",
    "        return_range = 2 \n",
    "        \n",
    "    #Noite    \n",
    "    elif hour >= time_night_begin and hour <= time_night_end:\n",
    "        return_range = 3 \n",
    "\n",
    "    #Madrugada    \n",
    "    elif hour >= time_dawn_begin and hour <= time_dawn_end:\n",
    "        return_range = 4\n",
    "    \n",
    "    return return_range\n",
    "\n",
    "\n",
    "def get_filter_quotes(DF, candidate):\n",
    "    words_list = []\n",
    "    for i, row in DF.iterrows():\n",
    "        text_norm = normalize('NFKD', row['full_text'].lower()).encode('ASCII','ignore').decode('ASCII')\n",
    "        if len(re.findall(candidate.lower(), text_norm)):        \n",
    "            words_list.append(text_norm)\n",
    "    text = ' '.join(words_list)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_quotes(DF, pattern):\n",
    "    return DF.set_index('full_text').filter(regex=pattern,axis=0).reset_index()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções necessárias por fazer todos os pre-processamentos e plotagem de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retorna a frequencia das palavras\n",
    "def freq(DF, candidate, qtd):\n",
    "    \n",
    "    text_list = []\n",
    "    words_list_count = []\n",
    "    \n",
    "    for i, row in DF.iterrows():\n",
    "        text_norm = normalize('NFKD', row['full_text'].lower()).encode('ASCII','ignore').decode('ASCII')\n",
    "        if len(re.findall(candidate.lower(), text_norm)):\n",
    "            text_list.append(text_norm)\n",
    "    text = remove_stop_words(' '.join(text_list))\n",
    "    counts = Counter(text.split())\n",
    "        \n",
    "    \n",
    "    for i, j in counts.most_common(qtd):\n",
    "        words = {}\n",
    "\n",
    "        words['words'] = i\n",
    "        words['count'] = j\n",
    "\n",
    "        words_list_count.append(words)\n",
    "        \n",
    "    d = pd.DataFrame(words_list_count)\n",
    "    \n",
    "    return d \n",
    "\n",
    "\n",
    "#Gera as hashTags mais usadas no dia, tarde, noite e madrugada.     \n",
    "def generate_hashtags_by_day(DF, show_qtd):\n",
    "    \n",
    "    hashtaglist_morning = []\n",
    "    hashtaglist_evening = []\n",
    "    hashtaglist_night = []\n",
    "    hashtaglist_dawn = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for row in range(DF.shape[0]):\n",
    "        hour = DF['hour'][row]\n",
    "        full_text = DF['full_text'][row].split()\n",
    "        \n",
    "        for words in full_text:\n",
    "            words = words.lower()\n",
    "            #Considera uma hashtag se a palavra se iniciar com #\n",
    "            if words.lower().startswith('#'):\n",
    "                #Manhã\n",
    "                if get_range_hour(hour) == 1:\n",
    "                    hashtaglist_morning.append(words)\n",
    "\n",
    "                #Tarde    \n",
    "                elif get_range_hour(hour) == 2:\n",
    "                    hashtaglist_evening.append(words)\n",
    "\n",
    "                #Noite    \n",
    "                elif get_range_hour(hour) == 3:\n",
    "                    hashtaglist_night.append(words)\n",
    "\n",
    "                #Madrugada    \n",
    "                elif get_range_hour(hour) == 4:\n",
    "                    hashtaglist_dawn.append(words)\n",
    "\n",
    "    df_morning = pd.DataFrame(columns=['turno', 'hashtags', 'freq'])\n",
    "    df_evening = pd.DataFrame(columns=['turno', 'hashtags', 'freq'])\n",
    "    df_night = pd.DataFrame(columns=['turno', 'hashtags', 'freq'])\n",
    "    df_dawn = pd.DataFrame(columns=['turno', 'hashtags', 'freq'])\n",
    "    \n",
    "       \n",
    "    \n",
    "    df_morning['hashtags'] = [i[0] for i in Counter(hashtaglist_morning).most_common(show_qtd)]\n",
    "    df_morning['freq'] = [i[1] for i in Counter(hashtaglist_morning).most_common(show_qtd)]\n",
    "    df_morning['turno'] = 'manha'\n",
    "    \n",
    "    df_evening['hashtags'] = [i[0] for i in Counter(hashtaglist_evening).most_common(show_qtd)]\n",
    "    df_evening['freq'] = [i[1] for i in Counter(hashtaglist_evening).most_common(show_qtd)]\n",
    "    df_evening['turno'] = 'tarde'\n",
    "    \n",
    "    df_night['hashtags'] = [i[0] for i in Counter(hashtaglist_night).most_common(show_qtd)]\n",
    "    df_night['freq'] = [i[1] for i in Counter(hashtaglist_night).most_common(show_qtd)]\n",
    "    df_night['turno'] = 'noite'\n",
    "    \n",
    "    df_dawn['hashtags'] = [i[0] for i in Counter(hashtaglist_dawn).most_common(show_qtd)]\n",
    "    df_dawn['freq'] = [i[1] for i in Counter(hashtaglist_dawn).most_common(show_qtd)]\n",
    "    df_dawn['turno'] = 'madrugada'\n",
    "    \n",
    "   \n",
    "    df_union = pd.concat([df_morning,\n",
    "                            df_evening,\n",
    "                            df_night ,\n",
    "                            df_dawn ])\n",
    "    \n",
    "    \n",
    "    return df_union \n",
    "\n",
    "\n",
    "\n",
    "def generate_sentences(DF, length_sentence, string_searchm, show_qtd):\n",
    "    #Negrito.\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    only_valid_words = re.compile('[A-Za-z]+: (.*)') #Apenas palavras válidas\n",
    "    w_list = []\n",
    "    sentence_list = []\n",
    "      \n",
    "    for ind, row in DF.iterrows():\n",
    "        text = row['full_text']\n",
    "        #text = remove_stop_words(text)\n",
    "        \n",
    "                \n",
    "        #Deixa a frase de maneira natural, sem acentos e busca a string informada\n",
    "        if len(re.findall(string_search, normalize('NFKD', text).encode('ASCII','ignore').decode('ASCII'))):\n",
    "            w_list.append(text)\n",
    "\n",
    "    for word in w_list:\n",
    "        for sent in nltk.sent_tokenize(word):\n",
    "            strip_speaker = only_valid_words.match(sent)\n",
    "            if strip_speaker is not None:\n",
    "                sent = strip_speaker.group(1)\n",
    "            words = nltk.word_tokenize(sent)\n",
    "            for phrase in ngrams(words, length_sentence):\n",
    "                if all(word not in string.punctuation for word in phrase): #Remove pontuações\n",
    "                    #phrase = re.sub(r'[^A-Za-z0-9]+', ' ', untokenize(phrase)) #apenas palavras válidas\n",
    "                    phrase = untokenize(phrase) #apenas palavras válidas\n",
    "                    phrase = phrase.replace('.', '').replace(\"''\", '')\n",
    "                    if phrase not in '  ':\n",
    "                        sentence_list.append(phrase)\n",
    "\n",
    "    phrase_counter = Counter(sentence_list).most_common(show_qtd)\n",
    "\n",
    "    for k,v in phrase_counter:\n",
    "        print(f'   Tamanho sequencia: {BOLD}{str(length_sentence)}{END} palavras', \n",
    "              f'   Sentenças: {BOLD}{k}{END}')\n",
    "        \n",
    "        \n",
    "        \n",
    "#Faz a contagem de todos  dispositivos onde foram feito os posts\n",
    "def count_post_by_devices(DF):\n",
    "    iphone_list = []\n",
    "    android_list = []\n",
    "    others_list = []\n",
    "    \n",
    "    for row in range(DF.shape[0]):\n",
    "\n",
    "        row = DF['source'][row].lower()\n",
    "\n",
    "        row = row.split()[-1].replace('</a>', '').replace('rel=\"nofollow\">', '')\n",
    "\n",
    "        if row == 'iphone':\n",
    "            iphone_list.append(row)\n",
    "        elif row == 'android':\n",
    "            android_list.append(row)\n",
    "        else:\n",
    "            others_list.append('others')\n",
    "\n",
    "    #Obtem a contagem das listas de cada devices\n",
    "    iphone = Counter(iphone_list)\n",
    "    android = Counter(android_list)\n",
    "    others = Counter(others_list)\n",
    "    \n",
    "       \n",
    "    \n",
    "    list_count = [iphone['iphone'], android['android'], others['others']]\n",
    "    \n",
    "    \n",
    "    d = {'list_devices': ['iphone', 'android', 'others'], \n",
    "        'count': list_count,\n",
    "        'percentage': [str(round(i / np.sum(list_count), 2) * 100) +'%' for i in list_count]}\n",
    "    \n",
    "    \n",
    "    df_return = pd.DataFrame(d)\n",
    "    return df_return\n",
    "\n",
    "\n",
    "#Faz a plotagem da contagem de dispositivos onde foram feitos os posts\n",
    "def plot_count_posts_by_devices(DF):\n",
    "    x = count_post_devices(DF)['list_devices']\n",
    "    y = count_post_devices(DF)['percentage']\n",
    "    \n",
    "    color = ['red', 'blue', 'yellow']\n",
    "    \n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "                x=x, y=y,\n",
    "                text=y,\n",
    "                textposition='auto',\n",
    "                marker_color= [c for c in color]\n",
    "            )])\n",
    "\n",
    "    fig.update_layout(title_text='PERCENTUAL DOS DISPOSITIVOS USADOS PARA OS POSTS')\n",
    "    fig.show(renderer=\"notebook\")\n",
    "    #py.iplot(fig)\n",
    "#plot_count_posts_devices(DF)\n",
    "\n",
    "\n",
    "# Faz a contagem dos dispositivos onde o usuário twitou usando algo relacionado a bolsonaro, lula \n",
    "def count_post_devices_by_candidate(DF, candidate):\n",
    "    \n",
    "    \n",
    "\n",
    "    list_data = []\n",
    "\n",
    "    \n",
    "    iphone_list = []\n",
    "    android_list = []\n",
    "    others_list = []\n",
    "    dict_count = {}\n",
    "\n",
    "    for row in range(DF.shape[0]):\n",
    "\n",
    "        if len(re.findall(candidate, normalize('NFKD', DF['full_text'][row].lower()).encode('ASCII','ignore').decode('ASCII'))):\n",
    "\n",
    "            row = DF['source'][row].lower()\n",
    "\n",
    "            row = row.split()[-1].replace('</a>', '').replace('rel=\"nofollow\">', '')\n",
    "\n",
    "            if row == 'iphone':\n",
    "                iphone_list.append(row)\n",
    "            elif row == 'android':\n",
    "                android_list.append(row)\n",
    "            else:\n",
    "                others_list.append('others')\n",
    "\n",
    "    #Obtem a contagem das listas de cada devices\n",
    "    iphone = Counter(iphone_list)\n",
    "    android = Counter(android_list)\n",
    "    others = Counter(others_list)\n",
    "\n",
    "    dict_count['candidate'] = candidate\n",
    "    dict_count['iphone'] = iphone['iphone']\n",
    "    dict_count['android'] = android['android']\n",
    "    dict_count['others'] = others['others']\n",
    "\n",
    "\n",
    "    list_data.append(dict_count)\n",
    "    \n",
    "    #Cria dataframe para posteriormente ser retornado pela função\n",
    "    d = pd.DataFrame(list_data)\n",
    "\n",
    "    #Calcula a porcentagem de cada device\n",
    "    #Calculo da porcentagem: (device / (somatorio de cada devices)) * 100\n",
    "    iphone_percentage = [str(round(i, 2) * 100) + '%' for i in (d['iphone'] / (d['iphone'] + d['android'] + d['others'])).values]\n",
    "    android_percentage = [str(round(i, 2) * 100) + '%' for i in (d['android'] / (d['iphone'] + d['android'] + d['others'])).values]\n",
    "    others_percentage = [str(round(i, 2) * 100) + '%' for i in (d['others'] / (d['iphone'] + d['android'] + d['others'])).values]\n",
    "\n",
    "    #Anexa as porcentagems no dataframe\n",
    "    d['iphone_percengate'] = iphone_percentage\n",
    "    d['android_percentage'] = android_percentage\n",
    "    d['others_percentage'] = others_percentage\n",
    "    \n",
    "    \n",
    "    d1 = d[['candidate', 'iphone', 'android', 'others']]\n",
    "    d2 = d[['candidate', 'iphone_percengate', 'android_percentage', 'others_percentage']]\n",
    "    \n",
    "    #Transoforma linhas em colunas para linhas. (UNPIVOT)\n",
    "    d1 = d1.melt(id_vars=['candidate'], var_name='list_devices', value_name='count') \n",
    "    d2 = d2.melt(id_vars=['candidate'], var_name='list_percetage', value_name='percetage') \n",
    "\n",
    "    d1['percetage'] = d2['percetage']\n",
    "    \n",
    "    return d1 \n",
    "\n",
    "# Faz a plotagem da contagem dos dispositivos onde o usuário twitou usando algo relacionado a bolsonaro, lula e dilma\n",
    "#dataFrame = count_post_devices_by_candidate(DF, 'bosonaro')\n",
    "def plot_count_posts_devices_by_candidate(df_1, df_2):\n",
    "    DF = pd.concat([df_1, df_2])\n",
    "    fig = px.bar(DF, x=\"candidate\", color=\"list_devices\",\n",
    "                 y='percetage',\n",
    "                 title=\"COMPARAÇÃO DO PERCENTUAL DOS DISPOSITIVOS ULTILIZADOS PARA AS POSTAGENS\",\n",
    "                 barmode='group',\n",
    "                 height=600\n",
    "                )\n",
    "\n",
    "    #fig.show()\n",
    "    py.iplot(fig)\n",
    "    \n",
    "#plot_count_posts_devices_by_candidate(DF)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#função responsável por buscar os top 20 verbos, adjetivos e substântivos\n",
    "def search_verb_adj_subs(DF, candidate):\n",
    "    file = open(\"POS_tagger_brill.pkl\",'rb') #Carrega modelo\n",
    "    mode_tagger = load(file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    stopWords = stopwords.words('portuguese')\n",
    "    list_alphabetic = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n",
    "                       'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', \n",
    "                       'r', 's', 't', 'u', 'v', 'x', 'z', 'ñ']\n",
    "    for i in list_alphabetic:\n",
    "        stopWords.append(i)\n",
    "\n",
    "    #Negrito.\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "    list_verb = []\n",
    "    list_adj = []\n",
    "    list_subs = [] \n",
    "    for i in range(DF.shape[0]):\n",
    "\n",
    "        phrase = DF['full_text'][i]\n",
    "        if len(re.findall(candidate, normalize('NFKD', phrase.lower()).encode('ASCII','ignore').decode('ASCII'))):\n",
    "            #verb_adj_subs = teste_tagger.tag(word_tokenize(return_text_clean(phrase, False)))\n",
    "            verb_adj_subs = mode_tagger.tag(word_tokenize(phrase))\n",
    "\n",
    "            for v in verb_adj_subs:\n",
    "                if v[1] == 'V': #Verbos\n",
    "                    list_verb.append(v[0].lower())\n",
    "                elif v[1] == 'ADJ': #Adjetivos\n",
    "                    list_adj.append(v[0].lower())\n",
    "                elif v[1] == 'N': #Substantivos \n",
    "                    word = v[0].lower()\n",
    "                    new_words = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', word, flags=re.MULTILINE).replace('http', '').replace('https', '') #Remove links\n",
    "                    new_words = re.sub(r'[^\\w]', '', new_words) #Remove espaços _ , () / \n",
    "                    if not new_words.strip() in stopWords:\n",
    "                        if not new_words in '': #Remove espaços em branco\n",
    "                            list_subs.append(new_words.strip())\n",
    "\n",
    "\n",
    "    print('TOP 20 verbos mais citados por '+candidate+'\\n')        \n",
    "    for i in Counter(list_verb).most_common(20):\n",
    "        print(f'Palavras: {BOLD}{i[0]}{END} Total citações: {BOLD}{i[1]}{END}')\n",
    "\n",
    "    print('\\n\\n')    \n",
    "    print('TOP 20 adjetivos mais citados '+candidate+'\\n')            \n",
    "    for i in Counter(list_adj).most_common(20):\n",
    "        print(f'Palavras: {BOLD}{i[0]}{END} Total citações: {BOLD}{i[1]}{END}')\n",
    "\n",
    "    print('\\n\\n')\n",
    "    print('TOP 20 substântivos mais citados '+candidate+'\\n')                \n",
    "    for i in Counter(list_subs).most_common(20):\n",
    "        print(f'Palavras: {BOLD}{i[0]}{END} Total citações: {BOLD}{i[1]}{END}')\n",
    "\n",
    "    print('\\n\\n')\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#Gera as hashTags mais usadas     \n",
    "def generate_hashtags_by_candidate(DF, candidate, show_qtd):\n",
    "\n",
    "    hashtag_list=[]\n",
    "    for row in range(DF.shape[0]):\n",
    "        hour = DF['hour'][row]\n",
    "        if len(re.findall(candidate, normalize('NFKD', DF['full_text'][row].lower()).encode('ASCII','ignore').decode('ASCII'))):        \n",
    "            full_text = DF['full_text'][row].split()\n",
    "\n",
    "            for words in full_text:\n",
    "                words = words.lower()\n",
    "\n",
    "                #Considera uma hashtag se a palavra se iniciar com #\n",
    "                if words.startswith('#'):\n",
    "                    hashtag_list.append(words.lower())\n",
    "\n",
    "\n",
    "    df_list = []\n",
    "    tamanho = np.sum([i[1] for i in Counter(hashtag_list).most_common(show_qtd)])\n",
    "    for i in Counter(hashtag_list).most_common(show_qtd):\n",
    "        df_dict = {}  \n",
    "        df_dict['hashtag'] = i[0]\n",
    "        df_dict['percentage'] = round((i[1] / tamanho) * 100, 2)\n",
    "        df_list.append(df_dict)\n",
    "\n",
    "    d = pd.DataFrame(df_list)\n",
    "    return d\n",
    "\n",
    "\n",
    "#df = freq(DF, 'lula', 20).sort_values(by=['count'])\n",
    "#Retorna grafico de barras horizontal exemplo: x['count'], y['words']\n",
    "def plot_bar_chart_horizontal(df_x, df_y):\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "                x=df_x,\n",
    "                y=df_y, \n",
    "                marker=dict(\n",
    "                color= 'rgba(50, 171, 96, 0.6)'),\n",
    "                orientation='h'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"FREQUENCIA DE PALAVRAS\",\n",
    "        xaxis_title=\"COUNT\",\n",
    "        yaxis_title=\"TERMS\"\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.show(renderer=\"notebook\")\n",
    "    #py.iplot(fig)\n",
    "    \n",
    "#df = generate_hashtags_by_candidate(DF, 'lula', 10).sort_values(by='percentage')\n",
    "#plot_bar_chart_horizontal(df['percentage'], df['hashtag'])            \n",
    "\n",
    "\n",
    "#Retorna a quantidade total de retweets e favoritos\n",
    "def return_sum_ret_favorite_by_candidate(DF, candidate):\n",
    "    #candidates = ['bolsonaro', 'lula', 'dilma']\n",
    "\n",
    "    ret_fav_count = {}\n",
    "\n",
    "    list_data = []\n",
    "\n",
    "    #for candidate in candidates:\n",
    "\n",
    "    for row in range(DF.shape[0]):\n",
    "        text_norm = normalize('NFKD', DF['full_text'][row].lower()).encode('ASCII','ignore').decode('ASCII')\n",
    "        if len(re.findall(candidate.lower(), text_norm)):\n",
    "            retweet = DF['retweet_count'][row]\n",
    "            favorite = DF['favorite_count'][row]\n",
    "            ret_fav_count = {'candidate': candidate, 'retweet_count':retweet, 'favorite_count': favorite}\n",
    "            list_data.append(ret_fav_count)\n",
    "\n",
    "    d = pd.DataFrame(list_data)\n",
    "\n",
    "    return d.groupby('candidate').sum().reset_index()\n",
    "\n",
    "# plota retweets por canditatos\n",
    "def plot_pie_chart_ret(DF1, DF2, DF3):\n",
    "    df = pd.concat([DF1, DF2, DF3])\n",
    "    fig = px.pie(df, values='retweet_count', names='candidate', title='PERCENTUAL DE RETWEETS DE COMENTÁRIOS DOS CANDIDATOS BOLSONARO, LULA E DILMA')\n",
    "    #fig.show()\n",
    "    py.iplot(fig)\n",
    "    \n",
    "# plota favoritos por canditatos    \n",
    "def plot_pie_chart_fav(DF1, DF2, DF3):\n",
    "    \n",
    "    df = pd.concat([DF1, DF2, DF3])\n",
    "    fig = px.pie(df, values='favorite_count', names='candidate', title='PERCENTUAL DE FAVORITES DE COMENTÁRIOS DOS CANDIDATOS BOLSONARO, LULA E DILMA')\n",
    "    #fig.show()    \n",
    "    py.iplot(fig)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#plota word_cloud     \n",
    "def plot_word_cloud(text, max_words=100):\n",
    "    mask = np.array(Image.open('tweet-image.png'))\n",
    "    wc = WordCloud(\n",
    "                   font_path='font-serious.ttf', mask=mask, background_color=\"black\",\n",
    "                   max_words=max_words, max_font_size=256,\n",
    "                   random_state=42, width=mask.shape[1],\n",
    "                   height=mask.shape[0])\n",
    "    wc.generate(remove_stop_words(remove_stop_words(text)))\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "\n",
    "#plot_word_cloud(get_filter_quotes(DF, 'bolsonaro'))    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_tweets_by_candidate(DF, candidate):\n",
    "    list_data = []\n",
    "    for row in range(DF.shape[0]):\n",
    "        df_dict = {}\n",
    "        #Remove acentos e busca a string desejada no texto\n",
    "        if len(re.findall(candidate.lower(), normalize('NFKD', DF['full_text'][row].lower()).encode('ASCII','ignore').decode('ASCII'))):        \n",
    "            tweets = DF['full_text'][row]\n",
    "            hour = DF['hour'][row]\n",
    "            year = DF['year'][row]\n",
    "            df_dict['tweets'] = tweets\n",
    "            df_dict['year'] = year \n",
    "            df_dict['hour'] = hour #hour[:-6]\n",
    "            list_data.append(df_dict)\n",
    "    d = pd.DataFrame(list_data)\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "def plot_count_tweets(DF, search):\n",
    "    list_data = []\n",
    "    for row in range(DF.shape[0]):\n",
    "        df_dict = {}\n",
    "        \n",
    "         \n",
    "        \n",
    "        total_tweets = DF['full_text'][row]\n",
    "        year = DF['year'][row]\n",
    "        month = DF['month'][row]\n",
    "        hour = DF['hour'][row]\n",
    "        \n",
    "        day  = DF['day'][row]\n",
    "        df_dict['total_tweets'] = total_tweets\n",
    "        df_dict['year'] = year \n",
    "        df_dict['month'] = month \n",
    "        df_dict['day'] = day\n",
    "        df_dict['hour'] = hour[:-6]\n",
    "        \n",
    "        list_data.append(df_dict)\n",
    "    d = pd.DataFrame(list_data)\n",
    "    search = search.lower()\n",
    "    \n",
    "    df = d[['total_tweets', search]].groupby(search).count().reset_index() \n",
    "    \n",
    "    \n",
    "    fig = px.line(df, x=search, y=\"total_tweets\", title='SÉRIE TEMPORAL TWEETS POR '+search.upper())\n",
    "    #fig.show()\n",
    "    py.iplot(fig)\n",
    "    \n",
    "    \n",
    "#generate_hashtags_by_candidate(DF, 'dilma', 10)\n",
    "#df_x = generate_hashtags_by_candidate(DF, 'lula', 10)['percentage'].sort_values()\n",
    "#df_y = generate_hashtags_by_candidate(DF, 'lula', 10)['hashtag']\n",
    "\n",
    "def plot_hashtags(df_x, df_y, candidate):\n",
    "    fig = go.Figure(go.Bar(\n",
    "                    x=df_x,\n",
    "                    y=df_y, \n",
    "                    marker=dict(\n",
    "                    color= 'rgba(50, 150, 200, 0.6)'),\n",
    "                    orientation='h'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"HASHTAGS MAIS UTILIZADAS POR \"+candidate.upper(),\n",
    "        xaxis_title=\"PERCENTAGE\",\n",
    "        yaxis_title=\"HASHTAGS\"\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.show(renderer=\"notebook\")\n",
    "    #py.iplot(fig)\n",
    "           \n",
    "    \n",
    "    \n",
    "def search_tweets_shift_by_candidate(DF, candidate):\n",
    "    morning = []\n",
    "    evening = []\n",
    "    night = []\n",
    "    dawn = []\n",
    "\n",
    "    for ind, row in DF.iterrows():\n",
    "        hour = row['hour']\n",
    "\n",
    "\n",
    "        #Manhã\n",
    "        if get_range_hour(hour) == 1:\n",
    "            morning.append(ind)\n",
    "\n",
    "        #Tarde    \n",
    "        elif get_range_hour(hour) == 2:\n",
    "            evening.append(ind)\n",
    "\n",
    "        #Noite    \n",
    "        elif get_range_hour(hour) == 3:\n",
    "            night.append(ind)\n",
    "\n",
    "        #Madrugada    \n",
    "        elif get_range_hour(hour) == 4:\n",
    "            dawn.append(ind)\n",
    "\n",
    "    df_dict = {}\n",
    "    df_dict['Manha'] = len(morning)\n",
    "    df_dict['Tarde'] = len(evening)\n",
    "    df_dict['Noite'] = len(night)\n",
    "    df_dict['Madrugada'] = len(dawn)\n",
    "\n",
    "    #d = {'candidate': candidate, 'Manha': len(morning), 'Tarde': len(evening), 'Noite': len(night), 'Madrugada': len(dawn)}\n",
    "    d1 = pd.DataFrame(df_dict.items(), columns=['shift', 'total_tweets'])\n",
    "    d1['candidate'] = candidate\n",
    "    return d1 \n",
    "\n",
    "\n",
    "def plot_count_tweets_by_shift(DF1, DF2):\n",
    "    df = pd.concat([DF1, DF2])\n",
    "    fig = px.line(df, x='shift', y=\"total_tweets\", color='candidate', title='SÉRIE TEMPORAL TWEETS POR TURNO')\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def get_quotes_by_year_month(DF, candidate):\n",
    "    list_df = []\n",
    "    for i, row in DF.iterrows():\n",
    "        dict_df = {}\n",
    "        text_norm = normalize('NFKD', row['full_text'].lower()).encode('ASCII','ignore').decode('ASCII')\n",
    "        year =  row['year']\n",
    "        month = row['month']\n",
    "        if len(re.findall(candidate, text_norm)):\n",
    "            dict_df['full_text'] = text_norm \n",
    "            dict_df['year_month'] = year +'-'+month\n",
    "            list_df.append(dict_df)\n",
    "    d = pd.DataFrame(list_df)\n",
    "    return d \n",
    "\n",
    "def quotes_groupby_year_month(quotes):\n",
    "    quotes_groupby = quotes.groupby(['year_month']).count().reset_index()\n",
    "    \n",
    "    return quotes_groupby    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTADOS\n",
    "<!--<h1>## 2.  METODOLOGIA</h1><br>\n",
    "<ol>-->\n",
    "<!--<li>Bolsonaro</li>\n",
    "<li>Dilma</li>\n",
    "<li>Lula</li>\n",
    "</ol>-->\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bolsonaro</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(get_filter_quotes(DF, 'bolsonaro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 1*: Podemos observar que ele comenta bastante sobre a esquerda, o PSOL (Partido Socialismo e\n",
    "Liberdade) e PT (Partido dos trabalhadores). Supõe-se que ele pauta bastante o seu posicionamento como\n",
    "contrário à esquerda, e é emblemático que a palavra \"contra\" também esteja em evidência.\n",
    "Também podemos localizar palavras relacionadas as pautas que o mesmo defende, como: Familia, economia, combate a corrução. A seguir, reproduzimos o gráfico de palavras mais frequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot as 20 palavras mais citadas\n",
    "df = freq(DF, 'bolsonaro', 20).sort_values(by=['count'])\n",
    "plot_bar_chart_horizontal(df['count'], df['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 2*: Aqui, é possível ver que a sigla PT está no segundo lugar de palavras mais mencionadas por Jair Bolsonaro - ficando atrás de Brasil, enfatizando mais ainda a polarização política. É interessante notar que o deputado\n",
    "fala bastante em \"familia\", deixando mais claro seu lado conservador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lula</h2>   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(get_filter_quotes(DF_LULA, 'lula'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 3*: Podemos observar que a palavra *PAI* pode está dando uma referência a expressão *PAI DOS POBRES*, expressão essa, bastante utilizada pelos eleitores do lula. Logo em seguida, podemos também observar a expressão *LULALIVRE*, expressa que foi bastante utilizada em hashtags, na época em que lula foi preso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot as 20 palavras mais citadas\n",
    "df = freq(DF_LULA, 'lula', 20).sort_values(by=['count'])\n",
    "plot_bar_chart_horizontal(df['count'], df['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 4*: *LULAPELOBRASIL*, palavra essa que faz referência a caravana para impulsionar a sua então candidatura em 2018. Outro ponto importante é a expressão *LULAPORMINASGERAIS*, que teve um fato histórico bastante ruim para o ex-presidente.\n",
    "Acusmado a arrastar multidões em andanças pelo Pais, o oetista leva pouca gente no périplo pelo interior de minas Gerais e é recebido com vaias e testemunha de perto e a olho nu, a melancólica degeneração de seu poderio politico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dilma</h2>   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(get_filter_quotes(DF_LULA, 'Dilma'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 5*: Expressões com terminologias 'COMDILMA', exemplo: 'PERIFEIRACOMDILMA', 'RETAFINALCOMDILMA', denotam um forte apoio por parte dos eleitores, em 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot as 20 palavras mais citadas\n",
    "df = freq(DF_LULA, 'dilma', 20).sort_values(by=['count'])\n",
    "plot_bar_chart_horizontal(df['count'], df['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fig. 5*: Pelo o histórico do PT, é facil perceber que a maioria de seus eleitores são do nordeste, isso porque ao longo do tempo, o PT soube cativar esse eleitorado, facilitando a vida dos mesmos. Pela expressão *pecomdilmaelula*, claramente podemos notar isso, o apoio do nordeste em peso para candidatura da Dilma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = generate_hashtags_by_candidate(DF, 'lula', 10)['percentage'].sort_values()\n",
    "df_y = generate_hashtags_by_candidate(DF, 'lula', 10)['hashtag']    \n",
    "plot_hashtags(df_x, df_y, 'bolsonaro')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 6*: Através desse gráfico, é possivel perceber as hashtags mais utilizadas pelos eleitores de Jair Bolsonaro para atacar o ex-presidente Lula. Nele, podemos ver a hashtag **#lulapresidiário** e **#lulanacadeia**, hashtags que fazem menção a época em que o ex-presidente Lula estava prestes a ser preso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = generate_hashtags_by_candidate(DF_LULA, 'bolsonaro', 10)['percentage'].sort_values()\n",
    "df_y = generate_hashtags_by_candidate(DF_LULA, 'bolsonaro', 10)['hashtag']    \n",
    "plot_hashtags(df_x, df_y, 'lula')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 7*: Pecebemos nesse gráfico, duas hashtags de ataque ao candidato Bolsonaro, são elas: **#bolsofake** e **caixa2dobolsonaro**(Que sugere ser uma denuncia que envolveu o candidato a presidente Jair Bolsonaro e seu futuro ministro Marcelo Alvaro Antônio). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_fav_bolso = return_sum_ret_favorite_by_candidate(DF, 'BOLSONARO')\n",
    "ret_fav_lula = return_sum_ret_favorite_by_candidate(DF_LULA, 'LULA')\n",
    "ret_fav_dilma = return_sum_ret_favorite_by_candidate(DF_LULA, 'DILMA')\n",
    "\n",
    "\n",
    "plot_pie_chart_fav(ret_fav_bolso, ret_fav_lula, ret_fav_dilma)\n",
    "plot_pie_chart_ret(ret_fav_bolso, ret_fav_lula, ret_fav_dilma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 8 e 9*: Através desses dois gráficos, é possível perceber os candidatos que mais tem engajamento em seus tweets e em seus comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = count_post_devices_by_candidate(DF, 'bolsonaro')\n",
    "df_2 = count_post_devices_by_candidate(DF_LULA, 'lula')\n",
    "plot_count_posts_devices_by_candidate(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 10*: Podemos observar que para os tweets de Jair Bolsonaro, 75% das postagens vem de iphone, em contrapartida, os do lula, vem de outros dispositivos. Será que podemos deduzir que os eleitores de bolsonaro tem uma classe social mais elevada do que os eleitores de lula e portando os mesmos tem condições de comprar um iphone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que horas turno do dia os eleitores do bolsonaro, lula e dilma, tem mais atividades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolso = search_tweets_shift_by_candidate(DF, 'bolsonaro')\n",
    "lula = search_tweets_shift_by_candidate(DF_LULA, 'lula')\n",
    "\n",
    "plot_count_tweets_by_shift(bolso, lula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 11*: Nesse gráfico é facil observar que Bolsonaro e Lula tem uma maior interação entre o turno da tarde e noite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolso = quotes_groupby_year_month(get_quotes_by_year_month(DF, 'lula'))\n",
    "lula = quotes_groupby_year_month(get_quotes_by_year_month(DF_LULA, 'bolsonaro'))\n",
    "#bolso['candidate'] = 'bolsonaro'\n",
    "#lula['candidate'] = 'lula'\n",
    "#df_lula_bolso = pd.concat([bolso, lula])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "#citacoes_agrupada_por_ano_mes\n",
    "ax.bar(bolso['year_month'], bolso['full_text'],\n",
    "       label='Bolsonaro citando Lula',color='green')\n",
    "\n",
    "\n",
    "#citacoes_agrupada_por_ano_mes\n",
    "ax.bar(lula['year_month'], lula['full_text'],\n",
    "       label='Lula citando Bolsonaro',color='red')\n",
    "\n",
    "ax.set_ylabel(\"Citações por candidato\")\n",
    "plt.xticks(rotation=90)\n",
    "ax.legend()\n",
    "#plt.grid(False)\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 12*: No gráfico acima, em destaque está o mês 10 de 2018, mês na qual lula mais citou bolsonaro. Vamos verificar elencar quais foram essas citações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotes_bolso = get_quotes_by_year_month(DF_LULA, 'bolsonaro')\n",
    "for i, row in df_quotes_bolso[df_quotes_bolso['year_month'] == '2018-10'].head(10).iterrows():\n",
    "    print(row['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possivel observar que a maioria dos tweets retratam o medo dos eleitores de lula em relação algumas paltas que o Bolsonaro defende, as privatizações e a reforma da previdência, reforma essa que o seu futuro ministro Paulo Guedes tãnto defende, que é o regime de captalização.\n",
    "\n",
    "O medo também refere-se a Bolsonaro defender tanto a tortura e a ditadura do exército."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotes_lula = get_quotes_by_year_month(DF, 'lula')\n",
    "for i, row in df_quotes_lula[df_quotes_lula['year_month'] == '2016-09'].head(10).iterrows():\n",
    "    print(row['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas citações de Bolsonaro para com Lula, os eleitores de Bolsonaro deixa bem claro os crimes na qual Lula foi associado, como o petrolão e mensalão.\n",
    "\n",
    "Aqui é possivel ver uma breve comparação que um eleitor faz: **\"lula se torna reu na lava jato (desvio de dinheiro). bolsonaro e reu por responder a uma calunia. a diferenca entre esquerda e direita!\"**. Aqui podemos observar que o eleitor associa toda a \"ESQUEDA\" a corrução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbos, adjetivos e substântivos mais ultilizados nas citações.\n",
    "\n",
    "*  Foi utilizado um modelo já treinado em cima do conjunto de dados Mac-Morpho, que é composto de sentenças com as POS taggeadas. O modelo treinado obteve uma acurácia de 98.19% e que o mesmo está disponibilizado no github: https://github.com/inoueMashuu/POS-tagger-portuguese-nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_verb_adj_subs(DF, 'lula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_verb_adj_subs(DF_LULA, 'bolsonaro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de analise de sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset de treinamento \n",
    "* Foi utilizado um dataset de tweets de politicos já rotulado com as seguintes classes: Positivo, Neutro e Negativo\n",
    "* link do dataset: https://www.kaggle.com/leandrodoze/tweets-from-mgbr?select=Tweets_Mg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando o Dataset.\n",
    "df = pd.read_csv('Tweets_Mg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda os tweets e as classes em uma variável para posteriormente treinar o modelo.\n",
    "x_train = df[\"Text\"].values\n",
    "classes = df[\"Classificacao\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Antes de começar o treinamento de fato, temos que entender o que é *Bag of Words*. \n",
    "* Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base,\n",
    "  depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então\n",
    "  classificar/treinar o modelo\n",
    "  \n",
    "*  Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na\n",
    "   frequência de suas palavras:\n",
    "   - {0,3,2,0,0,1,0,0,0,1, Positivo}\n",
    "   - {0,0,1,0,0,1,0,1,0,0, Negativo}\n",
    "   - {0,1,1,0,0,1,0,0,0,0, Neutro}\n",
    "   \n",
    "*  Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior\n",
    "   peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n",
    "*  A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário,\n",
    "   e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando o modelo.\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "freq_tweets = vectorizer.fit_transform(x_train)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"Esse governo está no início, vamos ver o que vai dar\",\n",
    "          \"Estou muito feliz com o governo de São Paulo esse ano\",\n",
    "          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n",
    "          \"A segurança desse país está deixando a desejar\",\n",
    "          \"O governador de Minas é do PT\",\n",
    "          \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n",
    "\n",
    "freq_tests = vectorizer.transform(x_test)\n",
    "model.predict(freq_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Avaliando o modelo \n",
    "* As métricas utilizadas foram: \n",
    "  - Cross validation: Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1.\n",
    "  - Acurácia: É basicamente o número de acertos (positivos) divido pelo número total de exemplos.\n",
    "  - Precisão: Usada em uma situação em que os Falsos Positivos são considerados mais prejudiciais que os Falsos Negativos.\n",
    "  - F1-Score: É simplesmente uma maneira de observar somente 1 métrica ao invés de duas (precisão e recall) em alguma situação. É uma média harmônica entre as duas, que está muito mais próxima dos menores valores do que uma média aritmética simples. Ou seja, quando tem-se um F1-Score baixo, é um indicativo de que ou a precisão ou o recall está baixo.\n",
    "  - Recall: Pode ser usada em uma situação em que os Falsos Negativos são considerados mais prejudiciais que os Falsos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "results = cross_val_predict(model, freq_tweets, classes, cv = 10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acurácia\n",
    "metrics.accuracy_score(classes, resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [\"Positivo\", \"Negativo\", \"Neutro\"]\n",
    "print(metrics.classification_report(classes, results, sentiments))\n",
    "\n",
    "# Lembrando que:\n",
    "#    : precision = true positive / (true positive + false positive)\n",
    "#    : recall    = true positive / (true positive + false negative)\n",
    "#    : f1-score  = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(classes, results)\n",
    "fig, ax = plt.subplots(figsize=(10,7)) \n",
    "sns.heatmap(cm, linewidths=1, annot=True, ax=ax, fmt='g', cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "ax.set_xlabel('Predict Label', fontsize=16)\n",
    "ax.set_ylabel('True Label', fontsize=16)\n",
    "ax.set_title('Matriz de Confusão', fontsize=18)\n",
    "ax.xaxis.set_ticklabels(['Positivo', 'Neutro', 'Negativo'])\n",
    "ax.yaxis.set_ticklabels(['Positivo', 'Neutro', 'Negativo'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 13*: Matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Lembrando que:\n",
    "   - Predict Label = O que o programa classificou como Negativo, Neutro, Positivo e All\n",
    "   - True Label    = O que é de fato Negativo, Neutro, Positivo e All\n",
    "#### Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. Já os positivos que o programa classificou como negativos foram 45, muito mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testando o modelo com os Tweets de Bolsonaro e Lula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citações de lula para bolsonaro \n",
    "x_lula =  get_quotes_by_year_month(DF_LULA, 'bolsonaro')['full_text']\n",
    "#x_lula = [cleaner(row) for ind, row in get_quotes_by_year_month(DF_LULA, 'bolsonaro')['full_text'].iteritems()]\n",
    "tweets = vectorizer.transform(x_lula)\n",
    "y = model.predict(tweets)\n",
    "d_lula = pd.DataFrame([x_lula, y]).T\n",
    "d_lula = d_lula.rename({'full_text': 'total_tweets', 'Unnamed 0': 'classification'}, axis=1)\n",
    "\n",
    "d1 = d_lula.groupby('classification').count().reset_index()\n",
    "d1['candidate'] = 'lula citando bolsonaro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citações de bolsonaro para Lula\n",
    "x_bolso =  get_quotes_by_year_month(DF, 'lula')['full_text']\n",
    "#x_bolso = [cleaner(row) for ind, row in get_quotes_by_year_month(DF, 'lula')['full_text'].iteritems()]\n",
    "tweets = vectorizer.transform(x_bolso)\n",
    "y = model.predict(tweets)\n",
    "d_bolso = pd.DataFrame([x_bolso, y]).T\n",
    "d_bolso = d_bolso.rename({'full_text': 'total_tweets', 'Unnamed 0': 'classification'}, axis=1)\n",
    "d2 = d_bolso.groupby('classification').count().reset_index()\n",
    "d2['candidate'] = 'bolsonaro citando lula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = pd.concat([d1, d2])\n",
    "\n",
    "fig = px.bar(d3, x=\"classification\", y=\"total_tweets\", color=\"candidate\", title=\"\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fig 14*: Podemos observar no gráfico que, os tweets de polaridade \"Neutra\" se destaca em relação aos tweets de outras polaridades e equanto os tweets \"Positivos\" estão acima dos \"negativos\" que no meu ponto de vista não faz sentido, visto que estamos buscando citações de um candidato no tweeter de um outro candidato. Isso está ocorrendo pelo fato do modelo não está bem ajustado para novas palavras. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  CONSIDERAÇÕES FINAIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essa análise, é possível enxergar de forma clara que a construção retórica de bolsonaro está\n",
    "voltada especialmente para criticar a esquerda: \"Dilma\", \"Lula\", \"PT\" e \"PSOL\" estão sempre entre as\n",
    "palavras mais frequentes. Também é interessante notar que apesar de ser um grupo que pede\n",
    "o retorno da ditadura militar e que o trabalho de Jair Bolsonaro na Câmara dos Deputados sempre foi voltado para o fortalecimento da carreira militar, palavras relacionadas a esse tema são pouco\n",
    "centrais nas nuvens - com exceção de Flávio, que menciona a PM com frequência.\n",
    "\n",
    "\n",
    "Um fenômeno curioso é o fato de que o PSOL, um partido com apenas 6 deputados federais e\n",
    "que nunca esteve no governo, receba tanta atenção desse grupo, mais atenção do que o\n",
    "próprio PT. O fato de estarem no espectro oposto do campo ideológico deles, mais à esquerda,\n",
    "e de serem uma força de oposição na base do Rio de Janeiro os colocam em embate\n",
    "constante. Na internet, especialmente, esse tipo de oposição tende a ganhar um nível maior, de\n",
    "luta entre lados opostos.\n",
    "\n",
    "\n",
    "\n",
    "O mundo virtual permitiu que discursos como o de Bolsonaro ganhassem maior repercussão entre o\n",
    "público. Por esse motivo, compreender de que forma esses atores se comportam nas redes\n",
    "sociais é uma maneira interessante de acessar a retórica empregada para angariar apoio. O\n",
    "virtual é cada vez mais presente na formação de ideias e de posicionamentos políticos.\n",
    "\n",
    "\n",
    "Por fim, ressaltamos a importância de se trabalhar com mineração de dados no campo da\n",
    "análise política. Esse tipo de abordagem permite enriquecer os estudos e fornecer ferramentas\n",
    "livres e replicáveis. Além disso, a possibilidade de acessar o conteúdo das redes sociais\n",
    "possibilita a construção de novas e interessantes questões de pesquisa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Sentiment Analysis using Python\n",
    ".GeeksForGeeks. Disponível em: <https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/>. Acesso em: 15 fev. 2021. \n",
    "\n",
    "\n",
    "POS-tagger-portuguese-nltk.GitHub. Disponível em: <https://github.com/inoueMashuu/POS-tagger-portuguese-nltk>. Acesso em: 12  fev. 2021. \n",
    "\n",
    "\n",
    "Step by Step: Twitter Sentiment Analysis in Python.Towards Data Science. Disponível em: <https://towardsdatascience.com/step-by-step-twitter-sentiment-analysis-in-python-d6f650ade58d>. Acesso em: 11 fev. 2021. \n",
    "\n",
    "\n",
    "Bar Charts in Python.Plotly. Disponível em: <https://plotly.com/python/bar-charts/>. Acesso em: 10 fev. 2021.\n",
    "\n",
    "\n",
    "Line Charts in Python.Plotly. Disponível em: <https://plotly.com/python/line-charts/>. Acesso em: 10 fev. 2021. \n",
    "\n",
    "\n",
    "Examples for Portuguese Processing.NLTK. Disponível em: <http://www.nltk.org/howto/portuguese_en.html>. Acesso em: 09 fev. 2021. \n",
    "\n",
    "\n",
    "Pandas.Pandas. Disponível em: <https://pandas.pydata.org/>. Acesso em: 08 fev. 2021. \n",
    "\n",
    "\n",
    "Worcloud.PyPi. Disponível em: <https://pypi.org/project/wordcloud/>. Acesso em: 07 fev. 2021. \n",
    "\n",
    "\n",
    "Carvalho, João Soares, *Métodos para Análise de Sentimentos no Twitter*. 2018. 20f. Trabalho conclusão de curso – Universidade de Minas Gerais, Minas Gerais, 2018\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
