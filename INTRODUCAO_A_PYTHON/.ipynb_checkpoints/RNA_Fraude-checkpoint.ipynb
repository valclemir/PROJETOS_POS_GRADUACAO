{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Supervisionado Utilizando Rede Neural do Pilar Fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passos realizados nessa análise:\n",
    "* Importação das bibliotecas\n",
    "* Leitura dos dados\n",
    "* Normalização dos dados\n",
    "* Treinamento da Rede Neural\n",
    "* Predição dos dados\n",
    "* Visualização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cx_Oracle\n",
    "import random \n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyexcelerate import Workbook\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, concatenate\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit modelo no dataset\n",
    "def fit_model(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    # Initial layer\n",
    "    model.add(Dense(units=100, input_shape=(37,), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Hidden layer\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Hidden layer\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(x_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_all_models_members(n_models):\n",
    "    all_models = []\n",
    "    for i in range(n_models):\n",
    "        model = Sequential()\n",
    "        # Initial layer\n",
    "        model.add(Dense(units=100, input_shape=(37,), activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        # Hidden layer\n",
    "        model.add(Dense(units=100, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        # Hidden layer\n",
    "        model.add(Dense(units=50, activation='relu'))\n",
    "        # Output layer\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Define filename for this ensemble\n",
    "        filename = 'model\\modelo_rede_especialista_{}.h5'.format(i+1)\n",
    "        model.load_weights(filename)\n",
    "\n",
    "        # Add to list of members\n",
    "        all_models.append(model)\n",
    "\n",
    "    return all_models\n",
    "\n",
    "# Defines the final model using the members' models as input\n",
    "def define_decisor_model(members):\n",
    "    # Blocks all layers on all models from being trained\n",
    "    for model in members:\n",
    "        for layer in model.layers:\n",
    "            # Make not trainable\n",
    "            layer.trainable = False\n",
    "            # Rename to avoid 'unique layer name' issue\n",
    "            #layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "    # Define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # Concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = Dense(100, activation='relu')(merge)\n",
    "    output = Dense(3, activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "    #model.summary()\n",
    "    # Plot graph of ensemble\n",
    "    #plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Fit the final model\n",
    "def fit_decisor_model(model, X_input, Y_input):\n",
    "    # Prrepare input data\n",
    "    X = [X_input for _ in range(len(model.input))]\n",
    "    # Encode output data\n",
    "    Y_input_cat = to_categorical(Y_input)\n",
    "    # Fit model\n",
    "    model.fit(X, Y_input_cat, epochs=100, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Make a prediction with a stacked model\n",
    "def predict_decisor_model(model, X_input):\n",
    "    # Prepare input data\n",
    "    X = [X_input for _ in range(len(model.input))]\n",
    "    # Make prediction\n",
    "    return model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_data(df):\n",
    " \n",
    "    aux = df['CLASSE'].value_counts()\n",
    "    max_ = max(aux.values)\n",
    "    values = max_ - aux.values\n",
    "    riscos = list(aux.index)\n",
    " \n",
    "    for i in range(len(riscos)):\n",
    "        sample = df.loc[df['CLASSE'] == riscos[i]]\n",
    "        sample = resample(sample, replace=True, n_samples=values[i], random_state=123)\n",
    "        df = pd.concat([df, sample])\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6be90e1149df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CLUSTERIZACAO_PILAR_FRAUDE_GERAL_20210218.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('CLUSTERIZACAO_PILAR_FRAUDE_GERAL_20210218.xlsx') \n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14217, 37)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_save = df.copy()\n",
    "\n",
    "cds_moderados = [\n",
    "    'ARB001'\n",
    "    ,'366640'\n",
    "    ,'415682'\n",
    "    ,'BZN401'\n",
    "    ,'367712'\n",
    "    ,'396188'\n",
    "    ,'406547'\n",
    "    ,'PKU003'\n",
    "    ,'405668'\n",
    "    ,'402781'\n",
    "    ,'402502'\n",
    "    ,'BSB002'\n",
    "    ,'410714'\n",
    "    ,'405377'\n",
    "    ,'384284'\n",
    "    ,'332492'\n",
    "    ,'387262'\n",
    "    ,'412945'\n",
    "    ,'369877'\n",
    "    ,'382774'\n",
    "    ,'389192'\n",
    "    ,'373375'\n",
    "    ,'381313'\n",
    "    ,'368735'\n",
    "    ,'318764'\n",
    "    ,'330358'\n",
    "    ,'409927'\n",
    "    ,'408870'\n",
    "    ,'399430'\n",
    "    ,'389575'\n",
    "    ,'328856'\n",
    "    ,'403485'\n",
    "    ,'337020'\n",
    "    ,'363725'\n",
    "    ,'382175'\n",
    "    ,'ESP401'\n",
    "    ,'357978'\n",
    "    ,'381696'\n",
    "    ,'401989'\n",
    "    ,'394372'\n",
    "    ,'PSC001'\n",
    "    ,'392709'\n",
    "    ,'377857'\n",
    "    ,'368220'\n",
    "    ,'405690'\n",
    "    ,'389863'\n",
    "    ,'394643'\n",
    "    ,'396054'\n",
    "    ,'358432'\n",
    "    ,'396529'\n",
    "    ,'401421'\n",
    "    ,'WAU301'\n",
    "    ,'408029'\n",
    "    ,'400714'\n",
    "    ,'349883'\n",
    "    ,'380546'\n",
    "    ,'403853'\n",
    "    ,'375791'\n",
    "    ,'300624'\n",
    "    ,'347717'\n",
    "    ,'399624'\n",
    "    ,'383437'\n",
    "    ,'393310'\n",
    "    ,'410556'\n",
    "    ,'391645'\n",
    "    ,'401980'\n",
    "    ,'338664'\n",
    "    ,'358084'\n",
    "    ,'384645'\n",
    "    ,'392040'\n",
    "    ,'414591'\n",
    "    ,'399985'\n",
    "    ,'391746'\n",
    "    ,'416356'\n",
    "    ,'368735'\n",
    "    ,'386032'\n",
    "    ,'315549'\n",
    "    ,'314744'\n",
    "    ,'365478'\n",
    "    ,'403320'\n",
    "    ,'403081'\n",
    "    ,'390943'\n",
    "    ,'380989'\n",
    "    ,'364214'\n",
    "    ,'390856'\n",
    "]\n",
    "\n",
    "\n",
    "#Transforma moderado em alto\n",
    "df.loc[(df['CD_CIR_DENTISTA'].isin(cds_moderados)) & (df['CLASSE'] == 'Moderado'), 'CLASSE'] = 'Alto'\n",
    "\n",
    "#df = X_save        \n",
    "df_alto = df[df['CLASSE'] == 'Alto']\n",
    "df_baixo = df[df['CLASSE'] == 'Baixo'].head(df_alto.shape[0])\n",
    "df_moderado = df[df['CLASSE'] == 'Moderado'].head(df_alto.shape[0])\n",
    "\n",
    "\n",
    "df = pd.concat([df_baixo, df_moderado, df_alto])\n",
    "\n",
    "y = df['CLASSE']\n",
    "df = df.drop(['CD_CIR_DENTISTA', 'CD_ESPECIALIDADE', 'CLASSE', 'NM_UNIDADE', 'FAIXA_POPULACAO'], axis=1)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_MD_BENE_DOS_PARES_NO_MS</th>\n",
       "      <th>QT_FRAGMENTACAO_DE_EVENTOS</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_MES</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>2510.875000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>30.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.868129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>403485</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2917</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.600000</td>\n",
       "      <td>1143.410000</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>13.840000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.715065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313914</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>300624</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120.700000</td>\n",
       "      <td>3031.835000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>66.119000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.868129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>337020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6234</td>\n",
       "      <td>49</td>\n",
       "      <td>807.35</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>559.300000</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.715065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290017</td>\n",
       "      <td>0.290018</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>414591</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>3327.930000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>194.327500</td>\n",
       "      <td>...</td>\n",
       "      <td>72.868129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356025</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>363725</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152016</td>\n",
       "      <td>94</td>\n",
       "      <td>1750.28</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>453.063333</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.715065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.337913</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>410714</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152763</td>\n",
       "      <td>38</td>\n",
       "      <td>805.60</td>\n",
       "      <td>112.222222</td>\n",
       "      <td>2392.375556</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>1</td>\n",
       "      <td>21.20</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>119.813333</td>\n",
       "      <td>...</td>\n",
       "      <td>72.868129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326154</td>\n",
       "      <td>0.326497</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>364214</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.200000</td>\n",
       "      <td>3070.236000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.868129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452016</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>390856</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153230</td>\n",
       "      <td>34</td>\n",
       "      <td>545.70</td>\n",
       "      <td>38.083333</td>\n",
       "      <td>613.657500</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>16.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.715065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291289</td>\n",
       "      <td>0.291166</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>392709</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153365</td>\n",
       "      <td>118</td>\n",
       "      <td>1473.16</td>\n",
       "      <td>151.416667</td>\n",
       "      <td>1864.677500</td>\n",
       "      <td>22.828325</td>\n",
       "      <td>360.748316</td>\n",
       "      <td>4</td>\n",
       "      <td>47.32</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>69.935000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.858542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313681</td>\n",
       "      <td>0.311043</td>\n",
       "      <td>0.402894</td>\n",
       "      <td>ARB001</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "1919                          0                     0.00   \n",
       "2917                          0                     0.00   \n",
       "4895                          0                     0.00   \n",
       "6234                         49                   807.35   \n",
       "7946                          0                     0.00   \n",
       "...                         ...                      ...   \n",
       "152016                       94                  1750.28   \n",
       "152763                       38                   805.60   \n",
       "153220                        0                     0.00   \n",
       "153230                       34                   545.70   \n",
       "153365                      118                  1473.16   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "1919                       123.500000                    2510.875000   \n",
       "2917                        65.600000                    1143.410000   \n",
       "4895                       120.700000                    3031.835000   \n",
       "6234                        35.000000                     559.300000   \n",
       "7946                       139.250000                    3327.930000   \n",
       "...                               ...                            ...   \n",
       "152016                      24.333333                     453.063333   \n",
       "152763                     112.222222                    2392.375556   \n",
       "153220                     104.200000                    3070.236000   \n",
       "153230                      38.083333                     613.657500   \n",
       "153365                     151.416667                    1864.677500   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "1919                         27.665424                      837.458084   \n",
       "2917                         23.948367                      552.884925   \n",
       "4895                         27.665424                      837.458084   \n",
       "6234                         23.948367                      552.884925   \n",
       "7946                         27.665424                      837.458084   \n",
       "...                                ...                             ...   \n",
       "152016                       23.948367                      552.884925   \n",
       "152763                       27.665424                      837.458084   \n",
       "153220                       27.665424                      837.458084   \n",
       "153230                       23.948367                      552.884925   \n",
       "153365                       22.828325                      360.748316   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "1919                        0                   0.00   \n",
       "2917                        0                   0.00   \n",
       "4895                        0                   0.00   \n",
       "6234                        0                   0.00   \n",
       "7946                        0                   0.00   \n",
       "...                       ...                    ...   \n",
       "152016                      0                   0.00   \n",
       "152763                      1                  21.20   \n",
       "153220                      0                   0.00   \n",
       "153230                      0                   0.00   \n",
       "153365                      4                  47.32   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "1919                       1.500000                    30.225000  ...   \n",
       "2917                       0.800000                    13.840000  ...   \n",
       "4895                       2.700000                    66.119000  ...   \n",
       "6234                       0.000000                     0.000000  ...   \n",
       "7946                       8.250000                   194.327500  ...   \n",
       "...                             ...                          ...  ...   \n",
       "152016                     0.000000                     0.000000  ...   \n",
       "152763                     5.666667                   119.813333  ...   \n",
       "153220                     1.000000                    29.380000  ...   \n",
       "153230                     0.833333                    16.040000  ...   \n",
       "153365                     5.500000                    69.935000  ...   \n",
       "\n",
       "        CUST_MD_BENE_DOS_PARES_NO_MS  QT_FRAGMENTACAO_DE_EVENTOS  \\\n",
       "1919                       72.868129                           0   \n",
       "2917                       43.715065                           0   \n",
       "4895                       72.868129                           0   \n",
       "6234                       43.715065                           0   \n",
       "7946                       72.868129                           0   \n",
       "...                              ...                         ...   \n",
       "152016                     43.715065                           0   \n",
       "152763                     72.868129                           0   \n",
       "153220                     72.868129                           0   \n",
       "153230                     43.715065                           0   \n",
       "153365                     25.858542                           0   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_MES  QT_UO_MED_EVENTO_NO_ANO  \\\n",
       "1919                   0.000000                 0.310000   \n",
       "2917                   0.000000                 0.313914   \n",
       "4895                   0.000000                 0.376324   \n",
       "6234                   0.290017                 0.290018   \n",
       "7946                   0.000000                 0.356025   \n",
       "...                         ...                      ...   \n",
       "152016                 0.337931                 0.337913   \n",
       "152763                 0.326154                 0.326497   \n",
       "153220                 0.000000                 0.452016   \n",
       "153230                 0.291289                 0.291166   \n",
       "153365                 0.313681                 0.311043   \n",
       "\n",
       "        QT_MED_UO_EVENTO_DOS_PARES  CD_CIR_DENTISTA  CD_ESPECIALIDADE  \\\n",
       "1919                      0.409064           403485                 2   \n",
       "2917                      0.400164           300624                 4   \n",
       "4895                      0.409064           337020                 2   \n",
       "6234                      0.400164           414591                 4   \n",
       "7946                      0.409064           363725                 2   \n",
       "...                            ...              ...               ...   \n",
       "152016                    0.400164           410714                 4   \n",
       "152763                    0.409064           364214                 2   \n",
       "153220                    0.409064           390856                 2   \n",
       "153230                    0.400164           392709                 4   \n",
       "153365                    0.402894           ARB001                25   \n",
       "\n",
       "        FAIXA_POPULACAO  NM_UNIDADE    CLASSE  \n",
       "1919                  4        UNNA  Moderado  \n",
       "2917                  5        UNNA  Moderado  \n",
       "4895                  7        UNNA  Moderado  \n",
       "6234                  7        UNNA  Moderado  \n",
       "7946                  3        UNNA  Moderado  \n",
       "...                 ...         ...       ...  \n",
       "152016                7        UNNA  Moderado  \n",
       "152763                4        UNNA  Moderado  \n",
       "153220                3        UNNA  Moderado  \n",
       "153230                7        UNNA  Moderado  \n",
       "153365                4        UNNA  Moderado  \n",
       "\n",
       "[157 rows x 42 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['CD_CIR_DENTISTA'].isin(cds_moderados)) & (df['CLASSE'] == 'Moderado')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4739, 42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['CLASSE'] == 'Baixo')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CUSTO_MED_EVENTO_NO_MES</th>\n",
       "      <th>CUSTO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>CUST_MD_EVEN_DOS_PARES_NO_MS</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>63</td>\n",
       "      <td>1501.63</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>2527.860000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>10.827500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347233</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>22.781587</td>\n",
       "      <td>24.469350</td>\n",
       "      <td>26.183801</td>\n",
       "      <td>399641</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>10458.76</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>9415.198333</td>\n",
       "      <td>16.110762</td>\n",
       "      <td>3184.606583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582828</td>\n",
       "      <td>0.483882</td>\n",
       "      <td>402.260000</td>\n",
       "      <td>321.323983</td>\n",
       "      <td>166.997459</td>\n",
       "      <td>GOH803</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>38</td>\n",
       "      <td>7820.27</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>7708.260000</td>\n",
       "      <td>16.110762</td>\n",
       "      <td>3184.606583</td>\n",
       "      <td>1</td>\n",
       "      <td>90.31</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>145.905000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384162</td>\n",
       "      <td>0.483882</td>\n",
       "      <td>193.251579</td>\n",
       "      <td>207.564835</td>\n",
       "      <td>166.997459</td>\n",
       "      <td>328544</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>47</td>\n",
       "      <td>9207.97</td>\n",
       "      <td>51.583333</td>\n",
       "      <td>10751.632500</td>\n",
       "      <td>16.110762</td>\n",
       "      <td>3184.606583</td>\n",
       "      <td>1</td>\n",
       "      <td>96.24</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>129.884167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410660</td>\n",
       "      <td>0.483882</td>\n",
       "      <td>180.439787</td>\n",
       "      <td>194.802019</td>\n",
       "      <td>166.997459</td>\n",
       "      <td>ESS304</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>51</td>\n",
       "      <td>22172.55</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>10251.532500</td>\n",
       "      <td>16.110762</td>\n",
       "      <td>3184.606583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>97.478333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844663</td>\n",
       "      <td>0.483882</td>\n",
       "      <td>425.908235</td>\n",
       "      <td>308.447093</td>\n",
       "      <td>166.997459</td>\n",
       "      <td>299151</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163278</td>\n",
       "      <td>15</td>\n",
       "      <td>3904.41</td>\n",
       "      <td>10.909091</td>\n",
       "      <td>2908.995455</td>\n",
       "      <td>7.665254</td>\n",
       "      <td>1138.794204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>0.446634</td>\n",
       "      <td>240.006667</td>\n",
       "      <td>253.571500</td>\n",
       "      <td>123.369664</td>\n",
       "      <td>376619</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163318</td>\n",
       "      <td>150</td>\n",
       "      <td>2650.50</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>1850.970000</td>\n",
       "      <td>6.149484</td>\n",
       "      <td>106.315827</td>\n",
       "      <td>3</td>\n",
       "      <td>53.01</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>55.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420952</td>\n",
       "      <td>0.443844</td>\n",
       "      <td>17.316600</td>\n",
       "      <td>16.959526</td>\n",
       "      <td>12.037776</td>\n",
       "      <td>72811P</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>BRADESCO</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163491</td>\n",
       "      <td>988</td>\n",
       "      <td>27290.09</td>\n",
       "      <td>907.181818</td>\n",
       "      <td>23972.626364</td>\n",
       "      <td>44.505451</td>\n",
       "      <td>686.547980</td>\n",
       "      <td>6</td>\n",
       "      <td>62.52</td>\n",
       "      <td>10.181818</td>\n",
       "      <td>124.196364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423890</td>\n",
       "      <td>0.346676</td>\n",
       "      <td>27.022763</td>\n",
       "      <td>24.917976</td>\n",
       "      <td>13.615924</td>\n",
       "      <td>CCI201</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9536.252000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>783.384000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.476896</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>413.041700</td>\n",
       "      <td>26.183801</td>\n",
       "      <td>336526</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>9298.476000</td>\n",
       "      <td>44.505451</td>\n",
       "      <td>686.547980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>47.904000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285110</td>\n",
       "      <td>0.346676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.523717</td>\n",
       "      <td>13.615924</td>\n",
       "      <td>RMP001</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6488 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "34                           63                  1501.63   \n",
       "119                          26                 10458.76   \n",
       "150                          38                  7820.27   \n",
       "219                          47                  9207.97   \n",
       "277                          51                 22172.55   \n",
       "...                         ...                      ...   \n",
       "163278                       15                  3904.41   \n",
       "163318                      150                  2650.50   \n",
       "163491                      988                 27290.09   \n",
       "164670                        0                     0.00   \n",
       "165511                        0                     0.00   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "34                          98.750000                    2527.860000   \n",
       "119                         28.666667                    9415.198333   \n",
       "150                         32.750000                    7708.260000   \n",
       "219                         51.583333                   10751.632500   \n",
       "277                         31.250000                   10251.532500   \n",
       "...                               ...                            ...   \n",
       "163278                      10.909091                    2908.995455   \n",
       "163318                     105.500000                    1850.970000   \n",
       "163491                     907.181818                   23972.626364   \n",
       "164670                      20.000000                    9536.252000   \n",
       "165511                     290.000000                    9298.476000   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "34                           27.665424                      837.458084   \n",
       "119                          16.110762                     3184.606583   \n",
       "150                          16.110762                     3184.606583   \n",
       "219                          16.110762                     3184.606583   \n",
       "277                          16.110762                     3184.606583   \n",
       "...                                ...                             ...   \n",
       "163278                        7.665254                     1138.794204   \n",
       "163318                        6.149484                      106.315827   \n",
       "163491                       44.505451                      686.547980   \n",
       "164670                       27.665424                      837.458084   \n",
       "165511                       44.505451                      686.547980   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "34                          0                   0.00   \n",
       "119                         0                   0.00   \n",
       "150                         1                  90.31   \n",
       "219                         1                  96.24   \n",
       "277                         0                   0.00   \n",
       "...                       ...                    ...   \n",
       "163278                      0                   0.00   \n",
       "163318                      3                  53.01   \n",
       "163491                      6                  62.52   \n",
       "164670                      0                   0.00   \n",
       "165511                      0                   0.00   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "34                         0.416667                    10.827500  ...   \n",
       "119                        0.000000                     0.000000  ...   \n",
       "150                        0.666667                   145.905000  ...   \n",
       "219                        0.916667                   129.884167  ...   \n",
       "277                        0.166667                    97.478333  ...   \n",
       "...                             ...                          ...  ...   \n",
       "163278                     0.000000                     0.000000  ...   \n",
       "163318                     3.166667                    55.850000  ...   \n",
       "163491                    10.181818                   124.196364  ...   \n",
       "164670                     1.200000                   783.384000  ...   \n",
       "165511                     2.400000                    47.904000  ...   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_ANO  QT_MED_UO_EVENTO_DOS_PARES  \\\n",
       "34                     0.347233                    0.409064   \n",
       "119                    0.582828                    0.483882   \n",
       "150                    0.384162                    0.483882   \n",
       "219                    0.410660                    0.483882   \n",
       "277                    0.844663                    0.483882   \n",
       "...                         ...                         ...   \n",
       "163278                 0.604584                    0.446634   \n",
       "163318                 0.420952                    0.443844   \n",
       "163491                 0.423890                    0.346676   \n",
       "164670                 7.476896                    0.409064   \n",
       "165511                 0.285110                    0.346676   \n",
       "\n",
       "        CUSTO_MED_EVENTO_NO_MES  CUSTO_MED_EVENTO_NO_ANO  \\\n",
       "34                    22.781587                24.469350   \n",
       "119                  402.260000               321.323983   \n",
       "150                  193.251579               207.564835   \n",
       "219                  180.439787               194.802019   \n",
       "277                  425.908235               308.447093   \n",
       "...                         ...                      ...   \n",
       "163278               240.006667               253.571500   \n",
       "163318                17.316600                16.959526   \n",
       "163491                27.022763                24.917976   \n",
       "164670                 0.000000               413.041700   \n",
       "165511                 0.000000                22.523717   \n",
       "\n",
       "        CUST_MD_EVEN_DOS_PARES_NO_MS  CD_CIR_DENTISTA  CD_ESPECIALIDADE  \\\n",
       "34                         26.183801           399641                 2   \n",
       "119                       166.997459           GOH803                13   \n",
       "150                       166.997459           328544                13   \n",
       "219                       166.997459           ESS304                13   \n",
       "277                       166.997459           299151                13   \n",
       "...                              ...              ...               ...   \n",
       "163278                    123.369664           376619                 3   \n",
       "163318                     12.037776           72811P                19   \n",
       "163491                     13.615924           CCI201                14   \n",
       "164670                     26.183801           336526                 2   \n",
       "165511                     13.615924           RMP001                14   \n",
       "\n",
       "        FAIXA_POPULACAO  NM_UNIDADE  CLASSE  \n",
       "34                    7        UNNA    Alto  \n",
       "119                   4        UNNA    Alto  \n",
       "150                   7        UNNA    Alto  \n",
       "219                   5        UNNA    Alto  \n",
       "277                   3        UNNA    Alto  \n",
       "...                 ...         ...     ...  \n",
       "163278                2        UNNA    Alto  \n",
       "163318                6    BRADESCO    Alto  \n",
       "163491                4        UNNA    Alto  \n",
       "164670                7        UNNA    Alto  \n",
       "165511                7        UNNA    Alto  \n",
       "\n",
       "[6488 rows x 49 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alto #6488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valclemir\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\valclemir\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#X_save = df.copy()\n",
    "#X_save.loc[(X_save['CD_CIR_DENTISTA'].isin(cd_descredenciados)) & (X_save['CLASSE'] == 'Alto')]\n",
    "#df_alto = df[df['CLASSE'] == 'Alto']\n",
    "#df_alto.shape\n",
    "\n",
    "#df.loc[(df['CD_CIR_DENTISTA'].isin(cd_descredenciados)) & \n",
    "#       (df['CLASSE'] == 'Moderado')]\n",
    "#df.shape\n",
    "#X_save.loc[X_save['CD_CIR_DENTISTa'].isin(cds_moderados) & (X_save['CLASS_'])]\n",
    "df_export['CD_CIR_DENTISTA'] = X_save.CD_CIR_DENTISTA\n",
    "df_export['CD_ESPECIALIDADE_EVENTO'] = X_save.CD_ESPECIALIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export[(df_export['CD_CIR_DENTISTA'].isin(cds_moderados)) & (df_export['CLASSE'] == 'Moderado')].to_excel('amostra_cds_moderados.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and label scaling\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(y)\n",
    "\n",
    "with open('model\\scaler.pickle', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "with open('model\\label.pickle', 'wb') as label_file:\n",
    "    pickle.dump(le, label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rede Neural Especialista: 1\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 2ms/step - loss: 0.7967 - accuracy: 0.6277\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.2284 - accuracy: 0.9155\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9371\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9511\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1290 - accuracy: 0.9533\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1116 - accuracy: 0.9592\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1102 - accuracy: 0.9599\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9613\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9672\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9673\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9675\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9725\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9678\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9666\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9737\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9707\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9722\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9714\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.9736\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9713\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9718\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9744\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0705 - accuracy: 0.9759\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9772\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9774\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9781\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9756\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9785\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9756\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9747\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9795\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9767\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9764\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.9742\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9788\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9764\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9775\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9796\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9792\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9784\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9778\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9777\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9814\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9760: 0s - loss: 0\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9795\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9770\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9808\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9753\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9820\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9790\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0552 - accuracy: 0.9829\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9797\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9808\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9816\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0527 - accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9809\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9840\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9791\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9819\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9807\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9780\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9817\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9808\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9827: 0s - los\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9804\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9817\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9825\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9805\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9835\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9817\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9827\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9838\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9806\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0532 - accuracy: 0.9826\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9803\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9838\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9818\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9812\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9825\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9811\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9848\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.9825\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9841\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0503 - accuracy: 0.9833\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9841\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0527 - accuracy: 0.9824\n",
      "\tKFold: 1\n",
      "\tAcurácia do Treinamento: 98.73\n",
      "\tAcurácia do Teste: 97.68\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.8006 - accuracy: 0.6113\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9014\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1724 - accuracy: 0.9364\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1573 - accuracy: 0.9443\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1356 - accuracy: 0.9516\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1254 - accuracy: 0.9563\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1204 - accuracy: 0.9571\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1239 - accuracy: 0.9568\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.9655\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1054 - accuracy: 0.9663\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1127 - accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9660\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9689\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9662\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9686\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9679\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9673\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.9710\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1052 - accuracy: 0.9621\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9668\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9686\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9700\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9735\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9751\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9750\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9761\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9786\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9738\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9762\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9769\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9779\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9771\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9756\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0804 - accuracy: 0.9741\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9781\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9773\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9778\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9760\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9791\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9789\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9766\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9774\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9790\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9794\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9760\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9742\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9761\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9777\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9777\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9782\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9787\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9794\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9764\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9820\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9801\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9799\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9806\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9819\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9789: 0s - loss: 0.078\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9766\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9805\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9781\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9817\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.9789\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9786\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9793\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9823\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9783\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9813\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9804\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9796\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9771: 0s - loss: 0.074\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9823\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9808\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9795\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9836\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9812\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9789\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9787\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9815: \n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9799\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9792\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9817\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9781\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9798\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9814\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9822\n",
      "\tKFold: 2\n",
      "\tAcurácia do Treinamento: 98.22\n",
      "\tAcurácia do Teste: 98.56\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 2ms/step - loss: 0.7773 - accuracy: 0.6363\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9008\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9386\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1470 - accuracy: 0.9470\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1340 - accuracy: 0.9544\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1248 - accuracy: 0.9584\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1191 - accuracy: 0.9571\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.9601\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1144 - accuracy: 0.9629\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9640\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9624\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9669\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9669\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9724\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9679\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9713\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9717\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9650\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9696\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9726\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9694: \n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0809 - accuracy: 0.9741\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.9762\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9717\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9715\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0768 - accuracy: 0.9733\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9762\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9756\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9757\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9735\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9788\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0776 - accuracy: 0.9742\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9745\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0767 - accuracy: 0.9756\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9719\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9749\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9783\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9776\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9797\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9771\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9792\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9783\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9783\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9746\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9793\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9778\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9749\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9777\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0633 - accuracy: 0.9788\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9799\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9770\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9774\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9805\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9801\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0753 - accuracy: 0.9751\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9810\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9774\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9779\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9807\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9772\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9807\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9774\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9736\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9759\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9773\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9760\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9795\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9833\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9817\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9793\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9790\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9804\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9790\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9819: 0s - l\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9817\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0602 - accuracy: 0.9801\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9784\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9810\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9762\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9809\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9774\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9818\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9826\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9825\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9798\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9827\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9808\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9813\n",
      "\tKFold: 3\n",
      "\tAcurácia do Treinamento: 97.79\n",
      "\tAcurácia do Teste: 97.40\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7913 - accuracy: 0.6312\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2246 - accuracy: 0.9098\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9373\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9440\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9482\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9578\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.9567\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1118 - accuracy: 0.9626\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9651\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1009 - accuracy: 0.9637\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9679\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9665\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9683\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9691\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9743\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9699\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9725\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9718\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9704\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9683\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9706\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.9743\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9715\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9691\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9794\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9721: 0s - loss: 0.087\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9716\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9767\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9736\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9734\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9747\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9793\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9785\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.9734\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9783\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9738\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0749 - accuracy: 0.9744\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0731 - accuracy: 0.9754\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9790\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9800\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9775\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9794\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9770\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9772\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9795\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9800\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9763\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9806\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9757\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0664 - accuracy: 0.9783\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.9756\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9786\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9795\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9771\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9773\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9788\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9811\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9777\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9782\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9784\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9814\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9790\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9787\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9811\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9825\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9785\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9829\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9766\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9800\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9801\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9831\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9819\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9824\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9792\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9782\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9823\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9805\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9770\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9813\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9817\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9806\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9825\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9791\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9838\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0596 - accuracy: 0.9810\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9813\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0577 - accuracy: 0.9811\n",
      "\tKFold: 4\n",
      "\tAcurácia do Treinamento: 98.48\n",
      "\tAcurácia do Teste: 98.07\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.7699 - accuracy: 0.6477\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.9053\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9360\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9441\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9524\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1254 - accuracy: 0.9562\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1174 - accuracy: 0.9590\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1184 - accuracy: 0.9579\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9608\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9643\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.9613\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.9670\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.9643\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9659\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9694\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9688\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9699\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9719\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9689\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9681\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.9727\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9739\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9744\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9763\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9682\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9702\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9722\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0723 - accuracy: 0.9746\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9794\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9760\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9716\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9758\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9759\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0789 - accuracy: 0.9751\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9783\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9736\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9770\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9771\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9802\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9788\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9760\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9797\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.9752: 0s - loss: 0\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9778\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9757\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9780\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9791\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9814\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9794\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9791\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9792\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9780\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9784\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9805: 0s -\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9753\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9784\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9778\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9792\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9806\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9761\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9794\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9791\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9812\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9813\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9814\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9786\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9785\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9810\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9811\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9818\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9828\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9814\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9772\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9790\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9823\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9795\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0577 - accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9808\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9798\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9787\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9807\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9829\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9772\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9798\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9826\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9797\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9805\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9811\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9791\n",
      "\tKFold: 5\n",
      "\tAcurácia do Treinamento: 98.46\n",
      "\tAcurácia do Teste: 98.42\n",
      "Acurácia do Especialista 1: 98.02\n",
      "Desvio Padrão do Especialista 1: 0.44\n",
      "\n",
      "Rede Neural Especialista: 2\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 4ms/step - loss: 0.7912 - accuracy: 0.6346\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.8969\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9287\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9473\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9545\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1192 - accuracy: 0.9594\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1139 - accuracy: 0.9593\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9652\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1072 - accuracy: 0.9627\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9672\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9658\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9690\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9673\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9715\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9684\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9756\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9739\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0811 - accuracy: 0.9752\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9727\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9728\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.9757\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9731\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9747\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9733\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.97 - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9764\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0835 - accuracy: 0.9712\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9763\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9774\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9746\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9747\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9776\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9776\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9771\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9772\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9792\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9765\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9780\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9777\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9781\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9846\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9795\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9810\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9797\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9813\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9785\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9796\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9796\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9805\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9786\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9762\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9735\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9813\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9804\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9794\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9796\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9816\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9792\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9791\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9816\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9852\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0503 - accuracy: 0.9832\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9807\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9830\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9799\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9818\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9810\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0540 - accuracy: 0.9811\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0532 - accuracy: 0.9820\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9826\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9825\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9820: 0s - loss: 0.0\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9809\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9814\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9824\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9849\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9847\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0499 - accuracy: 0.9836\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9837\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9823\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9831: 0s - loss: 0\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9813\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9782\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9819\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9821\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0525 - accuracy: 0.9828\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9808\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9824\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9793\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9822\n",
      "\tKFold: 1\n",
      "\tAcurácia do Treinamento: 98.88\n",
      "\tAcurácia do Teste: 97.78\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7688 - accuracy: 0.6422\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9057\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9392\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9447\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9488\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1232 - accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1138 - accuracy: 0.9620\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1141 - accuracy: 0.9612\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9615\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9692\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9657\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9673\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1050 - accuracy: 0.9648\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9687\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9712\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9698\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9714\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9717\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9755\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.9749\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9733\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9749\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9705\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0802 - accuracy: 0.9750\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9734\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9728\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9790\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9719\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9767\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9731: 0s -\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9754\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9758\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9762\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9777: 0s - loss: 0\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9781\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9765\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9793\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9793\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9742\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9758\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9761\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9789\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9770\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9766\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9797\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9795\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9774\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9776\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9794\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9793\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9812\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9786\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9780\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9795\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9801\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9787\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9769\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9795\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9788\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9780\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9823\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9796\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9812\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9810\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9811\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9818\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9769\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9794\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9776\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9801\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9799\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9802\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9793\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9823\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.9751\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9816\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9806\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9784\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9807\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9810\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9820\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9734\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0577 - accuracy: 0.9814\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9817\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9805\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9789\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9798\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9782\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9825\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9836\n",
      "\tKFold: 2\n",
      "\tAcurácia do Treinamento: 98.31\n",
      "\tAcurácia do Teste: 98.56\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.7495 - accuracy: 0.6564\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.2405 - accuracy: 0.9090\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.9257\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1389 - accuracy: 0.9500\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9460\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9542\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1197 - accuracy: 0.9599\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9581\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1061 - accuracy: 0.9621\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.9605\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9631\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0941 - accuracy: 0.9663\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9662\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9672\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9693\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9634\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9661\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9698\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9728\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.9717\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9755\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9741\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9749\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9737\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9690\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9765\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9728\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9744\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9765\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9743\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9701\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.9728\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9766\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0785 - accuracy: 0.9738\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9769\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9710\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9774\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9757\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9787\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9775\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9777\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9758\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9780\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9771\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9780\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9787\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9794\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9750\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.9767\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9780\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9786\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9799\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9782\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9777\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9794\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9794\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9777\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9827\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9778\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9820\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9798\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9809\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9788\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9784\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9805\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.9784\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9779\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9814\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9812\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9808\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9805\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9819\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9775\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9816\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9797\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9826\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9814\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9783\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9839\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9813\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9810\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9824\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9788\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9788\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9801\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9810\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9808\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9821\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9829\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9783\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9804\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9795\n",
      "\tKFold: 3\n",
      "\tAcurácia do Treinamento: 98.65\n",
      "\tAcurácia do Teste: 98.59\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 4ms/step - loss: 0.8020 - accuracy: 0.6247\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.2328 - accuracy: 0.9103\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9353\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9451\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9520\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1288 - accuracy: 0.9547\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1192 - accuracy: 0.9570\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.9553\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1077 - accuracy: 0.9594\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1099 - accuracy: 0.9603\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9656\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9631\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9657\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9689\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9719\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9697\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9720\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9662\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9720\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9709\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9676\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9712\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9728\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9736\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0771 - accuracy: 0.9752\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9740\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9757\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9756\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9732\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9749\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9776\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9755\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0727 - accuracy: 0.9739\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9727\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0681 - accuracy: 0.9771\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9746\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9785\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9814\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0712 - accuracy: 0.9786\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0712 - accuracy: 0.9758\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9794\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9780\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9773\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9801\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9784\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9795\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9819\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9775\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9834\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9774\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9784\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9790\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9762\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9795\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9753\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.9817\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9802\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9790\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0602 - accuracy: 0.9825\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9799\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9768\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9786\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9791\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9802\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9792\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9790\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9821\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9773\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9801\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9809\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9820\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9803\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9814\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9844\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9814\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9799\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9788\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9795\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9827: 0s -\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9770\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9823\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9808\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9811\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.9853\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9819\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9806\n",
      "\tKFold: 4\n",
      "\tAcurácia do Treinamento: 98.55\n",
      "\tAcurácia do Teste: 98.10\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 4ms/step - loss: 0.7679 - accuracy: 0.6283\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.2203 - accuracy: 0.9156\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.9321\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1603 - accuracy: 0.9441\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1415 - accuracy: 0.9501\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1118 - accuracy: 0.9578\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9594\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.9632\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1069 - accuracy: 0.9633\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9682\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1035 - accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9648\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9679\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9681\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9722\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9716\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9701\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.9720\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9726\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0818 - accuracy: 0.9733\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9753\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9706\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9758\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9725\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9732: 0s - loss: 0\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9737\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.9748\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9766\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9743\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9733: 0s - l\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.9769\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9702\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9719\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9762\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9749\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9798\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9772\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9766\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9800\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9733\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9781\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9801\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9738\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9797: 0s - loss: 0.068\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9787\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9793\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9785\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9769\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9757\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9786\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9801\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9769\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9790\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9816\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9766\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9775\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9805\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9794\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9776\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9806\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9787\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9801\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9802\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9821\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9789\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9824\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9804\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9793\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9794\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9818\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9791\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9797\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9812\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9808\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9797\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9798\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0586 - accuracy: 0.9782\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9817\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0602 - accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9792\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9791\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9819\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9789\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9798\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9801\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9797\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9790\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9817\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9763\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9815\n",
      "\tKFold: 5\n",
      "\tAcurácia do Treinamento: 98.30\n",
      "\tAcurácia do Teste: 98.06\n",
      "Acurácia do Especialista 2: 98.22\n",
      "Desvio Padrão do Especialista 2: 0.31\n",
      "\n",
      "Rede Neural Especialista: 3\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.8036 - accuracy: 0.6258\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2305 - accuracy: 0.9096\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1841 - accuracy: 0.9301\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1523 - accuracy: 0.9438\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9498\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1230 - accuracy: 0.9555\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9565\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.9591\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9670\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9660\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9663\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9672\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9724\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9716\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9696\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9698\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9729\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9745\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9711\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9753\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9750\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0755 - accuracy: 0.9750\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0824 - accuracy: 0.9730\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9778\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9756\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9711\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9766\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9690\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.9774\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9788\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9763\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9806\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9791\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9779\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9780\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9765\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9770\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9772\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9806\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9825\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.9752\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9770\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9823\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9790\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9802\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9781\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0544 - accuracy: 0.9819\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9759\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9812\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9757\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9808\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9817: 0s - loss: 0\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9806\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9816\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9788\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9805\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9810\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9826\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9818\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9812\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9779\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9825\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0510 - accuracy: 0.9841\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0512 - accuracy: 0.9825\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9795\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9803\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9836\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9778\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9819\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9818\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.9836\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9765\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9828\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9817\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9836\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.9854\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9845\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.9836\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9826\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0547 - accuracy: 0.9819\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9847\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9830\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9785\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.9850\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9837\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9808\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0547 - accuracy: 0.9830\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9826\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9835\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9841\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9869\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9822\n",
      "\tKFold: 1\n",
      "\tAcurácia do Treinamento: 98.51\n",
      "\tAcurácia do Teste: 97.40\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 3ms/step - loss: 0.8138 - accuracy: 0.6004\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.9084\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1873 - accuracy: 0.9261\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9505\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9531\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9569\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1169 - accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1125 - accuracy: 0.9605\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.9618\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.9589\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.9613\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9659\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9664\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9659\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9705\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9692\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9676\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.9621\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9718\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9738\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9737\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0801 - accuracy: 0.9739\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9693\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9715\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9716\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9686\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9733\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9692\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9725\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9735\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0728 - accuracy: 0.9772\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9759\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9755\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9726\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0702 - accuracy: 0.9757\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9745\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9753\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9765\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9790\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.9793\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9781\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9783\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9771\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9755\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9768\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9754\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9778\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9753\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9765\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9746\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9788\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9770\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9771\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9807\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9809\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9771\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9775\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9776\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9780\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9728\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9779\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9799\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9772\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9760\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9795\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9814\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9814\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9788\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9772\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9765\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9814\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9799\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9813\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9823: 0s - loss: 0.0533 - ac\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9769\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9805\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9797: 1s - los\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.9836\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9811\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9817\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9799\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9816\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9788\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9829\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9810\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9796\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9811\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9801\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9814\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9784\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9809\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9792\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9813\n",
      "\tKFold: 2\n",
      "\tAcurácia do Treinamento: 98.52\n",
      "\tAcurácia do Teste: 98.63\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.7996 - accuracy: 0.6341\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9103\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9323\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9500\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9510\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1256 - accuracy: 0.9571\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1267 - accuracy: 0.9522\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1123 - accuracy: 0.9602\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9676\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1073 - accuracy: 0.9644\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9683\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9663\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9676\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9696: 0s - los\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9669\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9685\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9670\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.9709\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9687\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9702\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9726\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9686\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9748\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9743\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9745\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9748\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9738\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9741\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9776\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9761\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9767\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9721\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9766\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9730\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9756\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9759\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9753\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9732\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9781\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9785\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9759\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9788\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9771\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.9760\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9739\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9807\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9759\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9724\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9785\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0723 - accuracy: 0.9771\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9805\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9764\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9782\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9801\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9782\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9802\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9785\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9809\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9776\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9807\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9769\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9814\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9797\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9792\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9788\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9775\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9819\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9796\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9817\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9762\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9832\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9781\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9825\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9817\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9805\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9794\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9816\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9793\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9792\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9820\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9807\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9787\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9817\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9834\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9809\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9763\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9785\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9794\n",
      "\tKFold: 3\n",
      "\tAcurácia do Treinamento: 98.60\n",
      "\tAcurácia do Teste: 98.24\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 3ms/step - loss: 0.7756 - accuracy: 0.6288\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2352 - accuracy: 0.9079\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.9353\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9459\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1327 - accuracy: 0.9533\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1381 - accuracy: 0.9528\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.9621\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1110 - accuracy: 0.9627\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9640\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9679\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9665\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9640\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9721\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9674\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9722\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9705\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9706\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9692\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9719\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9701\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0825 - accuracy: 0.9725\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9741\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9758\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9751\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9706\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9753\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0814 - accuracy: 0.9715\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9791\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9763\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9776\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9745\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9776\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9764\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0712 - accuracy: 0.9760\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9745\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9763\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9761\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9772\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9774\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9792\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9751\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9787: 0s - loss: 0.0\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9755\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9733\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9782\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9780\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9751\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9791\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9771\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9817\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9767\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9788\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9811\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9830\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9785\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9834\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9817\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9806\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0596 - accuracy: 0.9809\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9819\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9785\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9790\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9804\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9793\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9814\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9819\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9796\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9803\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9798\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9821\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9813: 1s -\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0577 - accuracy: 0.9819\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9817\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9789\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9814\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0541 - accuracy: 0.9820\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9819\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9805\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0537 - accuracy: 0.9818\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9798\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9819\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9818\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0532 - accuracy: 0.9824\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9834\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9780: 0s -\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9798\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9843\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9813\n",
      "\tKFold: 4\n",
      "\tAcurácia do Treinamento: 97.33\n",
      "\tAcurácia do Teste: 96.69\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.7783 - accuracy: 0.6461\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2477 - accuracy: 0.9010\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1650 - accuracy: 0.9373\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9494\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1232 - accuracy: 0.9556\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.9639\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.9626\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.9609\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1113 - accuracy: 0.9615\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9675\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.9607\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9642\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9686\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1081 - accuracy: 0.9630\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9706\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9676\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9659: 0s -\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9654\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9713\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9679\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9680\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9705\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9693\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9709\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9742\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9734\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9736\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.9743\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9714\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.9732\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9777\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9728\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9749\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9726\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0704 - accuracy: 0.9768\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9759\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9753\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9786\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9801\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9728\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9786\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9768\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.9750\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9774\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9789\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9788\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9789\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9795\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9758\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9797\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9781\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9800\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9749\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9787\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9791\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9792\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9763\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9779\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9817\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9786\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9790\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9808\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9797\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9766\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9823\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9805\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9799\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9791\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9825\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9817\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9807: 0s\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9779\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9794\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9785\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9801\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0664 - accuracy: 0.9767\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9801\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9823\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9819\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9805\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9825\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0541 - accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0569 - accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9802\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9799\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9808\n",
      "\tKFold: 5\n",
      "\tAcurácia do Treinamento: 98.63\n",
      "\tAcurácia do Teste: 98.35\n",
      "Acurácia do Especialista 3: 97.86\n",
      "Desvio Padrão do Especialista 3: 0.71\n",
      "\n",
      "Rede Neural Especialista: 4\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.8033 - accuracy: 0.6185\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2274 - accuracy: 0.9114\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9360\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9475\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9557\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9564\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1050 - accuracy: 0.9637: \n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9644\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9676\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9654\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9637\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9670: 0s - los\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9712\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9724: 0s\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9731\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9707\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9693\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9726: 0s - loss: 0.081\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9669\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0797 - accuracy: 0.9725\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9693\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9768\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9745\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9721\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9772\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9779\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0731 - accuracy: 0.9746\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9775\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9777\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9782\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9803\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9810\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9782\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9797\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9799\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9795\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9809\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9769\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9750\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9777\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9816\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9801\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9766\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9813\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9794\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9794\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0608 - accuracy: 0.9812\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9793\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9784\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9788\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9817\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9785\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9779\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9828\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9821\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9796\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9836\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9808\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9794\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0633 - accuracy: 0.9788\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9818\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9811\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9814\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9825\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9790\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9834\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9818\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9823\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9826\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9817\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0527 - accuracy: 0.9813\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0533 - accuracy: 0.9823\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.9830\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9813\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9824\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9825\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9809\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0475 - accuracy: 0.9832\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9843\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0513 - accuracy: 0.9845\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9839\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9806\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9833\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9809\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0513 - accuracy: 0.9843\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.9849\n",
      "\tKFold: 1\n",
      "\tAcurácia do Treinamento: 98.94\n",
      "\tAcurácia do Teste: 97.86\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 2ms/step - loss: 0.8177 - accuracy: 0.6171\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9072\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.9268\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9449\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1373 - accuracy: 0.9513\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9559\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9607\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1176 - accuracy: 0.9601\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1173 - accuracy: 0.9574\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9687\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9646\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9662\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9687\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9663\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.9739\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9670\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9678\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9707\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9700\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9716\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9750\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9672\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9758\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9719\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9754: 0s - loss: 0.0\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9749\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9726\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9717\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9767\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.9727\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9756\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9770\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9734\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9766\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9743: 0s - los\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9742\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9767\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9766\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9753\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9760\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9804\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9737\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9800\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9751\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9766\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9794\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9774\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9791\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9781\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9780\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9717\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9800\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9778\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9806\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9796\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9791\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9790\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9786\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9791\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9816\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9793\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9772\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9793\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9787\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9766\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9799\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9782\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9812\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9775\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9858\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9779\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0622 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9805\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9789\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9800\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9765\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9824\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9782\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9809\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9796\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9763\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9817\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9779\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9819\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9810\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9809\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9773\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9835\n",
      "\tKFold: 2\n",
      "\tAcurácia do Treinamento: 98.67\n",
      "\tAcurácia do Teste: 98.70\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7878 - accuracy: 0.6186\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2355 - accuracy: 0.9081\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9364\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1598 - accuracy: 0.9436\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1287 - accuracy: 0.9552\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1186 - accuracy: 0.9580\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.96 - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9636\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9598\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9615\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1014 - accuracy: 0.9664\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9689\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9650\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9681\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9680\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9661\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9716\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.9695\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9726\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9684\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9694\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9716: 0s - loss: 0.091\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9737\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9736\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9780\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9736\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9718\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9741\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9740\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9767\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9749\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9710\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0743 - accuracy: 0.9752\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9745\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9772\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9747\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9794\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9750\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9777\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9750\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9784\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9748\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9781\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0760 - accuracy: 0.9756\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9777\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0681 - accuracy: 0.9779\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9830\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9767\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9778\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9773\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9772\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9785\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9791\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9765\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9793\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9794\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9785\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9779\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.9820\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9807\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9788\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9805\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9753\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9793\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9773\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9795\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9794\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9808\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9795\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9802\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9808\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9804\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9823\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9787\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9790\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.9786: 0s - loss: 0.065\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9807\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9814\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9835\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9818\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9797\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9816\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9802\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9783\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9814\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9832\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9820\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.9811\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9803\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9839\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9820\n",
      "\tKFold: 3\n",
      "\tAcurácia do Treinamento: 98.56\n",
      "\tAcurácia do Teste: 98.38\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7808 - accuracy: 0.6219\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2305 - accuracy: 0.9096\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9390\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1483 - accuracy: 0.9469\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1297 - accuracy: 0.9558\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1249 - accuracy: 0.9539\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9598\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.9559\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9612\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.9618\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9646\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9647\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9706\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9649\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9713\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0873 - accuracy: 0.9707\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9717\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.9717\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.9723\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9721\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9707\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9753\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9701\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9739\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9764\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9758\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9751\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0713 - accuracy: 0.9764\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9764\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9715\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.9754\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0776 - accuracy: 0.9751\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9749\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9717\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9772\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9735\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9740\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9758\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9751\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9765\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9759\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9742\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9757\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9772\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9790 E - 1s 3ms/step - loss: 0.0631 - accuracy: 0.9789\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9745\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9790\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9784\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9761\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9780\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9781\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0596 - accuracy: 0.9818\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9778\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9774\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9768\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9789\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9784\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9777\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9775\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9807\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9793\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.97 - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9760\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9793\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9795\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9805\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9797\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9789\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9817\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9777\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0708 - accuracy: 0.9773\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.9808\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9790\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9780\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9803\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9795\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9838\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9829\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9789\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9789\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9799\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9784\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9812\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9811\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9812\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9799\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9792\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9826\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9831\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9780\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9817\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9807\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9792\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9825\n",
      "\tKFold: 4\n",
      "\tAcurácia do Treinamento: 98.16\n",
      "\tAcurácia do Teste: 97.82\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 3s 4ms/step - loss: 0.8077 - accuracy: 0.6180\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.9023\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9273\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9400\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9523\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1330 - accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1274 - accuracy: 0.9551\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9638\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.9611\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1091 - accuracy: 0.9624\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9635\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9647\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9662\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9712\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9691\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9675\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9689\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.9726\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9687\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.9723\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9691\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9739\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9719\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9675\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9773\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.9708\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9744\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9761\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9742\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9685: 0s - loss: 0\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9755\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9776\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0705 - accuracy: 0.9778\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9765\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9778: 0s - loss: 0.0\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.9776\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9735\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9778\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9746\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9757\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9770\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9785\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9751\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9782\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9811\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9737\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9765\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9775\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9782\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9775\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9759\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9814\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9808\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9786\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9768\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9787\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9797\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9801\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9794\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9805\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9771\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9767\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9789\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9778\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9812\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9802\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9836\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9775\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9780\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9793\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9789\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9813\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9797\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9801\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9797\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9791\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9794\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9814\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0545 - accuracy: 0.9831\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9805\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9832\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9807: 0s - l\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0547 - accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9799: 0s -\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9817\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9828\n",
      "\tKFold: 5\n",
      "\tAcurácia do Treinamento: 98.36\n",
      "\tAcurácia do Teste: 98.45\n",
      "Acurácia do Especialista 4: 98.24\n",
      "Desvio Padrão do Especialista 4: 0.35\n",
      "\n",
      "Rede Neural Especialista: 5\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7929 - accuracy: 0.6307\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2350 - accuracy: 0.9091\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9366\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1543 - accuracy: 0.9469: \n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1267 - accuracy: 0.9538\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9594: 0s - loss: - ETA: 0s - loss: 0.1153 - accuracy: 0.\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1131 - accuracy: 0.9599\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9643\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9663\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9679\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9636\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9681\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9697\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9685\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9706: 0s - l\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.9710: 0s - loss: 0.081\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9769\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9714\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9728\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9724\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9712\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9732\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9715\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9742\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9721\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9759\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9757\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9778\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9742\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9762: 0s - los\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9790\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.9777\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9785\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9796\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9778\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9777\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9805\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9760\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9762\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9774\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9796\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9788\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9801\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9777\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9811\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9808\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9808\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9777\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.9787\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9809\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9791\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9826\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9798\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9826\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9816\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9807\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9824\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9817: 0s - loss:\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9770\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.9830\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9844\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.9828\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9773\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9823\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9824\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9804\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9805\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9833\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9844\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9829\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9804\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9856\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0534 - accuracy: 0.9814\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9778\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.9836\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9832\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9789\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9804\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9811\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9807\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9847\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9827\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9834\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.9845\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0494 - accuracy: 0.9830\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9869\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9828\n",
      "\tKFold: 1\n",
      "\tAcurácia do Treinamento: 98.80\n",
      "\tAcurácia do Teste: 97.89\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.8036 - accuracy: 0.6208\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9091\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1863 - accuracy: 0.9333\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9471\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9471\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1206 - accuracy: 0.9570\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1183 - accuracy: 0.9546\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9649\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1072 - accuracy: 0.9644\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.9628\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.9650\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9662\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9657\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9644\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9727\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9686\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9711\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9719\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9658\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9710\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.9714\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9743\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9774\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9755\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9686\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9747\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0777 - accuracy: 0.9744\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9723\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0727 - accuracy: 0.9772\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9722\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9731\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9755\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9734\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9766\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9766\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9759\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9777\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9783\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9770\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9732\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9779\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9794\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9740\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9779\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9739\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9780\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9790\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9740\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9799\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9795\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9742\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9789\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9801\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9766: 0s\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9772\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9784\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9793\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9792\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9782\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9806\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9774\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9770\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9793: 0s -\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9806\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9801\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0586 - accuracy: 0.9801\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9793\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9789\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9785\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9817\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9824\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9784\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9765: 0s -\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9807\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9772: 0s - l\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9802\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9813\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9779: 0s - loss:\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9819\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0503 - accuracy: 0.9837\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9824\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9793\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9775\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.9832\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9807\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9828\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9826\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.97 - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9791\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9806\n",
      "\tKFold: 2\n",
      "\tAcurácia do Treinamento: 98.60\n",
      "\tAcurácia do Teste: 98.84\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 0.7976 - accuracy: 0.6263\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2337 - accuracy: 0.9088\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9331\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9473\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9569\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9589\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1149 - accuracy: 0.9578\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.9573\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1130 - accuracy: 0.9591\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9655\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9651\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.96 - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9634\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9661\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9673\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.9706\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9718\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9697: 0s - loss: 0\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9732\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.9755\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9716\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9754\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.9745\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9677\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9732\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9742\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9775\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9757\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9738\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9769\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9741\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9765\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9749\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9743\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9772\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9792\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.9750\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9737\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.97 - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9778\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9750\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9785\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0723 - accuracy: 0.9761\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9759\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9776\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9759\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9748\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0708 - accuracy: 0.9785\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.9775\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9775\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9799\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9781\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9775\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9768\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9790\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9791\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9736\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9793\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9789\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9782\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9785\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9781\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9781\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9814: 0s - loss: 0.0\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9782\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9799\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9777\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9799\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9811\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9806\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9819\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0596 - accuracy: 0.9809\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9791\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9811\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9805\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9795\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9800\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9776\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9785\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9841\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0537 - accuracy: 0.9838\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9818\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9828\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9779\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9803\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0552 - accuracy: 0.9826\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9833\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9819\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9813\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9838\n",
      "\tKFold: 3\n",
      "\tAcurácia do Treinamento: 98.68\n",
      "\tAcurácia do Teste: 98.49\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7726 - accuracy: 0.6457\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.9008\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1845 - accuracy: 0.9296\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1519 - accuracy: 0.9441\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9528\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9543\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9657\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1115 - accuracy: 0.9606\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1063 - accuracy: 0.9612\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1041 - accuracy: 0.9646\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9661\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9680\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9717\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9684\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9681\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9691\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.9705\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9753\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9686\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9723\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9728\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9728\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9751\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9723\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9738\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9730\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9760\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9766\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9778\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9749\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9757\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.9775\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9764\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9753\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.9785\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0731 - accuracy: 0.9771\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9743\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9771\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9765\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9767\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9792\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9732\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9807\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9765\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9777\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9804\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9811\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9786\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9785\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9767\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9775\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9783\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9801\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9774\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9774\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9808\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9791\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9804\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9789\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.9763\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9796\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9796: 0s - loss:\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9798\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9811\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9805\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9797\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0544 - accuracy: 0.9824\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9811\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9790\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9799\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9794\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9774\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9830\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0625 - accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9806\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9779\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9830\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9780\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9832\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9811\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0596 - accuracy: 0.9811\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0630 - accuracy: 0.9791\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9813\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.9844\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9850\n",
      "\tKFold: 4\n",
      "\tAcurácia do Treinamento: 98.63\n",
      "\tAcurácia do Teste: 98.31\n",
      "Epoch 1/100\n",
      "356/356 [==============================] - 2s 3ms/step - loss: 0.7734 - accuracy: 0.6300\n",
      "Epoch 2/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.2344 - accuracy: 0.9107\n",
      "Epoch 3/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1862 - accuracy: 0.9320\n",
      "Epoch 4/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1558 - accuracy: 0.9432\n",
      "Epoch 5/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9502\n",
      "Epoch 6/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9525\n",
      "Epoch 7/100\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9560\n",
      "Epoch 8/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.9592\n",
      "Epoch 9/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1102 - accuracy: 0.9600\n",
      "Epoch 10/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.9652\n",
      "Epoch 11/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1035 - accuracy: 0.9624\n",
      "Epoch 12/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9661\n",
      "Epoch 13/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9672\n",
      "Epoch 14/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9696\n",
      "Epoch 15/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9700\n",
      "Epoch 16/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.9634\n",
      "Epoch 17/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9691\n",
      "Epoch 18/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9719\n",
      "Epoch 20/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9720\n",
      "Epoch 21/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9676\n",
      "Epoch 22/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9717\n",
      "Epoch 23/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9741\n",
      "Epoch 24/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9686\n",
      "Epoch 25/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9722\n",
      "Epoch 26/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9732\n",
      "Epoch 27/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9776\n",
      "Epoch 28/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.9735\n",
      "Epoch 29/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9749\n",
      "Epoch 30/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9738\n",
      "Epoch 31/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9723\n",
      "Epoch 32/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9756\n",
      "Epoch 33/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9757\n",
      "Epoch 34/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9724\n",
      "Epoch 35/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.9748\n",
      "Epoch 36/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0687 - accuracy: 0.9774\n",
      "Epoch 37/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.9739\n",
      "Epoch 38/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.9785\n",
      "Epoch 39/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.9778\n",
      "Epoch 40/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9775\n",
      "Epoch 41/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9741\n",
      "Epoch 42/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9786\n",
      "Epoch 43/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9778\n",
      "Epoch 44/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9814\n",
      "Epoch 45/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9765\n",
      "Epoch 46/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9778\n",
      "Epoch 47/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9764\n",
      "Epoch 48/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9770\n",
      "Epoch 49/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9749\n",
      "Epoch 50/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9756\n",
      "Epoch 51/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9812\n",
      "Epoch 53/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.9799\n",
      "Epoch 54/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9764\n",
      "Epoch 55/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9768\n",
      "Epoch 56/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9780\n",
      "Epoch 58/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9796\n",
      "Epoch 60/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9771\n",
      "Epoch 61/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9771\n",
      "Epoch 62/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.9817\n",
      "Epoch 64/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9779\n",
      "Epoch 65/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9789\n",
      "Epoch 66/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9787\n",
      "Epoch 67/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0547 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9819\n",
      "Epoch 69/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9758\n",
      "Epoch 70/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9818\n",
      "Epoch 71/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9787\n",
      "Epoch 72/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9807\n",
      "Epoch 73/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9805\n",
      "Epoch 74/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9794\n",
      "Epoch 75/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9788\n",
      "Epoch 76/100\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9825\n",
      "Epoch 77/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9809\n",
      "Epoch 78/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9795\n",
      "Epoch 79/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9799\n",
      "Epoch 80/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9813\n",
      "Epoch 82/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9805\n",
      "Epoch 83/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9859\n",
      "Epoch 84/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9824\n",
      "Epoch 85/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9819\n",
      "Epoch 86/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0610 - accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9817\n",
      "Epoch 88/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9781\n",
      "Epoch 89/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.9814\n",
      "Epoch 90/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9804\n",
      "Epoch 91/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.9809\n",
      "Epoch 92/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0533 - accuracy: 0.9824\n",
      "Epoch 93/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9775\n",
      "Epoch 94/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9835\n",
      "Epoch 95/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9817\n",
      "Epoch 96/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9819\n",
      "Epoch 97/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9809\n",
      "Epoch 99/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9816\n",
      "Epoch 100/100\n",
      "356/356 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9828\n",
      "\tKFold: 5\n",
      "\tAcurácia do Treinamento: 98.02\n",
      "\tAcurácia do Teste: 98.17\n",
      "Acurácia do Especialista 5: 98.34\n",
      "Desvio Padrão do Especialista 5: 0.32\n",
      "Acurácia da Rede Neural Especialista 1: 98.45\n",
      "Acurácia da Rede Neural Especialista 2: 98.26\n",
      "Acurácia da Rede Neural Especialista 3: 98.57\n",
      "Acurácia da Rede Neural Especialista 4: 98.38\n",
      "Acurácia da Rede Neural Especialista 5: 98.05\n",
      "Epoch 1/100\n",
      "445/445 [==============================] - 5s 4ms/step - loss: 0.2928 - accuracy: 0.9307\n",
      "Epoch 2/100\n",
      "445/445 [==============================] - 2s 4ms/step - loss: 0.0519 - accuracy: 0.9869\n",
      "Epoch 3/100\n",
      "445/445 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9874\n",
      "Epoch 4/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9878\n",
      "Epoch 5/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.9873\n",
      "Epoch 6/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9893\n",
      "Epoch 7/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.9870\n",
      "Epoch 8/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9877\n",
      "Epoch 9/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0455 - accuracy: 0.9880\n",
      "Epoch 10/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9857\n",
      "Epoch 11/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.9869\n",
      "Epoch 12/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.9882\n",
      "Epoch 13/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9878\n",
      "Epoch 14/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9874\n",
      "Epoch 15/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.9871: 0s -\n",
      "Epoch 18/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9873\n",
      "Epoch 19/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.9860\n",
      "Epoch 20/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.9858\n",
      "Epoch 21/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9894\n",
      "Epoch 22/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9873\n",
      "Epoch 23/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.9878\n",
      "Epoch 24/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9855\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9878\n",
      "Epoch 26/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.9870\n",
      "Epoch 27/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9882\n",
      "Epoch 28/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9900\n",
      "Epoch 29/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.9880\n",
      "Epoch 30/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0403 - accuracy: 0.9872\n",
      "Epoch 31/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9880\n",
      "Epoch 32/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9873\n",
      "Epoch 34/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.9845\n",
      "Epoch 35/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9890\n",
      "Epoch 36/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9887\n",
      "Epoch 37/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9857\n",
      "Epoch 38/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9870\n",
      "Epoch 39/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0426 - accuracy: 0.9870\n",
      "Epoch 40/100\n",
      "445/445 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9877\n",
      "Epoch 41/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9887\n",
      "Epoch 42/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9887\n",
      "Epoch 43/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0469 - accuracy: 0.9860\n",
      "Epoch 44/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.9882\n",
      "Epoch 45/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9882\n",
      "Epoch 46/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0441 - accuracy: 0.9865\n",
      "Epoch 47/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9862\n",
      "Epoch 48/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9875\n",
      "Epoch 49/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9872\n",
      "Epoch 50/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9879\n",
      "Epoch 51/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9886\n",
      "Epoch 52/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9892\n",
      "Epoch 53/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9868\n",
      "Epoch 54/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.9889\n",
      "Epoch 55/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.9883\n",
      "Epoch 56/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9874\n",
      "Epoch 57/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9875\n",
      "Epoch 58/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.9892\n",
      "Epoch 59/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0407 - accuracy: 0.9876\n",
      "Epoch 60/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9881\n",
      "Epoch 61/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9874\n",
      "Epoch 62/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9899\n",
      "Epoch 63/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9891\n",
      "Epoch 64/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9892\n",
      "Epoch 65/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9892\n",
      "Epoch 66/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0407 - accuracy: 0.9877\n",
      "Epoch 67/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0442 - accuracy: 0.9870\n",
      "Epoch 68/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9869\n",
      "Epoch 69/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9867\n",
      "Epoch 70/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.9860\n",
      "Epoch 71/100\n",
      "445/445 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9892\n",
      "Epoch 72/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0423 - accuracy: 0.9877\n",
      "Epoch 73/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9882\n",
      "Epoch 75/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9873\n",
      "Epoch 76/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0432 - accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9885\n",
      "Epoch 78/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9882\n",
      "Epoch 79/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0346 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9874\n",
      "Epoch 81/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.9869: 0s\n",
      "Epoch 82/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0438 - accuracy: 0.9861\n",
      "Epoch 83/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9877\n",
      "Epoch 84/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9877\n",
      "Epoch 85/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9897\n",
      "Epoch 86/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9881\n",
      "Epoch 87/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9892\n",
      "Epoch 88/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0429 - accuracy: 0.9878\n",
      "Epoch 89/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9883\n",
      "Epoch 90/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9870: 0s\n",
      "Epoch 91/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0361 - accuracy: 0.9885\n",
      "Epoch 92/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9881\n",
      "Epoch 93/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9885\n",
      "Epoch 94/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9882\n",
      "Epoch 95/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.9890\n",
      "Epoch 96/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0385 - accuracy: 0.9889\n",
      "Epoch 97/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9877\n",
      "Epoch 98/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9878\n",
      "Epoch 100/100\n",
      "445/445 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9870\n",
      "Acurácia da Rede Neural Decisora: 98.85\n"
     ]
    }
   ],
   "source": [
    "# KFold cross validation\n",
    "seed = 123\n",
    "num_members = 5\n",
    "np.random.seed(seed)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for i in range(num_members):\n",
    "    aux_fold = 1\n",
    "    accuracy = []\n",
    "    print('\\nRede Neural Especialista: {}'.format(i+1))\n",
    "    for train, test in skf.split(X, Y):\n",
    "        # Divide the kfold in train and test\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        Y = Y.reshape(-1, 1)\n",
    "        Y_train = to_categorical(Y[train])\n",
    "        Y_test = to_categorical(Y[test])\n",
    "\n",
    "        # Train the modelo\n",
    "        model = fit_model(X_train, Y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        _, score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "        _, score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        print('\\tKFold: {}'.format(aux_fold))\n",
    "        print('\\tAcurácia do Treinamento: {:.2f}'.format(score_train*100))\n",
    "        print('\\tAcurácia do Teste: {:.2f}'.format(score_test*100))\n",
    "\n",
    "        # Scores\n",
    "        _, score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        accuracy.append(score*100)\n",
    "        aux_fold += 1\n",
    "\n",
    "    # Show the scores\n",
    "    print('Acurácia do Especialista {}: {:.2f}'.format(i+1, np.mean(accuracy)))\n",
    "    print('Desvio Padrão do Especialista {}: {:.2f}'.format(i+1, np.std(accuracy)))\n",
    "\n",
    "    # Save the model\n",
    "    filename = 'model\\modelo_rede_especialista_{}.h5'.format(i+1)\n",
    "    model.save(filename)\n",
    "    # Save the model and weights\n",
    "    model_json = model.to_json()\n",
    "    filename_model = 'model\\modelo_rede_especialista_{}.json'.format(i+1)\n",
    "    with open(filename_model, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "\n",
    "# Load all models\n",
    "i = 1\n",
    "Y_test_member = to_categorical(Y)\n",
    "all_members = load_all_models_members(num_members)\n",
    "for model_member in all_members:\n",
    "    _, acc = model_member.evaluate(X, Y_test_member, verbose=0)\n",
    "    print('Acurácia da Rede Neural Especialista {}: {:.2f}'.format(i, acc*100))\n",
    "    i += 1\n",
    "\n",
    "# Define combined model\n",
    "modelo_decisor = define_decisor_model(all_members)\n",
    "# Fit decision model for the test dataset\n",
    "modelo_decisor = fit_decisor_model(modelo_decisor, X, Y)\n",
    "# Predict and evaluate\n",
    "Y_pred = predict_decisor_model(modelo_decisor, X)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "acc = accuracy_score(Y, Y_pred)\n",
    "print('Acurácia da Rede Neural Decisora: {:.2f}'.format(acc*100))\n",
    "\n",
    "# Save the model decisor\n",
    "filename = 'model\\pesos_rede_decisora.h5'\n",
    "modelo_decisor.save_weights(filename)\n",
    "# Save the model as .json\n",
    "filename_model =  'model\\modelo_rede_decisora.json'\n",
    "model_json = modelo_decisor.to_json()\n",
    "with open(filename_model, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD DATASET FROM DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Insert result into database.\n",
    "    \"\"\"\n",
    "    # Add database path\n",
    "    os.environ['PATH'] = 'C:\\oracle\\instantclient_11_2\\;' + os.environ['PATH']\n",
    "    \n",
    "    # Tests/Connects database connection\n",
    "    dsn_tns = cx_Oracle.makedsn('brspodbadm01.odontoprev.com.br', '1721', service_name='DCMSDSV')\n",
    "    conn = cx_Oracle.connect(user=r'admprod', password='ad0dpvit2ad1600d#V', dsn=dsn_tns, mode=cx_Oracle.DEFAULT_AUTH)\n",
    "    \n",
    "    sql = f'SELECT * FROM TBIA_CIR_CALC_FRAUDE'\n",
    "    \n",
    "    DF = pd.read_sql(sql, conn)\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153305, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = X_save.copy()\n",
    "#df = pd.read_excel('CLUSTERIZACAO_PILAR_FRAUDE_GERAL_20210208.xlsx') \n",
    "\n",
    "X_save_bkp = df.copy()\n",
    "\n",
    "df.shape\n",
    "              \n",
    "#y = df['CLASSE']\n",
    "df = df.drop(['REFERENCIA', 'CD_CIR_DENTISTA', 'NR_CGCCPF', 'CD_ESPECIALIDADE_EVENTO', 'NM_UNIDADE', 'FAIXA_POPULACAO'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>CUSTO_MED_TRATA_NO_MES</th>\n",
       "      <th>CUSTO_MD_TRATA_DO_DENT_NO_ANO</th>\n",
       "      <th>CUST_MD_TRATA_DOS_PARES_NO_MS</th>\n",
       "      <th>CUSTO_MED_BENE_NO_MES</th>\n",
       "      <th>CUSTO_MD_BENE_DO_DENT_NO_ANO</th>\n",
       "      <th>CUST_MD_BENE_DOS_PARES_NO_MS</th>\n",
       "      <th>QT_FRAGMENTACAO_DE_EVENTOS</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_MES</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>151.125000</td>\n",
       "      <td>6.293565</td>\n",
       "      <td>112.077032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.777500</td>\n",
       "      <td>11.892697</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.777500</td>\n",
       "      <td>12.067374</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.408378</td>\n",
       "      <td>0.437420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>143.324167</td>\n",
       "      <td>9.385081</td>\n",
       "      <td>130.887540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.291765</td>\n",
       "      <td>20.565421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.087273</td>\n",
       "      <td>21.287855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.663829</td>\n",
       "      <td>0.416439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>203.820000</td>\n",
       "      <td>23.733245</td>\n",
       "      <td>375.271774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>52.540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.426667</td>\n",
       "      <td>25.656165</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.426667</td>\n",
       "      <td>25.786405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.422307</td>\n",
       "      <td>0.404817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>12.078317</td>\n",
       "      <td>833.158451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.202885</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.275518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.677634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>75.985833</td>\n",
       "      <td>8.137233</td>\n",
       "      <td>1219.415692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>216.060000</td>\n",
       "      <td>144.246177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>216.060000</td>\n",
       "      <td>158.353146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.764003</td>\n",
       "      <td>0.445066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12.788000</td>\n",
       "      <td>7.915495</td>\n",
       "      <td>497.083921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>127.880000</td>\n",
       "      <td>91.323135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>127.880000</td>\n",
       "      <td>98.144651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.363295</td>\n",
       "      <td>0.426636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153301</td>\n",
       "      <td>1</td>\n",
       "      <td>20.08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>58.768182</td>\n",
       "      <td>9.385081</td>\n",
       "      <td>130.887540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.08</td>\n",
       "      <td>29.554286</td>\n",
       "      <td>20.565421</td>\n",
       "      <td>20.08</td>\n",
       "      <td>44.331429</td>\n",
       "      <td>21.287855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.42228</td>\n",
       "      <td>0.419415</td>\n",
       "      <td>0.416439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.932857</td>\n",
       "      <td>9.385081</td>\n",
       "      <td>130.887540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.765000</td>\n",
       "      <td>20.565421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.765000</td>\n",
       "      <td>21.287855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.355210</td>\n",
       "      <td>0.416439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.040000</td>\n",
       "      <td>7.915495</td>\n",
       "      <td>497.083921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.560000</td>\n",
       "      <td>91.323135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.560000</td>\n",
       "      <td>98.144651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.426636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>50.640000</td>\n",
       "      <td>23.733245</td>\n",
       "      <td>375.271774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.702857</td>\n",
       "      <td>25.656165</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.702857</td>\n",
       "      <td>25.786405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.400011</td>\n",
       "      <td>0.404817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153305 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "0                             0                     0.00   \n",
       "1                             0                     0.00   \n",
       "2                             0                     0.00   \n",
       "3                             0                     0.00   \n",
       "4                             0                     0.00   \n",
       "...                         ...                      ...   \n",
       "153300                        0                     0.00   \n",
       "153301                        1                    20.08   \n",
       "153302                        0                     0.00   \n",
       "153303                        0                     0.00   \n",
       "153304                        0                     0.00   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "0                           10.000000                     151.125000   \n",
       "1                            3.833333                     143.324167   \n",
       "2                           12.000000                     203.820000   \n",
       "3                            0.250000                       3.010000   \n",
       "4                            0.250000                      75.985833   \n",
       "...                               ...                            ...   \n",
       "153300                       0.400000                      12.788000   \n",
       "153301                       3.000000                      58.768182   \n",
       "153302                       0.714286                       7.932857   \n",
       "153303                       1.000000                      29.040000   \n",
       "153304                       3.333333                      50.640000   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "0                             6.293565                      112.077032   \n",
       "1                             9.385081                      130.887540   \n",
       "2                            23.733245                      375.271774   \n",
       "3                            12.078317                      833.158451   \n",
       "4                             8.137233                     1219.415692   \n",
       "...                                ...                             ...   \n",
       "153300                        7.915495                      497.083921   \n",
       "153301                        9.385081                      130.887540   \n",
       "153302                        9.385081                      130.887540   \n",
       "153303                        7.915495                      497.083921   \n",
       "153304                       23.733245                      375.271774   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "0                           0                    0.0   \n",
       "1                           0                    0.0   \n",
       "2                           0                    0.0   \n",
       "3                           0                    0.0   \n",
       "4                           0                    0.0   \n",
       "...                       ...                    ...   \n",
       "153300                      0                    0.0   \n",
       "153301                      0                    0.0   \n",
       "153302                      0                    0.0   \n",
       "153303                      0                    0.0   \n",
       "153304                      0                    0.0   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "0                             0.000                        0.000  ...   \n",
       "1                             0.000                        0.000  ...   \n",
       "2                             2.000                       52.540  ...   \n",
       "3                             0.125                        1.505  ...   \n",
       "4                             0.000                        0.000  ...   \n",
       "...                             ...                          ...  ...   \n",
       "153300                        0.000                        0.000  ...   \n",
       "153301                        0.000                        0.000  ...   \n",
       "153302                        0.000                        0.000  ...   \n",
       "153303                        0.000                        0.000  ...   \n",
       "153304                        0.000                        0.000  ...   \n",
       "\n",
       "        CUSTO_MED_TRATA_NO_MES  CUSTO_MD_TRATA_DO_DENT_NO_ANO  \\\n",
       "0                         0.00                       3.777500   \n",
       "1                         0.00                      47.291765   \n",
       "2                         0.00                      50.426667   \n",
       "3                         0.00                       0.000000   \n",
       "4                         0.00                     216.060000   \n",
       "...                        ...                            ...   \n",
       "153300                    0.00                     127.880000   \n",
       "153301                   20.08                      29.554286   \n",
       "153302                    0.00                      27.765000   \n",
       "153303                    0.00                      43.560000   \n",
       "153304                    0.00                      21.702857   \n",
       "\n",
       "        CUST_MD_TRATA_DOS_PARES_NO_MS  CUSTO_MED_BENE_NO_MES  \\\n",
       "0                           11.892697                   0.00   \n",
       "1                           20.565421                   0.00   \n",
       "2                           25.656165                   0.00   \n",
       "3                           59.202885                   0.00   \n",
       "4                          144.246177                   0.00   \n",
       "...                               ...                    ...   \n",
       "153300                      91.323135                   0.00   \n",
       "153301                      20.565421                  20.08   \n",
       "153302                      20.565421                   0.00   \n",
       "153303                      91.323135                   0.00   \n",
       "153304                      25.656165                   0.00   \n",
       "\n",
       "        CUSTO_MD_BENE_DO_DENT_NO_ANO  CUST_MD_BENE_DOS_PARES_NO_MS  \\\n",
       "0                           3.777500                     12.067374   \n",
       "1                          73.087273                     21.287855   \n",
       "2                          50.426667                     25.786405   \n",
       "3                           0.000000                     62.275518   \n",
       "4                         216.060000                    158.353146   \n",
       "...                              ...                           ...   \n",
       "153300                    127.880000                     98.144651   \n",
       "153301                     44.331429                     21.287855   \n",
       "153302                     27.765000                     21.287855   \n",
       "153303                     43.560000                     98.144651   \n",
       "153304                     21.702857                     25.786405   \n",
       "\n",
       "        QT_FRAGMENTACAO_DE_EVENTOS  QT_UO_MED_EVENTO_NO_MES  \\\n",
       "0                                0                  0.00000   \n",
       "1                                0                  0.00000   \n",
       "2                                0                  0.00000   \n",
       "3                                0                  0.00000   \n",
       "4                                0                  0.00000   \n",
       "...                            ...                      ...   \n",
       "153300                           0                  0.00000   \n",
       "153301                           0                  0.42228   \n",
       "153302                           0                  0.00000   \n",
       "153303                           0                  0.00000   \n",
       "153304                           0                  0.00000   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_ANO  QT_MED_UO_EVENTO_DOS_PARES  \n",
       "0                      0.408378                    0.437420  \n",
       "1                      0.663829                    0.416439  \n",
       "2                      0.422307                    0.404817  \n",
       "3                      0.000000                    1.677634  \n",
       "4                      0.764003                    0.445066  \n",
       "...                         ...                         ...  \n",
       "153300                 0.363295                    0.426636  \n",
       "153301                 0.419415                    0.416439  \n",
       "153302                 0.355210                    0.416439  \n",
       "153303                 0.330000                    0.426636  \n",
       "153304                 0.400011                    0.404817  \n",
       "\n",
       "[153305 rows x 37 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Baixo', 'Baixo', 'Baixo', ..., 'Baixo', 'Baixo', 'Baixo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the model parameters\n",
    "with open('model\\scaler.pickle', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "with open('model\\label.pickle', 'rb') as label_file:\n",
    "    le = pickle.load(label_file)\n",
    "# Feature scaling\n",
    "X = scaler.transform(df)\n",
    "\n",
    "# Load the model decisor\n",
    "filename_model = 'model\\modelo_rede_decisora.json'\n",
    "with open(filename_model, 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights('model\\pesos_rede_decisora.h5')\n",
    "\n",
    "# Shows model features\n",
    "#model.summary()\n",
    "\n",
    "# Predict\n",
    "y_pred = predict_decisor_model(model, X)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Transform label\n",
    "y_pred_inv = le.inverse_transform(y_pred)\n",
    "y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_save_bkp['CLASSIFICACAO'] = y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-8f6bb51fe24f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_save_bkp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mreferencia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'REFERENCIA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mcd_cir_dentista\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CD_CIR_DENTISTA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcd_especialidade_evento\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CD_ESPECIALIDADE_EVENTO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#df_export = X_save_bkp[X_save_bkp['CD_CIR_DENTISTA'].isin(cds_moderados)]\n",
    "\n",
    "#len(cds_moderados)\n",
    "#X_save_bkp[X_save_bkp['CD_CIR_DENTISTA'].isin(cd_descredenciados)][X_save_bkp['CLASSE'] == 'Moderado']\n",
    "#df_export\n",
    "#X_save_bkp.to_excel('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_prod():\n",
    "    \"\"\"Insert result into database.\n",
    "    \"\"\"\n",
    "    # Add database path\n",
    "    os.environ['PATH'] = 'C:\\oracle\\instantclient_11_2\\;' + os.environ['PATH']\n",
    "    \n",
    "    # Tests/Connects database connection\n",
    "    dsn_tns = cx_Oracle.makedsn('brspodbadm01.odontoprev.com.br', '1721', service_name='DCMSDSV')\n",
    "    conn = cx_Oracle.connect(user=r'admprod', password='ad0dpvit2ad1600d#V', dsn=dsn_tns, mode=cx_Oracle.DEFAULT_AUTH)\n",
    "\n",
    "    columns_name = ['REFERENCIA', 'CD_CIR_DENTISTA', 'NR_CGCCPF', 'CD_ESPECIALIDADE_EVENTO', 'CLASSIFICACAO']\n",
    "    classes = ['Baixo', 'Moderado', 'Alto']\n",
    "\n",
    "    for i, line in X_save_bkp[columns_name].iterrows():\n",
    "        referencia = line['REFERENCIA']\n",
    "        cd_cir_dentista = line['CD_CIR_DENTISTA']\n",
    "        nr_cgccpf = line['NR_CGCCPF']\n",
    "        cd_especialidade_evento = line['CD_ESPECIALIDADE_EVENTO']\n",
    "        \n",
    "        #print(referencia)\n",
    "        comportamental = random.choice(classes)\n",
    "        tecnico = random.choice(classes)\n",
    "        classificacao = line['CLASSIFICACAO']\n",
    "\n",
    " \n",
    "\n",
    "        sql_string = f'''\n",
    "            INSERT INTO TBIA_CIR_CLAS_GERAL_DENT_TEST(\"Referencia\", CD_CIR_DENTISTA, NR_CGCCPF,\n",
    "                CD_ESPECIALIDADE, COMPORTAMENTAL, TECNICO, FRAUDE)\n",
    "            VALUES ( TO_DATE('{referencia}','yyyy/mm/dd hh24:mi:ss'), '{cd_cir_dentista}', '{nr_cgccpf}', \n",
    "                {cd_especialidade_evento},'{comportamental}', '{tecnico}', '{classificacao}')'''\n",
    "        #print(sql_string)\n",
    "        \n",
    "        try:\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(sql_string)\n",
    "        except Exception as e:\n",
    "            ds_msg_error = 'ERRO AO INSEIR NO BANCO'\n",
    "            ds_error = 'Error: {}'.format(e)\n",
    "            print(ds_msg_error, ds_error)\n",
    "            continue\n",
    "\n",
    " \n",
    "\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "            conn.commit()\n",
    "\n",
    " \n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6bca25de9bab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minsert_data_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-ccfcaf888b48>\u001b[0m in \u001b[0;36minsert_data_prod\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mds_msg_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ERRO AO INSEIR NO BANCO'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "insert_data_prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica os dentistas moderados na classe dada pelo kmeans, quais deles são altos na rede neural\n",
    "moderados = []\n",
    "alto = []\n",
    "total = []\n",
    "for indice, linha in df_export.iterrows():\n",
    "    #total.append(linha['CLASSE'])\n",
    "    if linha['CLASSE'] == 'Moderado': #Classe kmeans\n",
    "        total.append(linha['CLASSE'])\n",
    "        if linha['CLASSE_REDE_NEURAL'] == 'Moderado': #Classe rede rede neural\n",
    "            moderados.append(linha['CLASSE_REDE_NEURAL'])\n",
    "        else:\n",
    "            alto.append(linha['CLASSE_REDE_NEURAL'])\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentual_alto, percentual_moderado = len(alto) / len(total), len(moderados) / len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 75, 157)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moderados), len(alto), len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>QT_FRAGMENTACAO_DE_EVENTOS</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_MES</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "      <th>CLASSE_REDE_NEURAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>136986</td>\n",
       "      <td>44</td>\n",
       "      <td>1045.21</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>2578.1325</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>50.816667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357352</td>\n",
       "      <td>0.356768</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>314744</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145663</td>\n",
       "      <td>27</td>\n",
       "      <td>531.39</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>582.9500</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357234</td>\n",
       "      <td>0.356624</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>314744</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "136986                       44                  1045.21   \n",
       "145663                       27                   531.39   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "136986                     110.250000                      2578.1325   \n",
       "145663                      29.666667                       582.9500   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "136986                       27.665424                      837.458084   \n",
       "145663                       23.948367                      552.884925   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "136986                      0                    0.0   \n",
       "145663                      0                    0.0   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "136986                     2.166667                    50.816667  ...   \n",
       "145663                     0.000000                     0.000000  ...   \n",
       "\n",
       "        QT_FRAGMENTACAO_DE_EVENTOS  QT_UO_MED_EVENTO_NO_MES  \\\n",
       "136986                           0                 0.357352   \n",
       "145663                           0                 0.357234   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_ANO  QT_MED_UO_EVENTO_DOS_PARES  CD_CIR_DENTISTA  \\\n",
       "136986                 0.356768                    0.409064           314744   \n",
       "145663                 0.356624                    0.400164           314744   \n",
       "\n",
       "        CD_ESPECIALIDADE  FAIXA_POPULACAO  NM_UNIDADE    CLASSE  \\\n",
       "136986                 2                7        UNNA  Moderado   \n",
       "145663                 4                7        UNNA  Moderado   \n",
       "\n",
       "        CLASSE_REDE_NEURAL  \n",
       "136986                Alto  \n",
       "145663            Moderado  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_export[(df_export['CD_CIR_DENTISTA'].isin(cds_moderados)) & \n",
    "          (df_export['CLASSE'] == 'Moderado') & \n",
    "          (df_export['CD_CIR_DENTISTA'] == '314744')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export['grau_risco'] = 0\n",
    "df_export.loc[df_export['CLASSE_REDE_NEURAL'] == 'Baixo', 'grau_risco'] = 1\n",
    "df_export.loc[df_export['CLASSE_REDE_NEURAL'] == 'Moderado', 'grau_risco'] = 2\n",
    "df_export.loc[df_export['CLASSE_REDE_NEURAL'] == 'Alto', 'grau_risco'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_MES</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "      <th>CLASSE_REDE_NEURAL</th>\n",
       "      <th>grau_risco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>2510.875000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>30.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>403485</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120.700000</td>\n",
       "      <td>3031.835000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>66.119000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>337020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>3327.930000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>194.327500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356025</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>363725</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19607</td>\n",
       "      <td>104</td>\n",
       "      <td>2125.76</td>\n",
       "      <td>80.083333</td>\n",
       "      <td>1606.973333</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>10</td>\n",
       "      <td>209.42</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>139.151667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300417</td>\n",
       "      <td>0.298056</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>ARB001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>2573.340000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352542</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>ESP401</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148905</td>\n",
       "      <td>108</td>\n",
       "      <td>2215.24</td>\n",
       "      <td>68.916667</td>\n",
       "      <td>1459.052500</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>14.131667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291221</td>\n",
       "      <td>0.289511</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>328856</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>136.600000</td>\n",
       "      <td>2759.558000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>29.154000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301145</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>390943</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151563</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116.166667</td>\n",
       "      <td>3287.060000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>380989</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152763</td>\n",
       "      <td>38</td>\n",
       "      <td>805.60</td>\n",
       "      <td>112.222222</td>\n",
       "      <td>2392.375556</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>1</td>\n",
       "      <td>21.20</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>119.813333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326154</td>\n",
       "      <td>0.326497</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>364214</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.200000</td>\n",
       "      <td>3070.236000</td>\n",
       "      <td>27.665424</td>\n",
       "      <td>837.458084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452016</td>\n",
       "      <td>0.409064</td>\n",
       "      <td>390856</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "1919                          0                     0.00   \n",
       "4895                          0                     0.00   \n",
       "7946                          0                     0.00   \n",
       "19607                       104                  2125.76   \n",
       "19888                         0                     0.00   \n",
       "...                         ...                      ...   \n",
       "148905                      108                  2215.24   \n",
       "151227                        0                     0.00   \n",
       "151563                        0                     0.00   \n",
       "152763                       38                   805.60   \n",
       "153220                        0                     0.00   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "1919                       123.500000                    2510.875000   \n",
       "4895                       120.700000                    3031.835000   \n",
       "7946                       139.250000                    3327.930000   \n",
       "19607                       80.083333                    1606.973333   \n",
       "19888                      112.000000                    2573.340000   \n",
       "...                               ...                            ...   \n",
       "148905                      68.916667                    1459.052500   \n",
       "151227                     136.600000                    2759.558000   \n",
       "151563                     116.166667                    3287.060000   \n",
       "152763                     112.222222                    2392.375556   \n",
       "153220                     104.200000                    3070.236000   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "1919                         27.665424                      837.458084   \n",
       "4895                         27.665424                      837.458084   \n",
       "7946                         27.665424                      837.458084   \n",
       "19607                        27.665424                      837.458084   \n",
       "19888                        27.665424                      837.458084   \n",
       "...                                ...                             ...   \n",
       "148905                       27.665424                      837.458084   \n",
       "151227                       27.665424                      837.458084   \n",
       "151563                       27.665424                      837.458084   \n",
       "152763                       27.665424                      837.458084   \n",
       "153220                       27.665424                      837.458084   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "1919                        0                   0.00   \n",
       "4895                        0                   0.00   \n",
       "7946                        0                   0.00   \n",
       "19607                      10                 209.42   \n",
       "19888                       0                   0.00   \n",
       "...                       ...                    ...   \n",
       "148905                      0                   0.00   \n",
       "151227                      0                   0.00   \n",
       "151563                      0                   0.00   \n",
       "152763                      1                  21.20   \n",
       "153220                      0                   0.00   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "1919                       1.500000                    30.225000  ...   \n",
       "4895                       2.700000                    66.119000  ...   \n",
       "7946                       8.250000                   194.327500  ...   \n",
       "19607                      6.666667                   139.151667  ...   \n",
       "19888                      1.000000                    22.930000  ...   \n",
       "...                             ...                          ...  ...   \n",
       "148905                     0.583333                    14.131667  ...   \n",
       "151227                     1.600000                    29.154000  ...   \n",
       "151563                     1.000000                    28.160000  ...   \n",
       "152763                     5.666667                   119.813333  ...   \n",
       "153220                     1.000000                    29.380000  ...   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_MES  QT_UO_MED_EVENTO_NO_ANO  \\\n",
       "1919                   0.000000                 0.310000   \n",
       "4895                   0.000000                 0.376324   \n",
       "7946                   0.000000                 0.356025   \n",
       "19607                  0.300417                 0.298056   \n",
       "19888                  0.000000                 0.352542   \n",
       "...                         ...                      ...   \n",
       "148905                 0.291221                 0.289511   \n",
       "151227                 0.000000                 0.301145   \n",
       "151563                 0.000000                 0.432836   \n",
       "152763                 0.326154                 0.326497   \n",
       "153220                 0.000000                 0.452016   \n",
       "\n",
       "        QT_MED_UO_EVENTO_DOS_PARES  CD_CIR_DENTISTA  CD_ESPECIALIDADE  \\\n",
       "1919                      0.409064           403485                 2   \n",
       "4895                      0.409064           337020                 2   \n",
       "7946                      0.409064           363725                 2   \n",
       "19607                     0.409064           ARB001                 2   \n",
       "19888                     0.409064           ESP401                 2   \n",
       "...                            ...              ...               ...   \n",
       "148905                    0.409064           328856                 2   \n",
       "151227                    0.409064           390943                 2   \n",
       "151563                    0.409064           380989                 2   \n",
       "152763                    0.409064           364214                 2   \n",
       "153220                    0.409064           390856                 2   \n",
       "\n",
       "        FAIXA_POPULACAO  NM_UNIDADE    CLASSE  CLASSE_REDE_NEURAL  grau_risco  \n",
       "1919                  4        UNNA  Moderado                Alto           3  \n",
       "4895                  7        UNNA  Moderado                Alto           3  \n",
       "7946                  3        UNNA  Moderado                Alto           3  \n",
       "19607                 4        UNNA  Moderado                Alto           3  \n",
       "19888                 4        UNNA  Moderado                Alto           3  \n",
       "...                 ...         ...       ...                 ...         ...  \n",
       "148905                6        UNNA  Moderado                Alto           3  \n",
       "151227                3        UNNA  Moderado                Alto           3  \n",
       "151563                1        UNNA  Moderado                Alto           3  \n",
       "152763                4        UNNA  Moderado                Alto           3  \n",
       "153220                3        UNNA  Moderado                Alto           3  \n",
       "\n",
       "[77 rows x 44 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_export[df_export['CLASSE_REDE_NEURAL'] == 'Alto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379849 Alto Alto\n",
      "BEC001 Alto Alto\n",
      "73997P Alto Alto\n",
      "SFT101 Alto Alto\n",
      "274644 Alto Alto\n",
      "316253 Alto Alto\n",
      "324680 Alto Alto\n",
      "QUE901 Alto Alto\n",
      "XSP901 Alto Alto\n",
      "WSV301 Alto Alto\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_export.shape[0]):\n",
    "    if df_export['CLASSE'].values[i] == 'Alto':\n",
    "        print(df_export['CD_CIR_DENTISTA'].values[i], df_export['CLASSE'].values[i], df_export['CLASSE_REDE_NEURAL'].values[i])\n",
    "\n",
    "#df_export\n",
    "#df_export.loc[(df_export['CD_CIR_DENTISTA'].isin(cd_descredenciados)) & (df_export['CLASSE'] == 'Alto')]['CD_CIR_DENTISTA']\n",
    "#X_save.loc[(X_save['CD_CIR_DENTISTA'].isin(cd_descredenciados))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_save_bkp.to_excel('MODELO_RNA_FRAUDE_GERAL.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>QT_FRAGMENTACAO_DE_EVENTOS</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_MES</th>\n",
       "      <th>QT_UO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "      <th>CLASSE_REDE_NEURAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.430000</td>\n",
       "      <td>7.444786</td>\n",
       "      <td>460.430652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432035</td>\n",
       "      <td>394051</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>7.062000</td>\n",
       "      <td>8.979918</td>\n",
       "      <td>127.372096</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626842</td>\n",
       "      <td>0.413129</td>\n",
       "      <td>411461</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>24.887500</td>\n",
       "      <td>7.444786</td>\n",
       "      <td>460.430652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522271</td>\n",
       "      <td>0.432035</td>\n",
       "      <td>RNM001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334438</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>313135</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154634</td>\n",
       "      <td>4</td>\n",
       "      <td>44.36</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.203636</td>\n",
       "      <td>8.979918</td>\n",
       "      <td>127.372096</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.443108</td>\n",
       "      <td>0.413129</td>\n",
       "      <td>380540</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154635</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>52.783333</td>\n",
       "      <td>23.948367</td>\n",
       "      <td>552.884925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638637</td>\n",
       "      <td>0.400164</td>\n",
       "      <td>387743</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>19.410000</td>\n",
       "      <td>44.505451</td>\n",
       "      <td>686.547980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>19.4100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346676</td>\n",
       "      <td>395513</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.292000</td>\n",
       "      <td>7.444786</td>\n",
       "      <td>460.430652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432035</td>\n",
       "      <td>398118</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Baixo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154638</td>\n",
       "      <td>8</td>\n",
       "      <td>1125.45</td>\n",
       "      <td>16.583333</td>\n",
       "      <td>2540.698333</td>\n",
       "      <td>7.665254</td>\n",
       "      <td>1138.794204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>36.0275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533809</td>\n",
       "      <td>0.533415</td>\n",
       "      <td>0.446634</td>\n",
       "      <td>380958</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Moderado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154639 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "0                             0                     0.00   \n",
       "1                             0                     0.00   \n",
       "2                             0                     0.00   \n",
       "3                             0                     0.00   \n",
       "4                             0                     0.00   \n",
       "...                         ...                      ...   \n",
       "154634                        4                    44.36   \n",
       "154635                        0                     0.00   \n",
       "154636                        0                     0.00   \n",
       "154637                        0                     0.00   \n",
       "154638                        8                  1125.45   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "0                            1.000000                      98.430000   \n",
       "1                            0.200000                       7.062000   \n",
       "2                            0.500000                      24.887500   \n",
       "3                            0.000000                       0.000000   \n",
       "4                            0.000000                       0.000000   \n",
       "...                               ...                            ...   \n",
       "154634                       2.000000                      27.203636   \n",
       "154635                       1.500000                      52.783333   \n",
       "154636                       4.000000                      19.410000   \n",
       "154637                       0.100000                       3.292000   \n",
       "154638                      16.583333                    2540.698333   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "0                             7.444786                      460.430652   \n",
       "1                             8.979918                      127.372096   \n",
       "2                             7.444786                      460.430652   \n",
       "3                             0.466210                        0.000000   \n",
       "4                             0.466210                        0.000000   \n",
       "...                                ...                             ...   \n",
       "154634                        8.979918                      127.372096   \n",
       "154635                       23.948367                      552.884925   \n",
       "154636                       44.505451                      686.547980   \n",
       "154637                        7.444786                      460.430652   \n",
       "154638                        7.665254                     1138.794204   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "0                           0                    0.0   \n",
       "1                           0                    0.0   \n",
       "2                           0                    0.0   \n",
       "3                           0                    0.0   \n",
       "4                           0                    0.0   \n",
       "...                       ...                    ...   \n",
       "154634                      0                    0.0   \n",
       "154635                      0                    0.0   \n",
       "154636                      0                    0.0   \n",
       "154637                      0                    0.0   \n",
       "154638                      0                    0.0   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "0                              0.00                       0.0000  ...   \n",
       "1                              0.00                       0.0000  ...   \n",
       "2                              0.00                       0.0000  ...   \n",
       "3                              0.00                       0.0000  ...   \n",
       "4                              0.00                       0.0000  ...   \n",
       "...                             ...                          ...  ...   \n",
       "154634                         0.00                       0.0000  ...   \n",
       "154635                         0.00                       0.0000  ...   \n",
       "154636                         4.00                      19.4100  ...   \n",
       "154637                         0.00                       0.0000  ...   \n",
       "154638                         0.25                      36.0275  ...   \n",
       "\n",
       "        QT_FRAGMENTACAO_DE_EVENTOS  QT_UO_MED_EVENTO_NO_MES  \\\n",
       "0                                0                 0.000000   \n",
       "1                                0                 0.000000   \n",
       "2                                0                 0.000000   \n",
       "3                                0                 0.000000   \n",
       "4                                0                 0.000000   \n",
       "...                            ...                      ...   \n",
       "154634                           0                 0.443600   \n",
       "154635                           0                 0.000000   \n",
       "154636                           0                 0.000000   \n",
       "154637                           0                 0.000000   \n",
       "154638                           0                 0.533809   \n",
       "\n",
       "        QT_UO_MED_EVENTO_NO_ANO  QT_MED_UO_EVENTO_DOS_PARES  CD_CIR_DENTISTA  \\\n",
       "0                      0.000000                    0.432035           394051   \n",
       "1                      0.626842                    0.413129           411461   \n",
       "2                      0.522271                    0.432035           RNM001   \n",
       "3                      0.000000                    0.000000           334438   \n",
       "4                      0.000000                    0.000000           313135   \n",
       "...                         ...                         ...              ...   \n",
       "154634                 0.443108                    0.413129           380540   \n",
       "154635                 0.638637                    0.400164           387743   \n",
       "154636                 0.000000                    0.346676           395513   \n",
       "154637                 0.000000                    0.432035           398118   \n",
       "154638                 0.533415                    0.446634           380958   \n",
       "\n",
       "        CD_ESPECIALIDADE  FAIXA_POPULACAO  NM_UNIDADE    CLASSE  \\\n",
       "0                      5                4        UNNA     Baixo   \n",
       "1                      9                3        UNNA     Baixo   \n",
       "2                      5                1        UNNA     Baixo   \n",
       "3                      1                2        UNNA     Baixo   \n",
       "4                      1                4        UNNA     Baixo   \n",
       "...                  ...              ...         ...       ...   \n",
       "154634                 9                3        UNNA     Baixo   \n",
       "154635                 4                6        UNNA     Baixo   \n",
       "154636                14                1        UNNA     Baixo   \n",
       "154637                 5                3        UNNA     Baixo   \n",
       "154638                 3                1        UNNA  Moderado   \n",
       "\n",
       "        CLASSE_REDE_NEURAL  \n",
       "0                    Baixo  \n",
       "1                    Baixo  \n",
       "2                    Baixo  \n",
       "3                    Baixo  \n",
       "4                    Baixo  \n",
       "...                    ...  \n",
       "154634               Baixo  \n",
       "154635               Baixo  \n",
       "154636               Baixo  \n",
       "154637               Baixo  \n",
       "154638            Moderado  \n",
       "\n",
       "[154639 rows x 43 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_save_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valclemir\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QT_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>VL_TOTAL_EVENTOS_NO_MES</th>\n",
       "      <th>QT_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_EVENTOS_NO_ANO_DO_DENT</th>\n",
       "      <th>QT_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>VL_MED_EVENTO_DOS_PARES_NO_MES</th>\n",
       "      <th>QT_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>VL_TOTAL_GLOSA_NO_MES</th>\n",
       "      <th>QT_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>VL_MED_GLOSA_NO_ANO_DO_DENT</th>\n",
       "      <th>...</th>\n",
       "      <th>QT_MED_UO_EVENTO_DOS_PARES</th>\n",
       "      <th>CUSTO_MED_EVENTO_NO_MES</th>\n",
       "      <th>CUSTO_MED_EVENTO_NO_ANO</th>\n",
       "      <th>CUST_MD_EVEN_DOS_PARES_NO_MS</th>\n",
       "      <th>CD_CIR_DENTISTA</th>\n",
       "      <th>CD_ESPECIALIDADE</th>\n",
       "      <th>FAIXA_POPULACAO</th>\n",
       "      <th>NM_UNIDADE</th>\n",
       "      <th>CLASSE</th>\n",
       "      <th>CLASSE_REDE_NEURAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6212</td>\n",
       "      <td>39</td>\n",
       "      <td>788.19</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>1368.697500</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>19.691795</td>\n",
       "      <td>19.147419</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>386322</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.583333</td>\n",
       "      <td>3010.905000</td>\n",
       "      <td>22.162162</td>\n",
       "      <td>1524.015735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.688883</td>\n",
       "      <td>63.916161</td>\n",
       "      <td>73639P</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>BRADESCO</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43285</td>\n",
       "      <td>40</td>\n",
       "      <td>671.98</td>\n",
       "      <td>51.555556</td>\n",
       "      <td>857.808889</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>2</td>\n",
       "      <td>33.86</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>12.942222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>14.289000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>Z62101</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.111111</td>\n",
       "      <td>2566.115556</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.957248</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>319166</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49788</td>\n",
       "      <td>89</td>\n",
       "      <td>1545.93</td>\n",
       "      <td>59.083333</td>\n",
       "      <td>1044.392500</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>37.481667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>17.174831</td>\n",
       "      <td>15.969337</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>XSP901</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49921</td>\n",
       "      <td>42</td>\n",
       "      <td>2406.52</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>685.553000</td>\n",
       "      <td>22.162162</td>\n",
       "      <td>1524.015735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>7.663000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273758</td>\n",
       "      <td>55.631429</td>\n",
       "      <td>34.695590</td>\n",
       "      <td>63.916161</td>\n",
       "      <td>406891</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59193</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.166667</td>\n",
       "      <td>2654.450000</td>\n",
       "      <td>22.162162</td>\n",
       "      <td>1524.015735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>87.297500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.093245</td>\n",
       "      <td>63.916161</td>\n",
       "      <td>347778</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60785</td>\n",
       "      <td>18</td>\n",
       "      <td>446.40</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>570.716000</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>67.262000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>17.639930</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>406891</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61642</td>\n",
       "      <td>99</td>\n",
       "      <td>357.10</td>\n",
       "      <td>151.083333</td>\n",
       "      <td>544.175000</td>\n",
       "      <td>44.127020</td>\n",
       "      <td>682.879545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.800833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348669</td>\n",
       "      <td>3.607071</td>\n",
       "      <td>3.570044</td>\n",
       "      <td>13.658548</td>\n",
       "      <td>324680</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64633</td>\n",
       "      <td>48</td>\n",
       "      <td>822.24</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>1028.635000</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>16.654827</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>386322</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65093</td>\n",
       "      <td>25</td>\n",
       "      <td>742.00</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>959.361000</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>21.837600</td>\n",
       "      <td>25.304623</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>406891</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72587</td>\n",
       "      <td>19</td>\n",
       "      <td>1538.24</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1276.530000</td>\n",
       "      <td>22.162162</td>\n",
       "      <td>1524.015735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>53.726667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273758</td>\n",
       "      <td>80.960000</td>\n",
       "      <td>58.976790</td>\n",
       "      <td>63.916161</td>\n",
       "      <td>319166</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75112</td>\n",
       "      <td>60</td>\n",
       "      <td>692.26</td>\n",
       "      <td>43.083333</td>\n",
       "      <td>477.266667</td>\n",
       "      <td>22.733372</td>\n",
       "      <td>382.060089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>12.704167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428285</td>\n",
       "      <td>11.537667</td>\n",
       "      <td>10.763269</td>\n",
       "      <td>16.189830</td>\n",
       "      <td>QUE901</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80244</td>\n",
       "      <td>72</td>\n",
       "      <td>778.80</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>632.776667</td>\n",
       "      <td>22.733372</td>\n",
       "      <td>382.060089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.021667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428285</td>\n",
       "      <td>10.816667</td>\n",
       "      <td>10.320441</td>\n",
       "      <td>16.189830</td>\n",
       "      <td>386322</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82489</td>\n",
       "      <td>3</td>\n",
       "      <td>312.18</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>971.098333</td>\n",
       "      <td>7.409084</td>\n",
       "      <td>465.025457</td>\n",
       "      <td>2</td>\n",
       "      <td>262.64</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>172.410833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438453</td>\n",
       "      <td>16.513333</td>\n",
       "      <td>99.447079</td>\n",
       "      <td>53.573309</td>\n",
       "      <td>316253</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86032</td>\n",
       "      <td>42</td>\n",
       "      <td>844.10</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>447.610000</td>\n",
       "      <td>22.733372</td>\n",
       "      <td>382.060089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.647500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428285</td>\n",
       "      <td>20.097619</td>\n",
       "      <td>18.040669</td>\n",
       "      <td>16.189830</td>\n",
       "      <td>73997P</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>BRADESCO</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96266</td>\n",
       "      <td>8</td>\n",
       "      <td>862.48</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>296.076667</td>\n",
       "      <td>7.625572</td>\n",
       "      <td>1148.890095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452407</td>\n",
       "      <td>79.102500</td>\n",
       "      <td>85.752647</td>\n",
       "      <td>124.992279</td>\n",
       "      <td>386322</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99769</td>\n",
       "      <td>15</td>\n",
       "      <td>469.14</td>\n",
       "      <td>48.583333</td>\n",
       "      <td>1385.015000</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>31.276000</td>\n",
       "      <td>23.485712</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>73997P</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>BRADESCO</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104911</td>\n",
       "      <td>70</td>\n",
       "      <td>1116.50</td>\n",
       "      <td>37.666667</td>\n",
       "      <td>598.263333</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>50.228333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>14.408451</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>73997P</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>BRADESCO</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119460</td>\n",
       "      <td>32</td>\n",
       "      <td>605.44</td>\n",
       "      <td>39.090909</td>\n",
       "      <td>1038.158182</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>1</td>\n",
       "      <td>18.92</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>40.421818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>11.233750</td>\n",
       "      <td>4.758860</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>395133</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136036</td>\n",
       "      <td>10</td>\n",
       "      <td>310.20</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>673.553333</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>31.020000</td>\n",
       "      <td>30.277028</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>316253</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137749</td>\n",
       "      <td>48</td>\n",
       "      <td>909.44</td>\n",
       "      <td>41.777778</td>\n",
       "      <td>784.544444</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>2</td>\n",
       "      <td>38.20</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>17.759583</td>\n",
       "      <td>17.929894</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>Z62101</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143174</td>\n",
       "      <td>76</td>\n",
       "      <td>904.01</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>538.605833</td>\n",
       "      <td>22.733372</td>\n",
       "      <td>382.060089</td>\n",
       "      <td>1</td>\n",
       "      <td>11.03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.485000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428285</td>\n",
       "      <td>11.749737</td>\n",
       "      <td>11.118297</td>\n",
       "      <td>16.189830</td>\n",
       "      <td>XSP901</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158589</td>\n",
       "      <td>56</td>\n",
       "      <td>904.46</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>714.786667</td>\n",
       "      <td>23.885623</td>\n",
       "      <td>554.996424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>33.393333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402596</td>\n",
       "      <td>16.151071</td>\n",
       "      <td>14.952809</td>\n",
       "      <td>21.452806</td>\n",
       "      <td>QUE901</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165286</td>\n",
       "      <td>51</td>\n",
       "      <td>928.20</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>1364.050000</td>\n",
       "      <td>27.523405</td>\n",
       "      <td>845.296586</td>\n",
       "      <td>5</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>42.607778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415101</td>\n",
       "      <td>14.988235</td>\n",
       "      <td>16.109736</td>\n",
       "      <td>26.563730</td>\n",
       "      <td>406154</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>UNNA</td>\n",
       "      <td>Moderado</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        QT_TOTAL_EVENTOS_NO_MES  VL_TOTAL_EVENTOS_NO_MES  \\\n",
       "6212                         39                   788.19   \n",
       "42399                         0                     0.00   \n",
       "43285                        40                   671.98   \n",
       "49692                         0                     0.00   \n",
       "49788                        89                  1545.93   \n",
       "49921                        42                  2406.52   \n",
       "59193                         6                     0.00   \n",
       "60785                        18                   446.40   \n",
       "61642                        99                   357.10   \n",
       "64633                        48                   822.24   \n",
       "65093                        25                   742.00   \n",
       "72587                        19                  1538.24   \n",
       "75112                        60                   692.26   \n",
       "80244                        72                   778.80   \n",
       "82489                         3                   312.18   \n",
       "86032                        42                   844.10   \n",
       "96266                         8                   862.48   \n",
       "99769                        15                   469.14   \n",
       "104911                       70                  1116.50   \n",
       "119460                       32                   605.44   \n",
       "136036                       10                   310.20   \n",
       "137749                       48                   909.44   \n",
       "143174                       76                   904.01   \n",
       "158589                       56                   904.46   \n",
       "165286                       51                   928.20   \n",
       "\n",
       "        QT_MED_EVENTOS_NO_ANO_DO_DENT  VL_MED_EVENTOS_NO_ANO_DO_DENT  \\\n",
       "6212                        64.583333                    1368.697500   \n",
       "42399                       33.583333                    3010.905000   \n",
       "43285                       51.555556                     857.808889   \n",
       "49692                       54.111111                    2566.115556   \n",
       "49788                       59.083333                    1044.392500   \n",
       "49921                       19.500000                     685.553000   \n",
       "59193                       44.166667                    2654.450000   \n",
       "60785                       28.400000                     570.716000   \n",
       "61642                      151.083333                     544.175000   \n",
       "64633                       60.083333                    1028.635000   \n",
       "65093                       31.800000                     959.361000   \n",
       "72587                       18.000000                    1276.530000   \n",
       "75112                       43.083333                     477.266667   \n",
       "80244                       60.500000                     632.776667   \n",
       "82489                        7.416667                     971.098333   \n",
       "86032                       23.666667                     447.610000   \n",
       "96266                        2.833333                     296.076667   \n",
       "99769                       48.583333                    1385.015000   \n",
       "104911                      37.666667                     598.263333   \n",
       "119460                      39.090909                    1038.158182   \n",
       "136036                      20.750000                     673.553333   \n",
       "137749                      41.777778                     784.544444   \n",
       "143174                      46.000000                     538.605833   \n",
       "158589                      44.500000                     714.786667   \n",
       "165286                      71.666667                    1364.050000   \n",
       "\n",
       "        QT_MED_EVENTO_DOS_PARES_NO_MES  VL_MED_EVENTO_DOS_PARES_NO_MES  \\\n",
       "6212                         27.523405                      845.296586   \n",
       "42399                        22.162162                     1524.015735   \n",
       "43285                        23.885623                      554.996424   \n",
       "49692                        27.523405                      845.296586   \n",
       "49788                        23.885623                      554.996424   \n",
       "49921                        22.162162                     1524.015735   \n",
       "59193                        22.162162                     1524.015735   \n",
       "60785                        23.885623                      554.996424   \n",
       "61642                        44.127020                      682.879545   \n",
       "64633                        23.885623                      554.996424   \n",
       "65093                        27.523405                      845.296586   \n",
       "72587                        22.162162                     1524.015735   \n",
       "75112                        22.733372                      382.060089   \n",
       "80244                        22.733372                      382.060089   \n",
       "82489                         7.409084                      465.025457   \n",
       "86032                        22.733372                      382.060089   \n",
       "96266                         7.625572                     1148.890095   \n",
       "99769                        27.523405                      845.296586   \n",
       "104911                       23.885623                      554.996424   \n",
       "119460                       27.523405                      845.296586   \n",
       "136036                       23.885623                      554.996424   \n",
       "137749                       27.523405                      845.296586   \n",
       "143174                       22.733372                      382.060089   \n",
       "158589                       23.885623                      554.996424   \n",
       "165286                       27.523405                      845.296586   \n",
       "\n",
       "        QT_TOTAL_GLOSA_NO_MES  VL_TOTAL_GLOSA_NO_MES  \\\n",
       "6212                        0                   0.00   \n",
       "42399                       0                   0.00   \n",
       "43285                       2                  33.86   \n",
       "49692                       0                   0.00   \n",
       "49788                       0                   0.00   \n",
       "49921                       0                   0.00   \n",
       "59193                       0                   0.00   \n",
       "60785                       0                   0.00   \n",
       "61642                       0                   0.00   \n",
       "64633                       0                   0.00   \n",
       "65093                       0                   0.00   \n",
       "72587                       0                   0.00   \n",
       "75112                       0                   0.00   \n",
       "80244                       0                   0.00   \n",
       "82489                       2                 262.64   \n",
       "86032                       0                   0.00   \n",
       "96266                       0                   0.00   \n",
       "99769                       0                   0.00   \n",
       "104911                      0                   0.00   \n",
       "119460                      1                  18.92   \n",
       "136036                      0                   0.00   \n",
       "137749                      2                  38.20   \n",
       "143174                      1                  11.03   \n",
       "158589                      0                   0.00   \n",
       "165286                      5                  91.00   \n",
       "\n",
       "        QT_MED_GLOSA_NO_ANO_DO_DENT  VL_MED_GLOSA_NO_ANO_DO_DENT  ...  \\\n",
       "6212                       0.333333                     7.920000  ...   \n",
       "42399                      0.000000                     0.000000  ...   \n",
       "43285                      0.777778                    12.942222  ...   \n",
       "49692                      0.000000                     0.000000  ...   \n",
       "49788                      1.833333                    37.481667  ...   \n",
       "49921                      0.200000                     7.663000  ...   \n",
       "59193                      1.333333                    87.297500  ...   \n",
       "60785                      7.400000                    67.262000  ...   \n",
       "61642                      1.333333                     4.800833  ...   \n",
       "64633                      0.666667                    11.420000  ...   \n",
       "65093                      0.100000                     2.925000  ...   \n",
       "72587                      0.666667                    53.726667  ...   \n",
       "75112                      1.083333                    12.704167  ...   \n",
       "80244                      0.666667                     6.021667  ...   \n",
       "82489                      1.166667                   172.410833  ...   \n",
       "86032                      1.000000                    20.647500  ...   \n",
       "96266                      0.000000                     0.000000  ...   \n",
       "99769                      2.333333                    59.333333  ...   \n",
       "104911                     3.166667                    50.228333  ...   \n",
       "119460                     1.363636                    40.421818  ...   \n",
       "136036                     0.000000                     0.000000  ...   \n",
       "137749                     0.555556                    10.433333  ...   \n",
       "143174                     1.500000                    16.485000  ...   \n",
       "158589                     2.083333                    33.393333  ...   \n",
       "165286                     1.777778                    42.607778  ...   \n",
       "\n",
       "        QT_MED_UO_EVENTO_DOS_PARES  CUSTO_MED_EVENTO_NO_MES  \\\n",
       "6212                      0.415101                19.691795   \n",
       "42399                     0.273758                 0.000000   \n",
       "43285                     0.402596                14.289000   \n",
       "49692                     0.415101                 0.000000   \n",
       "49788                     0.402596                17.174831   \n",
       "49921                     0.273758                55.631429   \n",
       "59193                     0.273758                 0.000000   \n",
       "60785                     0.402596                20.666667   \n",
       "61642                     0.348669                 3.607071   \n",
       "64633                     0.402596                17.130000   \n",
       "65093                     0.415101                21.837600   \n",
       "72587                     0.273758                80.960000   \n",
       "75112                     0.428285                11.537667   \n",
       "80244                     0.428285                10.816667   \n",
       "82489                     0.438453                16.513333   \n",
       "86032                     0.428285                20.097619   \n",
       "96266                     0.452407                79.102500   \n",
       "99769                     0.415101                31.276000   \n",
       "104911                    0.402596                15.950000   \n",
       "119460                    0.415101                11.233750   \n",
       "136036                    0.402596                31.020000   \n",
       "137749                    0.415101                17.759583   \n",
       "143174                    0.428285                11.749737   \n",
       "158589                    0.402596                16.151071   \n",
       "165286                    0.415101                14.988235   \n",
       "\n",
       "        CUSTO_MED_EVENTO_NO_ANO  CUST_MD_EVEN_DOS_PARES_NO_MS  \\\n",
       "6212                  19.147419                     26.563730   \n",
       "42399                 84.688883                     63.916161   \n",
       "43285                 14.560000                     21.452806   \n",
       "49692                 40.957248                     26.563730   \n",
       "49788                 15.969337                     21.452806   \n",
       "49921                 34.695590                     63.916161   \n",
       "59193                 55.093245                     63.916161   \n",
       "60785                 17.639930                     21.452806   \n",
       "61642                  3.570044                     13.658548   \n",
       "64633                 16.654827                     21.452806   \n",
       "65093                 25.304623                     26.563730   \n",
       "72587                 58.976790                     63.916161   \n",
       "75112                 10.763269                     16.189830   \n",
       "80244                 10.320441                     16.189830   \n",
       "82489                 99.447079                     53.573309   \n",
       "86032                 18.040669                     16.189830   \n",
       "96266                 85.752647                    124.992279   \n",
       "99769                 23.485712                     26.563730   \n",
       "104911                14.408451                     21.452806   \n",
       "119460                 4.758860                     26.563730   \n",
       "136036                30.277028                     21.452806   \n",
       "137749                17.929894                     26.563730   \n",
       "143174                11.118297                     16.189830   \n",
       "158589                14.952809                     21.452806   \n",
       "165286                16.109736                     26.563730   \n",
       "\n",
       "        CD_CIR_DENTISTA  CD_ESPECIALIDADE  FAIXA_POPULACAO  NM_UNIDADE  \\\n",
       "6212             386322                 2                4        UNNA   \n",
       "42399            73639P                 6                7    BRADESCO   \n",
       "43285            Z62101                 4                7        UNNA   \n",
       "49692            319166                 2                2        UNNA   \n",
       "49788            XSP901                 4                7        UNNA   \n",
       "49921            406891                 6                4        UNNA   \n",
       "59193            347778                 6                4        UNNA   \n",
       "60785            406891                 4                4        UNNA   \n",
       "61642            324680                14                6        UNNA   \n",
       "64633            386322                 4                4        UNNA   \n",
       "65093            406891                 2                4        UNNA   \n",
       "72587            319166                 6                2        UNNA   \n",
       "75112            QUE901                25                7        UNNA   \n",
       "80244            386322                25                4        UNNA   \n",
       "82489            316253                 5                4        UNNA   \n",
       "86032            73997P                25                7    BRADESCO   \n",
       "96266            386322                 3                4        UNNA   \n",
       "99769            73997P                 2                7    BRADESCO   \n",
       "104911           73997P                 4                7    BRADESCO   \n",
       "119460           395133                 2                6        UNNA   \n",
       "136036           316253                 4                4        UNNA   \n",
       "137749           Z62101                 2                7        UNNA   \n",
       "143174           XSP901                25                7        UNNA   \n",
       "158589           QUE901                 4                7        UNNA   \n",
       "165286           406154                 2                7        UNNA   \n",
       "\n",
       "          CLASSE  CLASSE_REDE_NEURAL  \n",
       "6212    Moderado                Alto  \n",
       "42399   Moderado                Alto  \n",
       "43285   Moderado                Alto  \n",
       "49692   Moderado                Alto  \n",
       "49788   Moderado                Alto  \n",
       "49921   Moderado                Alto  \n",
       "59193   Moderado                Alto  \n",
       "60785   Moderado                Alto  \n",
       "61642   Moderado                Alto  \n",
       "64633   Moderado                Alto  \n",
       "65093   Moderado                Alto  \n",
       "72587   Moderado                Alto  \n",
       "75112   Moderado                Alto  \n",
       "80244   Moderado                Alto  \n",
       "82489   Moderado                Alto  \n",
       "86032   Moderado                Alto  \n",
       "96266   Moderado                Alto  \n",
       "99769   Moderado                Alto  \n",
       "104911  Moderado                Alto  \n",
       "119460  Moderado                Alto  \n",
       "136036  Moderado                Alto  \n",
       "137749  Moderado                Alto  \n",
       "143174  Moderado                Alto  \n",
       "158589  Moderado                Alto  \n",
       "165286  Moderado                Alto  \n",
       "\n",
       "[25 rows x 50 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_save_copy[X_save_copy['CD_CIR_DENTISTA'].isin(cd_descredenciados)][X_save['CLASSE'] == 'Moderado']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 98.98\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAHMCAYAAAAnPPeGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5xcZfX48c9JQknoxSACSjGOAioCIgpfpQgCigEFRZGuEQRRQaVYQBREf3alGCVIE1BRQEAQkabSixRlICJgJBAg1BBIO78/7t3JsNzd2V03M5vN583rvnbmue2ZyTB79pznPjcyE0mSJPVsRKc7IEmSNNQZMEmSJLVgwCRJktSCAZMkSVILBkySJEktGDBJkiS1YMAkdUBErBkRGRFHt+FcR5fnWnNBn6uTIuJTEXFPRLy4oF9vRBwXEc9GxKUR8ZqI+HlEfG9BnU9S5xkwadiJiC3KX5gZET/pYZuxETGr3Oaq/+Fce0fEZwfc2WEgIl4XESeWwcqMiJgZEfdGxMSIeGub+rAlcAJwD7A/sAfw2AI619LAYcC3gdnA/cCHgTMWxPkkDQ2jOt0BaQF6AfhoRByamS92W7cHEMCc//EcewNrAj/o534PAqMH4fwdFRH7ASdRvNdnA7dTvKbXAR8EPhER62XmPxZwV7Ypf+6bmdMX8LleAGqZORkgIl4BzMjM5xfweSV1kAGThrPfAR8BxgO/6rZuH+ASYOt2digilsnMZ7OYYv+Fdp57sEXEu4GJwD+A92Tmw93WHwF8uk3deSVAG4IlMnMOMLnp+QLJZEkaWizJaTi7Ffg7RXDUEBGbAOsBp1btFBHbRsS5EXF/WV56KiL+GBHv6rbdA8C7gNc0lQAzIrYo118VEQ9ExNoR8ZuImA48U6572RimcvvsYXmg1YuNiBERcURE/DsiXoiIOyNi9162XzUiToqIh8ry5MNlGW1sq3OVvkWRpftw92AJisAiM7/fnF2KiKUi4psR8a9yrNEjEXF6RLymW9+6yqp7R8Q+EXF3uf2DEfHFpu3WjIik/Dduer+uKp9fVfXe9fD+R0R8NiLuKMcnPRMR9Yg4JSIWa9quT5+Ppu3fGRGXR8TT5fa3lpk5SQsRM0wa7k4FvhcRq2fmlLJtX2AacFEP++wNrAicDkwBVgM+DlwREVtm5rXldp8FvgmsDHyuaf9/Nj1eGrga+CvwJaC3YORY4Ofd2tYBjgYe7WW/Lt8DPgNcA3y/PNcJFGNsXiIiXg1cBywOnAL8C3gtcACwZURsnJlP93SiiFgL2BC4tq/ltogYBVwGbAb8BvguMK4857blOad0221/YJWyj08BHwO+FRFTMvOXFOOU9gAmAP9XPoa+vV/dfRk4Bvg9cDIwF1gLeD+wBMV4Jej754OI2JEi0/lI+XqfBXYDfh4Ra2fmlwbQT0mdkJkuLsNqAbYAEvg8sBLwInBkuW40xS/e75TPnwOu6rb/UhXHXAV4HLikW/tVwAM99OOqsh/fqFi3Zrnu6F5exwoUg5gfB17b4jXXgHnAFcDIpvYNy/YE1mxqv4AiaFy923E2phiD1GO/yu12LI/5o378u3yi3Ofb3drfW7afUfFv+DCwfFP7GIog6bpux/hF8XVW+W/wsn+fqvefIiP5jz68jj59PoCRFGPVngJe1dS+OEUAPRcY1+n/X1xcXPq2WJLTsJaZTwAXUmQFAD4ALAdM6mWfGV2PI2LpiFiJ4pfbDcDbBtCN7/R3h7IEdB5FhmPnLAcY92I8RXnse5k5t6sxM28FLu927OWA91G8Ly9ExMpdC/AAxficbVucb9ny5zN9e0UA7EwRvH2zuTEzL6YYLD4+Irp/J52amU81bfs8cD1FZmqwPQ2sFhGb97ZRPz4fGwGvBiZlU8kyM2cB/49iSMT4weu+pAXJgEmLglOBceUvwn2BG7OXMlJErBMR50TEkxQllMcpsho7UGR9+uOx5l/4/fBTYEvg49lU4unF2uXPeyrWdX+tNYr/9/ejeF3dlxpFxqQ3XYHSMn3oW5e1gIcz88mKdXeXx1q5W/vLyonAExSZw8F2JMVA/Gsj4r8RcVZEfDQiFm/eqB+fj7XKn3dXnOuu8ufaFeskDUGOYdKi4DLgv8BRFEHIAT1tGMUcO9cAS1FMFXAnxS/FecARwFb9PHe/LzWPiCMpBjF/IzP7OrdPlD+zl3Xdn58JnNbD8Wa2OF/XL/y3tO5aj/3oi7mtN+lV1fsBFd99mXldRKwDvIfic7Il8FHgyxGxeWZO7+fnYyCvV9IQZcCkYS8z50bE6RS/0GYC5/Sy+dbAqyjm83nJVXQR8Y2qww9aR4tzfAj4BnAu8NV+7Pqv8ucbeHlW5g3dnk+m6PfimfmngfQzM/8dEbcBm0XE6zOzKrNV1cftImL5iqzbuhRZq8cH0p9eTKcojXVXmdnJzOcoSqHnQTF7OMXA+f0oymj9+Xx0/ZusV3GqdcufVRk0SUOQJTktKk4Gvgbsn71c/cX8jMZLsgMRsS3V45eeA1aIiP85mxARm1JkfG4A9s7M/gRjF1IEQYdExMimY24IvLt5w3Jc1yXAB8pzdu9HRDEZYyuHlT/PiYhXVhxnZHmZfldwcD7Fd87h3bbbniJTdWFmzuvDefvjXmCZKKaS6DrfCF56VWNXe/dyIBQDwaG4Kg769/m4FXgI2Kf5/SnHp32B4t/rgj6/EkkdZYZJi4TMfIji8vxW/kJ5CXgU9yKbAmxAcbn6ncAbu21/PcUA6p9ExN8ofqH+OTOnDaCbFwCLAb8GdukWgz2Xmef3tGNm3hMRJwAHAX+OiPMophU4iGIuqu6lswMoXus1ZfbtNopgZm2Kgcin0+L9yszLI2ICxUzf9Yhonun7tRQzfa8DrF/u8gtgL+Cw8r29ptzuUxTTABzZ2/kGaCJwKPC7iPghMAvYhervvn9GxPUUAevDwKoU0xXMYn5Wss+fjzKzeRDFtAI3RcREivLdh4FNgeMy877BfLGSFqBOX6bn4jLYC03TCvRh26ppBd4EXAp0Deq9imKOn1/Q7dJ1irEsp1D8wp9bnneLct1V9DzlwJq8/LL27GWpPE63Y46gmOvpQYqpFO4CdqcIfF4yrUC5/coUZaZ7KQY7P0XxS/+HwLr9eL9rFEHTvRRjtl4A6hQD199S8X59k6IUNYtiaoMzgNf08G+4d8X5qv4dXtbWtG4HikDuRYpA6Ftln7u//4dTBHHTym3/QxG8bjjQz0e5/bsorlR8pnxvbqMYzN/x/1dcXFz6vkTmoA7BkCRJGnYsyS1EarXaSOBm4L/1ev19tVrtWuZf1j0WuLFer+9Uq9W2oCjv/Ltc99t6vX5MT8dp2wvQQqlWq21HkXUaCfy8Xq8f3+EuaYir1WprUJR1X0lxBeHEer3+w1qttitFxvMNwCb1ev3mcvvFKTKSG5fbf6Zer1/Vga5LPTJgWrh8huK2G8sC1Ov1/+taUavVzuOlA0iv7SUYeslxpJ6UwfUJwDYU43VuqtVqF9br9T7dDkWLrDnAofV6/dZarbYMcEutVrucokz8AYrgqNknAOr1+htrtdpY4A+1Wu2t9Xp9sC8CkAbMq+QWErVabXWKW0h0v9cY5RfSVhRXIQ34OFKFTYDJ9Xr9/nq93jX42dmp1at6vT61Xq/fWj5+luIPtNXq9fo/6/V6vWKXdSlu60O9Xp9GMZ5u43b1V+qLjgRMEbFMOQGc+u4HwBcp0tXd7QxcUa/Xm29T8fZarfb3Wq32h1qt1jwPTG/HkbpbjWLwc5eum81KfVKr1dakuErzhl42+zswvlarjarVamtRzJ21Rhu6J/VZWwOmiHhjOdndXcA/IuKWiFi/1X6Lulqt9j5gWr1ev6WHTT4CnN30/FbgNfV6/c3AjykzT304jtRd1fxSXimiPqnVaktTTAL62W5/0HU3iSIYv5nij7q/UZT1pCGjrVfJlfPUfCkzryyfb0ExF8k7etlnAsVcKPz0pz/d6MN7fLwdXR1STvjR9/jDRRcycuRIXpw1ixkznmPLrbbhmOO+zVNPPcku47fn4j9ezRJLLFG5//jtt+a0X/6Gs844tcfjLIqWG138vfCCX8s9+vvtt3HSCT/h5J+dAsApPyuGnuz3iU92sltD1pLlqFA/UzB79mw+/an9ecdmm7Pn3vu8ZN1+e+/BIZ//Iuut331as8Keu+/GUV/7Buu89rXt6OqQVn6m2nqbndFvOWjQAoOZt/1k2NwiqN2DvpfqCpYAMvOqiFiqtx0ycyLF5HMA+fTMRa+SdODBh3DgwYcAcMtNN3Lm6ZMaQc4Vl1/G5v+3xUuCpccff4yVVlqZiODuO+9gXibLLb98r8eRqqy3/ht56KEHmDLlP6wydhUuveRivvn/vtvpbmmIy0yO/uqXWHvttV8WLFWZOXMmmcmYMWO47m9/ZeTIkQZLGnLaHTDdHxFfoZioDuBjzL/0XQNw+aWXsNe+n3hJ25//9EfO+9XZjBw1iiWXWIJjj/8ug3DnDi2CRo0axRFf+ioHTPg48+bNZaedP8hrXzuu093SEHfbrbdw0YUXMO51r+NDHyiuEfj0Zw9h1qxZHH/c13ly+nQO+tQnqdXewMk/O4Xp05/ggAn7MWLECMaOXYVjj/cPuY4Krwer0u6S3AoU9/PavGy6hmKm3e434uzJIplh0oJhSU6DzZKcBltHSnIbfWbwSnK3/HDY/LXe7gzTuzPz4OaGiNiV4vYDkiSp08wwVWr3u3JEH9skSdIwFxGTImJaRNzV1Pb/IuKeiLgjIn4XEcuX7WtGxMyIuL1cTm7aZ6OIuDMiJkfEj6IchxIRK0bE5RFxX/lzhbI9yu0ml+fZsFVf2xIwRcT2EfFjYLWyg13LL/DSUUmSho6IwVta+wWwXbe2y4H1M/NNFDf1bk6s/CszNyiX/ZvaT6K4on5cuXQd83DgiswcRzE56uFl+/ZN204o9+9VuzJMDwO3UNyp+5am5ULgPW3qgyRJaiVGDN7SQmZeA0zv1vbHzOxKplwPrN5rdyNWBZbNzOuyGJh9OrBTuXo8cFr5+LRu7adn4Xpg+fI4PWrLGKbM/Dvw94g4s+lNkCRJ6s2+wLlNz9cqJ8B+BvhyZl5LcfeBKU3bNN+RYJXMnAqQmVMjYmzZ3tNdDKb21JG2BEwRcSfl7MAVl7dnZr65Hf2QJEktDOI0NM2TT5cmlvMr9mXfL1EM2zmrbJoKvDozn4iIjYDzI2I9BnZHgn7v066r5N5X0RYUabYj29QHSZLUyiBeJddt8um+dyFiL4rYYeuyzEZmvgi8WD6+JSL+BbyOIjvUXLZbnWIoEMCjEbFqmV1aFZhWtk/hpfcrbN6nUlvGMGXmg10LsAJwIHAV8HXgknb0QZIkDX0RsR1wGPD+zHy+qf0VETGyfLw2xYDt+8uS27MRsWl5ddyewAXlbhcCe5WP9+rWvmd5tdymwNNdpbuetKsk9zpgN4qbxD5BUY+MzNyyHeeXJEl91MY7Q0TE2cAWwMoRMQU4iuKquCWAy8thPNeXV8S9EzgmIuYAc4H9M7NrwPgBFFfcjQb+UC4AxwO/ioj9gIeAXcv2S4AdgMnA80DLe/i0ZabviJgHXAvsl5mTy7b7M3Ptfh7Kmb41aJzpW4PNmb412Doy0/c7jhy8mb7/dtywmem7XdMKfBB4BLgyIn4WEVvT5g+AJEnSQLVrDNPvMvPDwOspxi59DlglIk6KiG3b0QdJktQH7Z24cqHR1lujZOaMzDwrM99HMSL9dubPuilJkjqtjRNXLkw69moyc3pm/jQzt+pUHyRJkvqiXfMwSZKkhcEwK6UNFgMmSZI03zArpQ0W3xVJkqQWzDBJkqT5zDBVMmCSJEnzjXAMUxXDSEmSpBbMMEmSpPksyVUyYJIkSfM5rUAlw0hJkqQWzDBJkqT5LMlVMmCSJEnzWZKrZBgpSZLUghkmSZI0nyW5SgZMkiRpPktylQwjJUmSWjDDJEmS5rMkV8mASZIkzWdJrpJhpCRJUgtmmCRJ0nyW5CoZMEmSpPksyVUyjJQkSWrBDJMkSZrPklwlAyZJkjSfAVMl3xVJkqQWzDBJkqT5HPRdyYBJkiTNZ0muku+KJElSC2aYJEnSfJbkKhkwSZKk+SzJVfJdkSRJasEMkyRJms+SXCUDJkmS1BAGTJUsyUmSJLVghkmSJDWYYapmwCRJkuYzXqpkSU6SJKkFM0ySJKnBklw1AyZJktRgwFTNkpwkSVILZpgkSVKDGaZqBkySJKnBgKmaAZMkSZrPeKmSY5gkSZJaMMMkSZIaLMlVM2CSJEkNBkzVLMlJkiS1YIZJkiQ1mGGqZsAkSZIaDJiqWZKTJElqwQyTJEmazwRTJQMmSZLUYEmumiU5SZKkFswwSZKkBjNM1QyYJElSgwFTNUtykiRJLZhhkiRJ85lgqmTAJEmSGizJVbMkJ0mS1IIZJkmS1GCGqZoBkyRJajBgqmZJTpIkqQUzTJIkqcEMUzUzTJIkab4YxKXVqSImRcS0iLirqW3FiLg8Iu4rf65QtkdE/CgiJkfEHRGxYdM+e5Xb3xcRezW1bxQRd5b7/CjKaLCnc/TGgEmSJHXKL4DturUdDlyRmeOAK8rnANsD48plAnASFMEPcBTwNmAT4KimAOikctuu/bZrcY4eGTBJkqSGiBi0pZXMvAaY3q15PHBa+fg0YKem9tOzcD2wfESsCrwHuDwzp2fmk8DlwHblumUz87rMTOD0bseqOkePHMMkSZIaBnMMU0RMoMjwdJmYmRNb7LZKZk4FyMypETG2bF8N+E/TdlPKtt7ap1S093aOHhkwSZKkBaIMjloFSH1VFcnlANoHxJKcJElqaGdJrgePluU0yp/TyvYpwBpN260OPNyiffWK9t7O0SMDJkmSNF8br5LrwYVA15VuewEXNLXvWV4ttynwdFlWuwzYNiJWKAd7bwtcVq57NiI2La+O27PbsarO0SNLcpIkqSMi4mxgC2DliJhCcbXb8cCvImI/4CFg13LzS4AdgMnA88A+AJk5PSK+DtxUbndMZnYNJD+A4kq80cAfyoVeztFzX4uB4wuNfHrmvE73QcPEcqOLBOsLczrcEQ0bS5Z/gvqZ0mApP1NtnUny1Z++cNACg4d+/P5hMwumGSZJktTgTN/VHMMkSZLUghkmSZLUYIapmgGTJElqMGCqZklOkiSphYUuw9R1ZZM0WJZc6P4v0FDnZ0oLNRNMlfzfWpIkNViSq7bQBUzOb6LB0pUFGP2WgzrbEQ0bM2/7CQDPz16o5rfTEDZmMYOXoWKhC5gkSdKCY4apmgGTJElqMF6q5ghqSZKkFswwSZKkBkty1QyYJElSg/FSNUtykiRJLZhhkiRJDZbkqhkwSZKkBuOlapbkJEmSWjDDJEmSGkaMMMVUxYBJkiQ1WJKrZklOkiSpBTNMkiSpwavkqhkwSZKkBuOlapbkJEmSWjDDJEmSGizJVTNgkiRJDQZM1QyYJElSg/FSNccwSZIktWCGSZIkNViSq2bAJEmSGoyXqlmSkyRJasEMkyRJarAkV82ASZIkNRgvVbMkJ0mS1IIZJkmS1GBJrpoBkyRJajBeqmZJTpIkqQUzTJIkqcGSXDUDJkmS1GC8VM2SnCRJUgtmmCRJUoMluWoGTJIkqcF4qZolOUmSpBbMMEmSpAZLctUMmCRJUoPxUjVLcpIkSS2YYZIkSQ2W5KoZMEmSpAYDpmqW5CRJklowwyRJkhpMMFUzYJIkSQ2W5KpZkpMkSWrBDJMkSWowwVTNgEmSJDVYkqtmSU6SJKkFM0ySJKnBBFM1AyZJktQwwoipkiU5SZKkFswwSZKkBhNM1QyYJElSg1fJVbMkJ0mS1IIZJkmS1DDCBFMlAyZJktRgSa6aJTlJkqQWzDBJkqQGE0zVDJgkSVJDYMRUxZKcJElqu4ioRcTtTcszEfHZiDg6Iv7b1L5D0z5HRMTkiKhHxHua2rcr2yZHxOFN7WtFxA0RcV9EnBsRiw+0vwZMkiSpYUQM3tKbzKxn5gaZuQGwEfA88Lty9fe71mXmJQARsS6wG7AesB1wYkSMjIiRwAnA9sC6wEfKbQG+VR5rHPAksN+A35eB7ihJkoafiBi0pR+2Bv6VmQ/2ss144JzMfDEz/w1MBjYpl8mZeX9mzgLOAcZH0YGtgN+U+58G7NTPt6PBgEmSJC0QETEhIm5uWib0sOluwNlNzw+KiDsiYlJErFC2rQb8p2mbKWVbT+0rAU9l5pxu7QNiwCRJkhoiBm/JzImZuXHTMvHl54vFgfcDvy6bTgLWATYApgLf7dq0ors5gPYB8So5SZLUMKL98wpsD9yamY8CdP0EiIifAReVT6cAazTttzrwcPm4qv1xYPmIGFVmmZq377d+ZZgiYoWIeFW3tv0i4vsRsf1AOyFJkhZZH6GpHBcRqzat2xm4q3x8IbBbRCwREWsB44AbgZuAceUVcYtTlPcuzMwErgR2KfffC7hgoJ3sb4bpFxTpsf0BIuJI4BvAs8DBEbFbZv66590lSdJQ1s4EU0SMAbYBPtnU/O2I2ICifPZA17rMvDsifgX8A5gDHJiZc8vjHARcBowEJmXm3eWxDgPOiYhvALcBpwy0r/0NmDYGDm56/ingW5l5REScABzK/BqkJElayLTzXnKZ+TzF4Ozmtj162f5Y4NiK9kuASyra76e4iu5/1t9B3ysBjwJExHrAqsCp5brzgNpgdEqSJGko6W+G6QnmX5K3JTA1M+9tOtbIweqYJElqP+8lV62/AdOfgaPKOREOBc5vWvd6oLcJpyRJ0hDXgavkFgr9Lcl9kaIk9z2KSaK+1rRud+Cvg9QvSZKkIaNfGabMnEpRiquyPcV9YCRJ0kLK/FK1QZu4MjOnD9axJElSZ7TzKrmFSb8DpojYjGKSqVcDS3ZbnZn5nsHomCRJar8RxkuV+hUwRcTHgYnAUxR3CX5xQXRKkiRpKOlvhukLwLnA3plpsCRJ0jBjSa5afwOm1YFPGSxJkjQ8GS9V6++0ArcCay6AfkiSJA1Z/c0wfQY4IyL+mZl/WxAdkiRJnWNJrlp/A6bzgOWBayPiWaD7VAKZmesMSs8kSVLbeZVctf4GTH8FckF0RJIkaajq70zfH1tQHZEkSZ1nSa7aoM30LUmSFn6GS9UGFDBFxHpAjZfP9E1m/vJ/7ZQkSdJQ0t+ZvpcDfg9s1tVU/mwe12TAJEnSQmqEJblK/Z2H6VjglcBWFMHSrsC2FLN/3w9sOqi9kyRJbRUxeMtw0t+AaTvgOOAv5fMHMvNPmflR4ErgwMHsnCRJ0lDQ3zFMrwImZ+bciHgBWKZp3a+BcwatZ5Ikqe28Sq5afzNMj1JMXAnwIPC2pnXr4OB6SZIWapbkqvU3w/QXiiDpIuAs4GsR8WpgDrAvcPHgdk/99ddrr+Fbxx/LvLnz2PmDu7LfJyZ0ukvqsJOP2p3t37k+j01/lo13PQ6A4z67Ezu8c31mzZ7Lv6c8zoSjzuTp52YyatQITvrq7mzw+jUYNXIEZ118I9+Z9McejwOwwrJjOONb+/KaV63Igw9P52NfPIWnnp3JbttvzCF7bwPAjJkvcvBx53Lnvf9t/xugtjn6y0dyzTVXseKKK/Gb838PwNNPP8Vhhx7Cww//l1e9ajW+/d3vs+xyy3HzjTfwuYMP5FWrrQ7AVu/ehk8eUIzq+OUZp/Pb835NZvKBXXZl9z326thrkrr0N8N0DHBF+fjbwE+BDwJ7A38ADhq0nqnf5s6dy3HHHsOJJ/+c3114MZdechH/mjy5091Sh53x++sZf+AJL2m74vp72GjX49jkw9/kvgen8YV9twXgg+/ekCUWH8VbP3Qc79j9W3z8g5vx6lVX7PE4AJ/fZxuuurHOG8cfw1U31vn8PsWxHnj4Cbb9+A/Y5MPf5Js/u5QTvvyRBfxK1Wk77rQzJ5z8s5e0nfrzn7HJppty4SWXscmmm3LqKfPXv2XDjTj3vPM597zzG8HS5Pvu5bfn/Zozzv4V5553PtdcfRUPPvhAO1/GIm9ExKAtw0m/AqbMvC8zryofz8rMz2TmKzNzucz8UGY+vkB6qT656847WGON17D6Gmuw2OKLs90O7+WqK69ovaOGtb/e+i+mP/38S9quuP4e5s6dB8CNd/6b1VYpKu1JMmbJxRk5cgSjl1icWbPn8uyMF3o8DsD7tngTZ/7+BgDO/P0N7LjlmwC4/u//5qlnZxbnuGP+OTR8bbTxW1luueVe0nbVlVew4/idANhx/E5c+ec/9XqMf99/P29805sZPXo0o0aNYqON38qVV/S+jwaXJblq/c0wNUTE6IhYLSL6PfllRCweEeuXy2ID7YNeatqjj/LKVV/ZeD52lVV49NFHO9gjLQz2HP92LvvrPwD47Z9u4/kXZvHvy4/l3j8cww9Ov4Inn3l5kNRs7ErL8MjjzwDwyOPP8IoVl3nZNnvv9I7GObRoeeKJJ3jFK8YC8IpXjGX69Pn3bL/j77fzoQ+M58D9P8G/Jt8HwDqvHcett9zEU089ycyZM/nLtVfzyCNTO9J3qdlAgp3tga8BG5ZNmwC3RsRPgSszs9cr5SJiC+A04AGKQeJrRMRemXlNf/uil8qK+yJ7tYN688X93sPcufM455KbAHjremsyd+481t72S6ywzBj+NOlz/PmGe3jgv08M+Bzv3Hgce+30drbe9/uD1W0NA69fdz0uufzPjBmzFNdeczWfO/ggLrzkMtZeZx323vcTHPCJ/Rg9Zgyve93rGTXSu3i1k783qvUrwxQRO1IM+H4W+HK3/f9DMZaple8C22bmuzLzncB7gB6/SSNiQkTcHBE3T5w4sT/dXeSsssoreWTqI43n0x59lLFjx3awRxrKdt/xbezwzvXZ+0u/aLR9aPuN+ePf/sGcOfN47MnnuO72+9lo3Vf3epxpTzzLK1deFoBXrrwsj01/trFu/XGv4qSvfpRdPzeR6U/PWCCvQ0PbSiutxGOPTQPgscemseKKxZi4pZdemjFjlgLg/975LubMmc2TTz4JwM4f3IWzf/1bJp12Jssttxyvfs1rOtP5RdSIQVyGk/6+nqOB0zNza+A73dbdCazfh2Mslj1LOkgAACAASURBVJn1rieZeS/QY1kuMydm5saZufGECV7x1Zv11n8jDz30AFOm/IfZs2Zx6SUX864tt+p0tzQEbfOON3Do3u9ml8/+lJkvzG60T3lkOlu8tQbAmCUXZ5M3rUn9gd7LuhdffScf27GYYeRjO76Ni666A4A1XrkC53znE+z3ldOZ/NC0BfRKNNS9a4ut+P0F5wPw+wvOZ4sttwbg8ccfI7PIit915x3kvGT55YtxbtOfKDKaU6c+zJ+vuJzttn9vB3ouvVR0fWD7tHHETOD9mXl5RIwEZgMbZ+atEfFO4I+Z+bIb8nY7xiSKe8+dUTbtDozKzH360IV8YU6fu7tIuvaaq/n28ccxb95cdtr5g3zikwd0uktD1pJlln/0W4b3xZ2nfXNv/m+jcay8/NJMm/4MXz/5Er6wz7YssfgoniizPjfe+QAHH3sOS41enIlf+xivX3tVIuCMC67n+6df0eNxTjv/OlZcbinO/Na+rLHqCvxn6pPs/sVTePKZ5znxqx9lp6034KGpxZiVOXPnsfnu3+7Y+9AOM2/7CQDPz+779+pwcvgXDuGWm4rxRyuutBL7f+rTbLn11hx26OeYOnUqq666Kt/+3g9YbrnlOeeXZ/Lrc89h5MiRLLnkkhzyhcPY4C3FSI9999ydp556ilGjRnHoFw/nbZu+vcOvrHPGLBbQ5jkODz7/nkH7AP9op9cPm/pefwOmacDBmXlORcC0B3BcZq7R4hhLUNxCZXOKD8E1wImZ+WIfumDApEGzqARMap9FPWDS4OtEwPTZCwYvYPrB+OETMPV3JN0VwOERcQnQNSAhI2JxiiDosj4cY7nM/B7wva6GiKgB9Z53kSRJ6pz+jmE6kuJ+cvcAJ1OU1r4A3AasSTHGqZVrI+JDXU8i4lDgd/3shyRJWgBGxOAtw0l/J678N/BW4HJgx7J5G+BW4G2ZOaUPh9kC2CMifh0R1wCvo5iaQJIkdVhEDNoynPR7covMfBAY8I19MnNqRFwKHAHMA47IzOcGejxJkqQFre2zgUXE5cBUiikIVgcmRcQ1mfn5dvdFkiS91HArpQ2WlgFTRHy1H8fLzPx6i21OyMzzy8dPRcQ7KLJNkiSpw4ZZJW3Q9CXDdDTF4O6+vIUJ9BowNQVLXc/ntNpHkiSpk/oSMM0E5gC/AU4H/goVNy1rISL+kpmbR8Sz3fYPiszUsv09piRJGlwjTDFV6kvAtAqwK7AnxTxMD1AETmeUV831SWZuXv58+a3MJUnSkDDc7gE3WFq+L5n5XGaemplbAusAvwA+CkyOiGsj4hMR0e/sUESMjYhXdy397rkkSVKb9Hcepgcz8xuZ+XrgHcA/gROBSX09RkS8PyLuA/4NXE2RsfpDf/ohSZIWjIjBW4aTAWXeImJDYDdgPDAXuLMfu38d2BS4NzPXAramGBclSZI6bETEoC3DSZ8DpohYPSIOi4i7gJspgp6jgVUz82v9OOfszHwCGBERIzLzSmCD/nRakiSpnfoyD9PewB7Au4CHgLOAnTPzvgGe86mIWBq4BjgrIqZRXIUnSZI6bJglhgZNX66SmwQ8Q3Fl3NUUUwK8PSLeXrVxZp7e4njjKaYq+BywO7AccExfOyxJkhYcZ/qu1tdboywL7F0uvUmKwKrnDTJnlA/nRcTFwBOZ2e95nSRJktqlLwHTuME4UURsChwPTKcY+H0GsDLFWKY9M/PSwTiPJEkauOE2WHuwtAyYMvNfg3SunwBHUpTg/gxsn5nXR8TrgbMBAyZJkjrMeKna/zShZ0QcGRGr9HHzUZn5x8z8NfBIZl4PkJn3/C99kCRJWtAGHDBFxEiK0tpqfdxlXtPjmd3WOYZJkqQhYEQM3jKc9HXQd0/683a8OSKeKfcZXT7uOsaS/2M/JEnSIIh+/WpfdPyvAVOfZebIdp1LkiRpMLUsyUXEij2sSopbmjzbtO1ug9QvSZLUAZbkqvVlDNPlEbFs98bMnJeZ/9c143c5I/gZg9w/SZLURgZM1foSMK0FXFrezqRSREwATgEuG6yOSZIkDRV9CZjeA6wLXBwRo7uvjIiDgZOBC4GdB7d7kiSpnSJi0JbhpGXAlJk3ATsAbwEujIglutZFxBeBHwC/AnbJzNkLqqOSJGnBsyRXrU/zMGXm34AdgXcAv42IxSLiKIpbnZwJfDQz5y64bkqSJHVOn6cVyMyrI2InitLb3cA6FOOWJnjzXEmShodhVkkbNC0DpohYu+npv4DDKMpwF1FkmNZqrlNm5v2D3EdJktQm3ny3Wl8yTJOpvnXJ+4D3VrQ7QaUkSQup4Tb2aLD0JWDaZ4H3QpIkaQhrGTBl5mnt6IgkSeo8K3LV2nYvOUmSNPSN8Oa7lfo0rYAkSdJgi4gHIuLOiLg9Im4u21aMiMsj4r7y5wple0TEjyJickTcEREbNh1nr3L7+yJir6b2jcrjTy73HXA0aMAkSZIaIgZv6aMtM3ODzNy4fH44cEVmjgOuKJ8DbA+MK5cJwElFf2NF4CjgbcAmwFFdQVa5zYSm/bYb6PtiwCRJkhqGwEzf44Gu8dOnATs1tZ+eheuB5SNiVYpbuF2emdMz80ngcmC7ct2ymXldOV/k6U3H6jcDJkmS1CkJ/DEibomICWXbKpk5FaD8ObZsXw34T9O+U8q23tqnVLQPiIO+JUlSw2BOXFkGQROamiZm5sSm55tl5sMRMRa4PCLu6e1wFW05gPYBMWCSJEkNgzmtQBkcTexl/cPlz2kR8TuKMUiPRsSqmTm1LKtNKzefAqzRtPvqwMNl+xbd2q8q21ev2H5ALMlJkqS2i4ilImKZrsfAtsBdFPes7brSbS/ggvLxhcCe5dVymwJPlyW7y4BtI2KFcrD3tsBl5bpnI2LT8uq4PZuO1W9mmCRJUkMb7yW3CvC78kr/UcAvM/PSiLgJ+FVE7Ac8BOxabn8JsAPFLduep7wTSWZOj4ivAzeV2x2TmdPLxwcAvwBGA38olwExYJIkSQ3tipcy837gzRXtTwBbV7QncGAPx5oETKpovxlY/3/uLJbkJEmSWjLDJEmSGsykVDNgkiRJDf/D3UOGNQNJSZKkFswwSZKkBvNL1QyYJElSQxunFVioWJKTJElqwQyTJElqML9UzYBJkiQ1WJGrZklOkiSpBTNMkiSpwXmYqhkwSZKkBktP1XxfJEmSWjDDJEmSGizJVTNgkiRJDYZL1SzJSZIktWCGSZIkNViSq2bAJEmSGiw9VfN9kSRJasEMkyRJarAkV82ASZIkNRguVbMkJ0mS1IIZJkmS1GBFrpoBkyRJahhhUa6SJTlJkqQWzDBJkqQGS3LVDJgkSVJDWJKrZElOkiSpBTNMkiSpwZJcNQMmSZLU4FVy1SzJSZIktWCGSZIkNViSq2bAJEmSGgyYqlmSkyRJasEMkyRJanAepmoGTJIkqWGE8VIlS3KSJEktmGGSJEkNluSqGTBJkqQGr5KrZsAkSZIazDBVcwyTJElSC2aYJElSg1fJVTNgkiRJDZbkqlmSkyRJasEMkyRJavAquWoGTJIkqcF4qZolOUmSpBYWugzTkgtdjzXUzbztJ53ugoaZMYv5N7oWXiOsyVUy/JAkSQ2GS9UWuoDphTmd7oGGi65spZ8pDZauz9R9j87sbEc0bIxbZXSnu6DSQhcwSZKkBcgUUyUDJkmS1ODEldW8Sk6SJKkFM0ySJKnBi+SqGTBJkqQG46VqluQkSZJaMMMkSZLmM8VUyYBJkiQ1eJVcNUtykiRJLZhhkiRJDV4lV82ASZIkNRgvVbMkJ0mS1IIZJkmSNJ8ppkoGTJIkqcGr5KpZkpMkSWrBgEmSJDVEDN7S+3lijYi4MiL+GRF3R8RnyvajI+K/EXF7uezQtM8RETE5IuoR8Z6m9u3KtskRcXhT+1oRcUNE3BcR50bE4gN9XwyYJElSQwzi0sIc4NDMfAOwKXBgRKxbrvt+Zm5QLpcAlOt2A9YDtgNOjIiRETESOAHYHlgX+EjTcb5VHmsc8CSw38DeFQMmSZLUAZk5NTNvLR8/C/wTWK2XXcYD52Tmi5n5b2AysEm5TM7M+zNzFnAOMD4iAtgK+E25/2nATgPtrwGTJEmar40ppsYpI9YE3gLcUDYdFBF3RMSkiFihbFsN+E/TblPKtp7aVwKeysw53doHxIBJkiQ1xGD+FzEhIm5uWia87HwRSwPnAZ/NzGeAk4B1gA2AqcB3G117uRxA+4A4rYAkSVogMnMiMLGn9RGxGEWwdFZm/rbc59Gm9T8DLiqfTgHWaNp9deDh8nFV++PA8hExqswyNW/fb2aYJElSQxuvkgvgFOCfmfm9pvZVmzbbGbirfHwhsFtELBERawHjgBuBm4Bx5RVxi1MMDL8wMxO4Etil3H8v4IKBvi9mmCRJUkMbp63cDNgDuDMibi/bjqS4ym0DivLZA8AnATLz7oj4FfAPiivsDszMuQARcRBwGTASmJSZd5fHOww4JyK+AdxGEaANSBQB2EIjX5jTeiOpL5Ys/1zwM6XB0vWZuu/RmZ3tiIaNcauMhjbfrOSuKc8NWmCw/upLD5tpw80wSZKk+YZNiDO4DJgkSVKD95Kr5qBvSZKkFswwSZKkhlZXty2qDJgkSVKD8VI1S3KSJEktmGGSJEnzmWKqZMAkSZIavEqumiU5SZKkFswwSZKkBq+Sq2bAJEmSGoyXqlmSkyRJasEMkyRJms8UUyUDJkmS1OBVctUsyUmSJLVghkmSJDV4lVw1AyZJktRgvFTNkpwkSVILZpgkSdJ8ppgqGTBJkqQGr5KrZsAkSZIaHPRdzTFMkiRJLZhhkiRJDSaYqhkwSZKk+YyYKlmSkyRJasEMkyRJavAquWoGTJIkqcGr5KpZkpMkSWrBDJMkSWowwVTNgEmSJDVYkqtmSU6SJKkFM0ySJKmJKaYqBkySJKnBklw1S3KSJEktmGGSJEkNJpiqGTBJkqQGS3LVLMlJkiS1YIZJkiQ1eC+5agZMkiRpPuOlSpbkJEmSWjDDJEmSGkwwVTNgkiRJDV4lV82SnCRJUgtmmCRJUoNXyVUzYJIkSfMZL1WyJCdJktSCGSZJktRggqmaAZMkSWrwKrlqluQkSZJaMMMkSZIavEqumgGTJElqsCRXzZKcJElSCwZMkiRJLViSkyRJDZbkqplhkiRJasEMkyRJavAquWoGTJIkqcGSXDVLcpIkSS2YYZIkSQ0mmKoZMEmSpPmMmCpZkpMkSWrBDJMkSWrwKrlqBkySJKnBq+SqWZKTJElqwQyTJElqMMFUzYBpIfTVLx/BNVdfxYorrsRvL7gIgJ/86AdcdeUVjIgRrLDSSnz92G8yduwq3HTjDXz2059itdVWB2Crd2/D/p86qJPd1xBU9Zk66YQfc95vfsWKK6wIwKc/ewj/9853cecdd/D1o78CQGay/4GfZut3b9OxvquzfnD8Udz0t2tYboUVOfG08wC4/757OOG7xzJr1ouMHDmKAz53BLV138iM557lO9/4Eo89+gjz5s5h5932ZJsddgJg0knf5+brrmXevOQtb92UCQd/kYjgq5//FNOfeJx5c+ew7ps25IDPHcHIkSM7+ZKHPyOmSpGZne5Df+QLczrdhc675eabGDNmDF864rDGL7fnnnuOpZdeGoCzzjyd+/81ma8cdQw33XgDp/1iEj858aed7PKQtGT554KfqerP1Ekn/JgxY8aw1z77vWTbmTNnsthiizFq1Cgee2wau35gPH+68lpGjfLvr67P1H2PzuxsR9rorttvYcnRY/jecV9uBExfOWR/xn/oY2y86ebcdN21nHf2Lzj+R6fwqzN+zoznnmOfAz7L009N55O778QZ51/B5HvuZtJJ3+f4H08C4IsH7cNeEz7Nm97yVp6f8RxjllqazOSbX/k8m225De/aertOvuS2GrfKaGhzCPP87MELDMYs1vuIqIjYDvghMBL4eWYeP1jnHmwdGcMUEYtHxPrlslgn+rAw22jjt7Lscsu9pK0rWAJ4YeZMwlF76oeqz1RPRo8e3QiOXnzxRT9ri7j1N9iIZZZd9qWNETw/YwYAz894jpVWfkWjfebMGWQmM5+fyTLLLldkiyKYNWsWc+bMZvbsWcydM4cVVlgJgDFLFd9tc+fOYfac2V7B1QYxiP/1ep6IkcAJwPbAusBHImLdNrzEAWn7n4QRsQVwGvAARdS8RkTslZnXtLsvw82Pf/h9fn/h+Sy99DL8/NTTG+133H47u+78fl4xdiyHfOEwXvvacR3spRYm5/zyLH5/4fmsu976fP4LhzeCqjvu+DtHfflIpj78MMce/22zS3qJCZ/+Al/9/KeYdOL3mJfz+M6JpwHwvg/sxteP+Ax77rwNM2fO4LCjv8WIESN4w/pv5k1veSt77vxuMuF9H/gwa6y5duN4Xzn0AO79511svOlmbLbFuzv1shYZbfwbaBNgcmbeX5w3zgHGA/9oWw/6oe0luYi4BfhoZtbL568Dzs7MjXrYfgIwoXw6MTMntqenQ1utVlsTuKher69fse6IGTNmvGPKlCk71mq1ZYF59Xr9uVqttgPww3q9bsSkl+n+marVaqsAjwM5Y8aMi5ZaaqlH6vX6vt32eQPFH0DvrNfrL7S7zxoaKj47PwKurtfr59VqtQ8BE+r1+rtrtdouwGbAIf/973+PXG211T4OvBkYS1GW+XB5yMuBw+r1+jVN51gSOAs4uV6vX96u16b/Tbff4dD0ezwidgG2y8yPl8/3AN6WmUNyoG0nSnKLdQVLAJl5L9BjWS4zJ2bmxuVisNQ3v1xsscXeDVCv15+p1+vPlY8vARar1Word7R3WijU6/VH6/X63Hq9Pm/atGmrU/w12H2bfwIzgJcF7lqk7QX8tnz8a+Z/dvYBfluv13PGjBk7A/8GXg/sDFxfr9efK7+v/gBs2nzAMiC/kCIDoYVEt9/h3X+PV+WyhuzA6k4ETDdHxCkRsUW5/Ay4pQP9GFZqtVpz1uj9s2fPnlm2v7JWq0X5eBOKf/MnOtBFLWRqtdqqXY+XWWaZ5YG7yva1arXaqPLxa4AaRYld6vIw8K7y8VbAfeXjh4CtAUYVddwacH/Z/q5arTaqVqstVu77z1qttnTX57D8zO0A3NO2V6EFbQqwRtPz1Sk+O0NSJ0pySwAHAptTRJfXACdm5ott7chCrFarnQ1sAawMPAocRfFFUgPmAQ/ef//9r549e/aba7XaQcABwBxgJnBIvV7/W0c6riGrh8/UFsAGQD7//POvHjNmzBvq9frUWq22B3A4MJvi83ZMvV4/vyMdV8f18NmpU5TYRgEvAJ+q1+u31Gq1VwG/AFadNWvWaxdffPFP1Ov1M2u12kjgROCdFBmGS+v1+iFlWfgiYAmKq6j+DHyuXq97beswEBGjgHspguj/AjdRDNm5u6Md68HCNq2A+igiJljC1GDx86TB5mdKABGxA/ADioB4UmYe2+Eu9ahtAVNE3EkvtcnMfFNbOiJJktRP7bwW+H3lzwPLn2eUP3cHnm9jPyRJkvqlE2OY/pqZm7VqkyRJGio6cZXcUhGxedeTiHgHsFQH+rFQi4idIyIj4vXl8zUj4q7y8QZlXViqFBFzI+L2iPh7RNxa/n/Yah8vFliElN8vZzQ9HxURj0XERf08zgMRMehTmTR/50nt0ImAaT/ghPJ/ogcorozYt/ddVOEjwF+A3SrWbUBx1ZzUk5mZuUFmvhk4Avhmqx0ys2VQpWFlBrB+RIwun29DcSXTAlXeLkMactoeMGXmLeWX9JuAN5df2re2ux8Ls4hYmmK23P3oFjBFxOLAMcCHywzChyNixYg4PyLuiIjrI8IB9mq2LPAkFJ+tiLiizDrdGRGNSQIj4rny584R8acorBoR90bEKyNiyYg4tdzvtojYskOvR4PnD8B7y8cfAc7uWtHT90pErBQRfyw/Az+laXLCiPhYRNxYfjf9tCs4iojnIuKYiLgBeHtEfDUiboqIuyJiYpQ3LIyIjcqs6HXMHw+Lnz21Q6duvvteYH/gM+X/GF/tRD8WYjsBl5azpE+PiA27VmTmLOCrwLllMHou8DXgtvJKxCOB06sOqkXK6PKX1j3Az4Gvl+0vADtn5obAlsB3u35ZdcnM3wGPUPzC+hlwVGZ2PScz30jxy/W0iFiyLa9GC8o5wG7lv+ObgBua1vX0vXIU8JfMfAvFzNyvBoiIN1Dc+mSzzNwAmEtx0Q8UwzLuysy3ZeZfgJ9k5lszc31gNPMvGjoVODgz396tn372tMC1PWCKiJMp/qf5NMVfHrsCr2l3PxZyH6H4IqP8+ZEW229OeVViZv4ZWCki+nZreg1XXSW51wPbAaeXgVEAx0XEHcCfgNWAVSr2/zRFKe/FzOzKOjR/zu4BHgRet2BfhhakzLwDWJPiO+aSbqt7+l55J3Bm2X4xZfaSYnLCjYCbIuL28nnXHXbnAuc1HXvLiLihnI5mK2C98tjLZ+bV5TZnNG3vZ08LXCduMf6OzHxTRNyRmV+LiO8y/55DaiEiVqL4Alk/IpJisq+kGAvW424Vbc5YKgAy87pyUO4rKMa+vQLYKDNnl+MMq/5SX41ilu9VImJEZs6j+nOmhd+FwHcoZvNeqam9t++Vqu+XAE7LzCMq1r2QmXOhKK9RfJ9tnJn/iYijKT6D0cNxe+qLNKg6UZLruqP58xHxKorbK6zVgX4srHYBTs/M12Tmmpm5BsUNLFdv2uZZYJmm59dQpr4jYgvg8cx8pk391RBXXmk5kuIeg8sB08pgaUsqsr9R3M7gVOCjwD+BQ8pVzZ+z11GUYurd99dCZxJwTGbe2a29p++V5vbtgRXK7a8AdomIseW6FSOiqrrQFaA/Xo7X3AUgM58Cno75V1nv3rSPnz0tcJ3IMP0+IpYH/h9wK8VfDD/rQD8WVh8Bju/Wdh7FGIIuVwKHl2nvbwJHA6eWZZbnKe4krkXb6PLzAcVf53tl5tyIOIvi/9GbgdupvtHpkcC1mXlteYybIuJiiqzAyWUZZQ6wt/eIXPhl5hSK+8J1dzTV3ytfA86OiFuBqylurEtm/iMivgz8MSJGUPyxfCBF+az5fE9FcVP2Oylu6nxT0+p9gEkR8TxwWVO7nz0tcG2duLL8n2TTzPxb+XwJYMnMfLptnZAkSeqnTsz0fV3FFQ6SJElDVifGMP0xIj7Y/VJlSZKkoaoTGaZnKebcmAvMpLzyITOXbWtHJEmS+qjtAZMkSdLCphMTV0Y5Pf5XyudrRMQm7e6HJElSX3ViDNOJwNsp5nABeA44oQP9kNoqIvaO4g7wXcusiPhXRBw32LdxiIirIuKqwTzmwigitijf6y063RdJC7dOzMP0tszcMCJuA8jMJ6O4Yay0qNgVmEIxuejOFLcYWYbidiOSpCGoEwHT7PIO1QkQEa+guMWCtKi4PTMnl48vj4hxwH4R8ZnyFiPqQXl17WLlTaYlqW06UZL7EfA7YGxEHAv8BTiuA/2QhopbKe7IvnJzY0SsFRFnRcRjEfFiRNweETt33zkidouIe8pt7q7aptxu5Yg4KSL+W257T0RMaNW5prLW+yPiJxHxeNmnM8tZ+5u3HRURRzT15+GI+G5zybGnMllTyXLNprYHyvPsGxH3ALOA95brvhYRt0bE02Wf/hwRm7Z6PZI0EG3PMGXmWRFxC8WdqgPYKTP/2e5+SEPImsDTFPdyA4qLIYAbgGnA54DHgA8D50XETpl5Ybndu4FfAhcDh1LcOPeHwGI03UsrIpYF/koRmB1Ncf/B9wAnRcQSmfnjPvTzh8BFFOMPa8C3KaYHab7VzpnAjsC3gL8BbwC+Xr7GD/bp3Xi5LYEN+P/t3VuIVVUcx/Hvny5CgmGSvmU3KiIrSumGCVFQBknpSzRkmQ8ilSKJBJp2eRPyRTCji1kwPZiUkI5mavqilVCmZBpFRprmDPUg2c1fD/99nOPhzJw502kfrd8HhnP23meftfbDDP9Z67/WP0tuHCHLZUAWAF5CTm8OBTqArRExVtKuQbZlZlZXaQFTRFxQdXgE6Ky+JqmnrL6YtdlZRQHbSg7TZGB2pVp7YRH5D8UESZVAan0RSD1HVpCHDCL2ApMq03kR8SWwnVOLj84iC+mOkbS/OLexGCFaGBHLJP3ZoN9bJVXyrDZExJXA9Ih4RJIiYjwZ1E2VtLKqjR7grYi4XtJn9b64geHAjZJ+rD4paXrlfTHN3wXsAR4rntfMrGXKnJLbCXxavP4E7AP2F+93ltgPs3bbSxYe7QFeBZZLWlrzmbuBtWR19rMrP2TB0esiYlgRJIwDVlXnPknaQe8oTPX37QC+rfN9I4CrB9Dv92uOvwCGAKOq2vidHAWrbmNDcf32AbRRz/baYAlydC0iNkdEN1lw9Q/gCnL0y8yspUobYZJ0CUBEvASskbS2OL4HuLOsfpidBu4np5EuBOYAMyNiR9WoDMBI4OHip54R5PTaOcDhOtdrz40ELieDir6+r5HaUeBKNfhKftJI4Fxyq5DBtlHPodoTEXEDGVCuJ0eUDpHTg69U9cfMrGXasUpunKQZlQNJ6yLi+Tb0w6xddldWyUXEJmAXsDgi3pF0rPhMN7CNzAWq5yC9oyqj6lwfBXxXddxNToX3NVX1VR/nm9ENHAfG93H9YPF6vHit3U6kr4CqXjmCyeTzPyDpZBAYEcOBnwfUWzOzJrQjYDoaEfPJ5FCRiZrd/d9i9t8k6beImAu8B8wEFheXusgNXvdI+rWv+yPiE2BKRCyqymG6iUyyrg6Yush9ng5IOtLyB+ltYx5wvqQP+/lcpV/X0DtdBzCxibbOI0eUTgZTEXEHcBGZ0G5m1lLtCJgeBBaSWwsAbC3Omf0vSVpTBD5PRcTSIkB6BviYXPW1lMxJGk4GGZdKmlbcvpAMOt6NiOXkNN+zQG3OzxIyIXtbRCwhR5SGAlcBNXUgcgAAAgdJREFU4yVNasFzbImITmBVRLxY9P8EGbxNBOZJ2ifpUER8BDwdEUfJka8O4LImmusCZgMrIuJ1MndpAfDDP30OM7N6St+HSVKPpFnABPIP9SyvkDNjPpkDNANA0gFgLPA5uU/ZB8Ay8vdmU+UmSRuBh8hE59XAXDKQOGWKTdIvwK1k3s88MvfnNWASsLmFz9FBrvCbQo6arQIeJxd4HK753HZyX7YVwAHghYE2Imk98CRwG7nVwTQy3+vr/u4zMxuskOqlB/yLDUaMAVYClW0GjpLLkHeX2hEzMzOzAWrHTt/LgTmSRksaTW6293Ib+mFmZmY2IO0ImIZKOjkFIGkLmUthZmZmdlpqR9L3NxGxAHizOO7Aq1rMzMzsNNaOEaZp5Eqe1eRKuQuBR9vQDzMzM7MBKT3p28zMzOxMU2bx3TX9XZd0X1l9MTMzM2tGmTlMtwDfA51kEdAosW0zMzOzQSttSq6orH4Xuav3tWTl805Je0rpgJmZmdkglZb0LekvSV2SpgI3kzvybomIJ8rqg5mZmdlglLqtQEQMAe4lR5kuJssirC6zD2ZmZmbNKnNK7g2ycOg64G2XQjEzM7MzRZkB0wngWHFY3WgAkjSslI6YmZmZNcn7MJmZmZk10I6dvs3MzMzOKA6YzMzMzBpwwGRmZmbWgAMmMzMzswYcMJmZmZk18DfNz20m5bkhcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y, y_pred_inv)\n",
    "print('Acurácia: {:.2f}\\n'.format(accuracy*100))\n",
    "\n",
    "cm = confusion_matrix(y, y_pred_inv)\n",
    "fig, ax = plt.subplots(figsize=(10,7)) \n",
    "sns.heatmap(cm, linewidths=1, annot=True, ax=ax, fmt='g', cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "ax.set_xlabel('Rede neural', fontsize=16)\n",
    "ax.set_ylabel('K-Means', fontsize=16)\n",
    "ax.set_title('Matriz de Confusão', fontsize=18)\n",
    "ax.xaxis.set_ticklabels(['Alto', 'Baixo', 'Moderado'])\n",
    "ax.yaxis.set_ticklabels(['Alto', 'Baixo', 'Moderado'])\n",
    "\n",
    "#plt.savefig('cm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva o resultado em uma planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_save[['CD_CIR_DENTISTA', 'CD_ESPECIALIDADE', 'NM_CIR_DENTISTA', 'CLASSE', 'CLASSE_REDE_REURAL']]\n",
    "X_ = X_.rename(columns={'CLASSE': 'CLASSE_CONSULTORIA_COMP_V1'})\n",
    "\n",
    "print(X_.shape)\n",
    "X_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.to_excel('RESULTADO_RNA_COMP_V1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com novos dentistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('SAMPLES_FLEURY.csv') \n",
    "\n",
    "X_save = df_test[['CD_CIR_DENTISTA', 'NM_CIR_DENTISTA', 'CPF_CNPJ', 'CD_ESPECIALIDADE']]\n",
    "df_test = df_test.drop(['Unnamed: 0', 'CD_CIR_DENTISTA', 'CPF_CNPJ', 'CD_ESPECIALIDADE', 'NM_CIR_DENTISTA', 'ID_DENTISTA_PRINCIPAL'], axis=1)\n",
    "\n",
    "columns_remove = ['FICHAS_NEGADAS_PRE_CD12M', 'EVENTOS_PRE_CD12M', 'EVENTOS_GLOSADOS_PRE_CD12M', 'PERC_EVENTOSGLOSADOS_PRE_CD12M', 'PERC_FICHAS_NEGADAS_PRE_CD12M', 'EVENTOS_PRE_ESP12M', 'EVENTOS_GLOSADOS_PRE_ESP12M', 'PERC_EVENTOSGLOSADOSPRE_ESP12M', 'FICHAS_NEGADAS_PRE_CD6M', 'LOOP_GTOS_PRE_CD6M', 'EVENTOS_PRE_CD6M', 'EVENTOS_GLOSADOS_PRE_CD6M', 'PERC_EVENTOS_GLOSADOS_PRE_CD6M', 'PERC_FICHAS_NEGADAS_PRE_CD6M', 'EVENTOS_PRE_ESP6M', 'EVENTOS_GLOSADOS_PRE_ESP6M', 'PERC_EVENTOSGLOSADOS_PRE_ESP6M', 'FICHAS_NEGADAS_PRE_CD2M', 'LOOP_GTOS_PRE_CD2M', 'EVENTOS_PRE_CD2M', 'EVENTOS_GLOSADOS_PRE_CD2M', 'PERC_EVENTOS_GLOSADOS_PRE_CD2M', 'PERC_FICHAS_NEGADAS_PRE_CD2M', 'EVENTOS_PRE_ESP2M', 'EVENTOS_GLOSADOS_PRE_ESP2M', 'PERC_EVENTOSGLOSADOS_PRE_ESP2M', 'FICHAS_NEGADAS_PRE_CD1M', 'LOOP_GTOS_PRE_CD1M', 'EVENTOS_PRE_CD1M', 'EVENTOS_GLOSADOS_PRE_CD1M', 'PERC_EVENTOS_GLOSADOS_PRE_CD1M', 'PERC_FICHAS_NEGADAS_PRE_CD1M', 'EVENTOS_PRE_ESP1M', 'EVENTOS_GLOSADOS_PRE_ESP1M', 'PERC_EVENTOSGLOSADOS_PRE_ESP1M', 'COMP150', 'COMP151', 'COMP153']\n",
    "\n",
    "df_test.drop(columns=columns_remove, inplace=True)\n",
    "\n",
    "columns_remove = ['PERC_EVENTOS_GLOSADOS_CD12M', 'PERC_EVENTOS_GLOSADOS_CD6M', 'PERC_EVENTOS_GLOSADOS_CD2M', 'PERC_EVENTOS_GLOSADOS_CD1M', 'PERC_VL_GLOSADO_CD12M', 'PERC_VL_GLOSADO_CD6M',\n",
    "'PERC_VL_GLOSADO_CD2M', 'PERC_VL_GLOSADO_CD1M', 'PERC_EVENTOS_RES_1F_CD12M',\n",
    "'PERC_EVENTOS_RES_1F_CD6M', 'PERC_EVENTOS_RES_1F_CD2M', 'PERC_EVENTOS_RES_1F_CD1M',\n",
    "'PERC_EVENTOS_RES_CD12M', 'PERC_EVENTOS_RES_CD6M', 'PERC_EVENTOS_RES_CD2M',\n",
    "'PERC_EVENTOS_RES_CD1M', 'PERC_FICHASCANCELADASPRE_CD12M', 'PERC_FICHASCANCELADAS_PRE_CD6M',  'PERC_FICHASCANCELADAS_PRE_CD2M', 'PERC_FICHASCANCELADAS_PRE_CD1M', 'UO_EVENTO_CD12M',\n",
    "'UO_EVENTO_ESP12M', 'UO_EVENTO_CD6M', 'UO_EVENTO_ESP6M', 'UO_EVENTO_MD6M', 'UO_EVENTO_CD2M',\n",
    "'UO_EVENTO_ESP2M', 'UO_EVENTO_CD1M', 'UO_EVENTO_ESP1M', 'COMP121', 'COMP122', 'COMP124',\n",
    "'COMP125', 'COMP129', 'COMP130', 'COMP133', 'COMP134', 'COMP137', 'COMP138', 'COMP140',\n",
    "'COMP141', 'COMP156', 'COMP157', 'COMP159', 'COMP160', 'COMP163', 'COMP164', 'COMP166',\n",
    "'COMP167', 'COMP170', 'COMP171', 'COMP173', 'COMP174']\n",
    "\n",
    "df_test.drop(columns=columns_remove, inplace=True)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the model parameters\n",
    "with open('model\\scaler.pickle', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "with open('model\\label.pickle', 'rb') as label_file:\n",
    "    le = pickle.load(label_file)\n",
    "# Feature scaling\n",
    "X = scaler.transform(df_test)\n",
    "\n",
    "# Load the model decisor\n",
    "filename_model = 'model\\modelo_rede_decisora.json'\n",
    "with open(filename_model, 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights('model\\pesos_rede_decisora.h5')\n",
    "\n",
    "# Shows model features\n",
    "#model.summary()\n",
    "\n",
    "# Predict\n",
    "y_pred = predict_decisor_model(model, X)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Transform label\n",
    "y_pred_inv = le.inverse_transform(y_pred)\n",
    "y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_save['CLASSE_REDE_REURAL'] = y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_save.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
