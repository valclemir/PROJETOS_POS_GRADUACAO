{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#import numpy as np\n",
    "import json \n",
    "\n",
    "# Palavras das quais será gerada a lista simulando o resultado da extração do texto\n",
    "#palavras = ['madri', 'abrigo', 'fila', 'menino', 'soprano', 'nó', 'engolir',\n",
    "#            'dentro','caverna', 'percepção', 'flash']\n",
    "\n",
    "with open('jairbolsonaro.json', 'r') as json_file:\n",
    "    words = json.load(json_read)\n",
    "    \n",
    "\n",
    "\n",
    "# Lista simulando as palavras lidas do texto\n",
    "livro  = np.random.choice(palavras, 800, replace=True)\n",
    "\n",
    "# Conta a frequencia de cada palavra na lista\n",
    "counter = Counter(livro)\n",
    "\n",
    "# Dicionario vazio para o resultado das médias\n",
    "medias = {}\n",
    "\n",
    "# Calculo das médias (considerando 3 capítulos)\n",
    "for item in counter.items():\n",
    "    medias[item[0]] = round(item[1]/3,2)\n",
    "\n",
    "# Apresentando o resultado\n",
    "print(medias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json \n",
    "import re    \n",
    "import csv \n",
    "\n",
    "with open('jairbolsonaro.json', 'r') as json_file:\n",
    "    words = json.load(json_file)\n",
    "    \n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as stopWords_file:\n",
    "    stop_words = [row[0].strip() for row in csv.reader(stopWords_file, delimiter='\\t')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('^@[A-Za-z0-9_]{1,15}$')\n",
    "\n",
    "\n",
    "words_token = []\n",
    "for i in words:\n",
    "    text = i['full_text']\n",
    "    \n",
    "    words_split = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    words_token.append(words_split.split())\n",
    "    \n",
    "#counter = Counter(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence  = []\n",
    "\n",
    "for i in words_token:\n",
    "    for w in i:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brasil', 1123),\n",
       " ('es', 995),\n",
       " ('n', 741),\n",
       " ('Bolsonaro', 656),\n",
       " ('todos', 542),\n",
       " ('ncia', 535),\n",
       " ('rio', 394),\n",
       " ('sobre', 349),\n",
       " ('est', 316),\n",
       " ('PT', 315)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
